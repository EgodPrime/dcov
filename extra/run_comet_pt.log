2024-06-13 05:02:58,993 logger.py[line:35] INFO Seed Selector Exists! Continue COMET!
2024-06-13 05:02:58,998 logger.py[line:35] INFO INFO: Mutation progress 1/100
2024-06-13 05:02:58,998 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:02:58,998 logger.py[line:35] INFO Score for NLAll is: 0.8970588235294118
2024-06-13 05:02:58,998 logger.py[line:35] INFO Score for MDtype is: 0.8629032258064516
2024-06-13 05:02:58,998 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:02:58,998 logger.py[line:35] INFO Score for MParam is: 0.8541666666666666
2024-06-13 05:02:58,998 logger.py[line:35] INFO Score for MDims is: 0.8378378378378378
2024-06-13 05:02:58,999 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:02:58,999 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:02:58,999 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:02:58,999 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:02:58,999 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:02:58,999 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82
2024-06-13 05:02:58,999 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:03:03,246 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 05:03:04,633 logger.py[line:35] INFO Insert 7 out of 30 Global New Layers
2024-06-13 05:03:04,633 logger.py[line:35] INFO insert AveragePooling2D after conv3_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:03:04,633 logger.py[line:35] INFO insert Cropping2D after conv4_block4_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:03:04,634 logger.py[line:35] INFO insert ZeroPadding2D after conv3_block4_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:03:04,634 logger.py[line:35] INFO insert BatchNormalization after pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:03:04,634 logger.py[line:35] INFO insert LocallyConnected2D after conv4_block4_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:03:04,634 logger.py[line:35] INFO insert ReLU after conv3_block1_0_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:03:04,635 logger.py[line:35] INFO insert UpSampling2D after cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8f01d22d0>
2024-06-13 05:03:04,672 logger.py[line:35] INFO Converting output shape (None, 114, 114, 64) to actual shape [None, 114, 114, 64]
[DEBUG] Inserting layer: <keras.layers.pooling.AveragePooling2D object at 0x7fa8f010aa10>
2024-06-13 05:03:04,884 logger.py[line:35] INFO Converting output shape (None, 28, 28, 512) to actual shape [None, 28, 28, 512]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ReLU object at 0x7fa8f01142d0>
2024-06-13 05:03:04,896 logger.py[line:35] INFO Converting output shape (None, 28, 28, 512) to actual shape [None, 28, 28, 512]
[DEBUG] Inserting layer: <keras.layers.convolutional.ZeroPadding2D object at 0x7fa8f00873d0>
2024-06-13 05:03:05,032 logger.py[line:35] INFO Converting output shape (None, 36, 32, 128) to actual shape [None, 28, 28, 128]
[DEBUG] Inserting layer: <keras.layers.convolutional.Cropping2D object at 0x7fa8b87be690>
2024-06-13 05:03:05,249 logger.py[line:35] INFO Converting output shape (None, 14, 12, 254) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.local.LocallyConnected2D object at 0x7fa8b87d7f50>
2024-06-13 05:03:13,818 logger.py[line:35] INFO Converting output shape (None, 10, 14, 250) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.convolutional.UpSampling2D object at 0x7fa8385f2190>
2024-06-13 05:03:14,190 logger.py[line:35] INFO Converting output shape (None, 10, 30, 9) to actual shape [None, 10, 10, 3]
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'custom_crop_layer_1')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 05:03:14,380 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 20/2170
The Configuration Coverage is: 73/2049
The NDims Coverage Is: 10/117
The DType Coverage Is: 12/354
The Shape Coverage Is: 27/295
The Input Coverage Is: 49/766
2024-06-13 05:03:26,565 logger.py[line:35] INFO Loading the framework
2024-06-13 05:03:26,566 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:03:27,050 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll1/resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll1.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:08:29,784 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 5m, 2s
2024-06-13 05:08:29,784 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll1 crash on backend pytorch when predicting
2024-06-13 05:08:29,806 logger.py[line:35] INFO coverage_c=8218
2024-06-13 05:08:29,872 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll1
2024-06-13 05:08:29,872 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:08:29,872 logger.py[line:35] INFO after_prediction
2024-06-13 05:08:30,280 logger.py[line:35] INFO INFO: Mutation progress 2/100
2024-06-13 05:08:30,280 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:08:30,280 logger.py[line:35] INFO Score for NLAll is: 0.8913043478260869
2024-06-13 05:08:30,280 logger.py[line:35] INFO Score for MDtype is: 0.8629032258064516
2024-06-13 05:08:30,280 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:08:30,280 logger.py[line:35] INFO Score for MParam is: 0.8541666666666666
2024-06-13 05:08:30,280 logger.py[line:35] INFO Score for MDims is: 0.8378378378378378
2024-06-13 05:08:30,280 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:08:30,280 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:08:30,280 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:08:30,280 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:08:30,281 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:08:30,281 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype132-SpecialI1-MShape20-Edge90
2024-06-13 05:08:30,281 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:08:34,431 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_NLAll')>, 'custom_cast_layer_5_copy_SpecialI_copy_MShape_copy_Edge': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'custom_cast_layer_5_copy_SpecialI_copy_MShape_copy_Edge_copy_NLAll')>, 'custom_pad_layer_1_copy_Edge': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'custom_pad_layer_1_copy_Edge_copy_NLAll')>, 'conv4_block1_0_bn_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'conv4_block1_0_bn_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2_copy_NLAll')>, 'conv3_block3_2_conv_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'conv3_block3_2_conv_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2_copy_NLAll')>, 'avg_pool_copy_Edge_1_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2': <KerasTensor: shape=(None, 512) dtype=float32 (created by layer 'avg_pool_copy_Edge_1_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2_copy_NLAll')>}
2024-06-13 05:08:35,719 logger.py[line:35] INFO Insert 6 out of 20 Global New Layers
2024-06-13 05:08:35,719 logger.py[line:35] INFO insert Conv2DTranspose after conv2_block2_1_conv_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_NLAll
2024-06-13 05:08:35,719 logger.py[line:35] INFO insert RepeatVector after avg_pool_copy_Edge_1_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2_copy_NLAll
2024-06-13 05:08:35,720 logger.py[line:35] INFO insert GaussianDropout after conv4_block6_1_conv_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_NLAll
2024-06-13 05:08:35,720 logger.py[line:35] INFO insert AlphaDropout after conv3_block1_3_bn_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_NLAll
2024-06-13 05:08:35,720 logger.py[line:35] INFO insert ELU after conv3_block1_2_conv_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_NLAll
2024-06-13 05:08:35,720 logger.py[line:35] INFO insert TimeDistributed after conv4_block3_1_bn_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.convolutional.Conv2DTranspose object at 0x7f7a102f2c10>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/initializers/initializers_v2.py", line 674, in __call__
    'Identity matrix initializer can only be used for 2D matrices. '
ValueError: Identity matrix initializer can only be used for 2D matrices. Received: shape=(64,) of rank 1.
2024-06-13 05:08:36,288 logger.py[line:35] INFO INFO: Mutation progress 2/100
2024-06-13 05:08:36,289 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:08:36,289 logger.py[line:35] INFO Score for NLAll is: 0.8913043478260869
2024-06-13 05:08:36,289 logger.py[line:35] INFO Score for MDtype is: 0.8629032258064516
2024-06-13 05:08:36,289 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:08:36,289 logger.py[line:35] INFO Score for MParam is: 0.8541666666666666
2024-06-13 05:08:36,289 logger.py[line:35] INFO Score for MDims is: 0.8378378378378378
2024-06-13 05:08:36,289 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:08:36,289 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:08:36,289 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:08:36,289 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:08:36,289 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:08:36,289 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4
2024-06-13 05:08:36,289 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:08:43,512 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype')>}
2024-06-13 05:08:47,186 logger.py[line:35] INFO Change 1 Layer's DType Out Of 5 Layer classes
2024-06-13 05:08:47,186 logger.py[line:35] INFO Changing 1 out of 5 Layer's DType.
2024-06-13 05:08:47,189 logger.py[line:35] INFO Selecting a Global DType half For Layer avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype')>}
2024-06-13 05:08:51,350 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 20/2170
The Configuration Coverage is: 83/2049
The NDims Coverage Is: 10/117
The DType Coverage Is: 16/354
The Shape Coverage Is: 33/295
The Input Coverage Is: 59/766
2024-06-13 05:08:57,586 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:08:58,035 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (1042) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:09:57,878 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 59s
2024-06-13 05:09:57,879 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MDtype2 crash on backend pytorch when predicting
2024-06-13 05:09:57,901 logger.py[line:35] INFO coverage_c=9737
2024-06-13 05:09:57,955 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MDtype2
2024-06-13 05:09:57,955 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:09:57,956 logger.py[line:35] INFO after_prediction
2024-06-13 05:09:58,133 logger.py[line:35] INFO INFO: Mutation progress 3/100
2024-06-13 05:09:58,133 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:09:58,133 logger.py[line:35] INFO Score for NLAll is: 0.8913043478260869
2024-06-13 05:09:58,133 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:09:58,133 logger.py[line:35] INFO Score for MDtype is: 0.8571428571428571
2024-06-13 05:09:58,133 logger.py[line:35] INFO Score for MParam is: 0.8541666666666666
2024-06-13 05:09:58,133 logger.py[line:35] INFO Score for MDims is: 0.8378378378378378
2024-06-13 05:09:58,133 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:09:58,134 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:09:58,134 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:09:58,134 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:09:58,134 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:09:58,134 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-NLAll58
2024-06-13 05:09:58,134 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:10:00,936 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:10:01,531 logger.py[line:35] INFO Generating model using MDtype
2024-06-13 05:10:01,534 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_MDtype')>}
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 91, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dtype(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 403, in mutate_dtype
    mode=mutation_mode
  File "/root/implementations/scripts/tools/architecture_utils.py", line 990, in choose_layers_for_mdtype
    current_dtype_set = set(input_diversity[layer_class]["dtype"])
KeyError: 'LSTM'
2024-06-13 05:10:02,092 logger.py[line:35] INFO INFO: Mutation progress 3/100
2024-06-13 05:10:02,092 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:10:02,092 logger.py[line:35] INFO Score for NLAll is: 0.8913043478260869
2024-06-13 05:10:02,092 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:10:02,092 logger.py[line:35] INFO Score for MDtype is: 0.8571428571428571
2024-06-13 05:10:02,092 logger.py[line:35] INFO Score for MParam is: 0.8541666666666666
2024-06-13 05:10:02,092 logger.py[line:35] INFO Score for MDims is: 0.8378378378378378
2024-06-13 05:10:02,092 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:10:02,092 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:10:02,092 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:10:02,093 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:10:02,093 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:10:02,093 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype64-Edge69
2024-06-13 05:10:02,093 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:10:05,334 logger.py[line:35] INFO Generating model using MParam
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1': <KerasTensor: shape=(None, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MParam')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2': <KerasTensor: shape=(None, 8, 8, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_copy_MParam')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1': <KerasTensor: shape=(None, 16384) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MParam')>, 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 1, 1, 256) dtype=float32 (created by layer 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 8, 8, 96) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_MParam')>, 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1_copy_MParam')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2_copy_MParam')>, 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 256) dtype=float64 (created by layer 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>}
2024-06-13 05:10:05,480 logger.py[line:35] INFO Changing 1/1 of layer flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2_copy_MParam's configuration
2024-06-13 05:10:05,481 logger.py[line:35] INFO changing config data_format in layer flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2_copy_MParam: from channels_last to channels_last
2024-06-13 05:10:05,481 logger.py[line:35] INFO Changing 1/5 of layer batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam's configuration
2024-06-13 05:10:05,481 logger.py[line:35] INFO changing config center in layer batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from True to False
2024-06-13 05:10:05,481 logger.py[line:35] INFO changing config momentum in layer batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from 0.99 to 0.4428880232959266
2024-06-13 05:10:05,481 logger.py[line:35] INFO Changing 3/15 of layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam's configuration
2024-06-13 05:10:05,481 logger.py[line:35] INFO changing config bias_regularizer in layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from None to l1
2024-06-13 05:10:05,481 logger.py[line:35] INFO changing config bias_initializer in layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from {'class_name': 'Zeros', 'config': {}} to RandomUniform
2024-06-13 05:10:05,481 logger.py[line:35] INFO changing config activation in layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from relu to selu
2024-06-13 05:10:05,481 logger.py[line:35] INFO changing config kernel_regularizer in layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from None to l1
2024-06-13 05:10:05,481 logger.py[line:35] INFO Changing 2/15 of layer conv2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 05:10:05,482 logger.py[line:35] INFO changing config use_bias in layer conv2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from True to False
2024-06-13 05:10:05,482 logger.py[line:35] INFO changing config dilation_rate in layer conv2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from (1, 1) to [1, 2]
2024-06-13 05:10:05,482 logger.py[line:35] INFO changing config activation in layer conv2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from relu to elu
2024-06-13 05:10:05,482 logger.py[line:35] INFO Changing 2/15 of layer conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam's configuration
2024-06-13 05:10:05,482 logger.py[line:35] INFO changing config use_bias in layer conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from True to True
2024-06-13 05:10:05,482 logger.py[line:35] INFO changing config activation in layer conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from relu to sigmoid
2024-06-13 05:10:05,482 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 05:10:05,482 logger.py[line:35] INFO changing config bias_regularizer in layer conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from None to l2
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MParam': <KerasTensor: shape=(None, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MParam')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_copy_MParam': <KerasTensor: shape=(None, 8, 8, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_copy_MParam')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MParam': <KerasTensor: shape=(None, 16384) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MParam')>, 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 1, 1, 256) dtype=float32 (created by layer 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_MParam': <KerasTensor: shape=(None, 8, 8, 96) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_MParam')>, 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1_copy_MParam': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1_copy_MParam')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2_copy_MParam': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2_copy_MParam')>, 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 3, 3, 256) dtype=float64 (created by layer 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>}
2024-06-13 05:10:05,737 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 28/2170
The Configuration Coverage is: 95/2049
The NDims Coverage Is: 15/117
The DType Coverage Is: 19/354
The Shape Coverage Is: 41/295
The Input Coverage Is: 75/766
2024-06-13 05:10:06,762 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:10:07,210 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:10:32,443 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:10:32,444 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: expected scalar type Float but found Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
Automatic inference of operator: selu
2024-06-13 05:10:35,873 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 28s
2024-06-13 05:10:35,873 logger.py[line:35] INFO alexnet-SpecialI120-MDims44-MDtype64-Edge69-MParam3 crash on backend pytorch when predicting
2024-06-13 05:10:35,901 logger.py[line:35] INFO coverage_c=12515
2024-06-13 05:10:35,986 logger.py[line:35] INFO Fail on backend: pytorch of model alexnet-SpecialI120-MDims44-MDtype64-Edge69-MParam3
2024-06-13 05:10:35,986 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:10:35,986 logger.py[line:35] INFO after_prediction
2024-06-13 05:10:36,101 logger.py[line:35] INFO INFO: Mutation progress 4/100
2024-06-13 05:10:36,101 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:10:36,101 logger.py[line:35] INFO Score for NLAll is: 0.8913043478260869
2024-06-13 05:10:36,101 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:10:36,101 logger.py[line:35] INFO Score for MDtype is: 0.8571428571428571
2024-06-13 05:10:36,101 logger.py[line:35] INFO Score for MParam is: 0.84
2024-06-13 05:10:36,101 logger.py[line:35] INFO Score for MDims is: 0.8378378378378378
2024-06-13 05:10:36,101 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:10:36,101 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:10:36,101 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:10:36,101 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:10:36,102 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:10:36,102 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7
2024-06-13 05:10:36,102 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:10:40,463 logger.py[line:35] INFO Generating model using LMerg
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_LMerg')>, 'cropping2d': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_LMerg')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_LMerg')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_LMerg')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2_copy_LMerg')>, 'cropping2d_1': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_1_copy_LMerg')>, 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 20, 20, 256) dtype=float32 (created by layer 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_LMerg')>, 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_LMerg')>, 'cropping2d_2': <KerasTensor: shape=(None, 11, 11, 64) dtype=float32 (created by layer 'cropping2d_2_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 05:10:41,531 logger.py[line:35] INFO Insert 2 out of 5 Global New Layers
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 72, in generate_model_by_model_mutation
    return InteractionMutationUtils.merge_layers(model=model, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 165, in merge_layers
    assert len(selected_layer_name_list) == 1
AssertionError
2024-06-13 05:10:42,112 logger.py[line:35] INFO INFO: Mutation progress 4/100
2024-06-13 05:10:42,112 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:10:42,112 logger.py[line:35] INFO Score for NLAll is: 0.8913043478260869
2024-06-13 05:10:42,112 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:10:42,112 logger.py[line:35] INFO Score for MDtype is: 0.8571428571428571
2024-06-13 05:10:42,112 logger.py[line:35] INFO Score for MParam is: 0.84
2024-06-13 05:10:42,112 logger.py[line:35] INFO Score for MDims is: 0.8378378378378378
2024-06-13 05:10:42,113 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:10:42,113 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:10:42,113 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:10:42,113 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 05:10:42,113 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:10:42,113 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-NLAll94
2024-06-13 05:10:42,113 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:10:44,945 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:10:45,603 logger.py[line:35] INFO Generating model using MDims
2024-06-13 05:10:45,606 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_MDims')>}
2024-06-13 05:10:45,792 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 05:10:45,792 logger.py[line:35] INFO Global Layer Class: 1; Local Layer Class: 0; Total Layer Class: 1
2024-06-13 05:10:45,792 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 05:10:45,793 logger.py[line:35] INFO Selecting a Global NDims 6 For Layer dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_MDims
2024-06-13 05:10:45,796 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_MDims': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_MDims')>}
2024-06-13 05:10:45,997 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:10:46,588 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 29/2170
The Configuration Coverage is: 120/2049
The NDims Coverage Is: 20/117
The DType Coverage Is: 23/354
The Shape Coverage Is: 46/295
The Input Coverage Is: 89/766
2024-06-13 05:10:46,883 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:10:47,328 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (49) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:10:55,554 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 8s
2024-06-13 05:10:55,555 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-NLAll94-MDims4 crash on backend pytorch when predicting
2024-06-13 05:10:55,577 logger.py[line:35] INFO coverage_c=12516
2024-06-13 05:10:55,678 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-NLAll94-MDims4
2024-06-13 05:10:55,678 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:10:55,678 logger.py[line:35] INFO after_prediction
2024-06-13 05:10:55,788 logger.py[line:35] INFO INFO: Mutation progress 5/100
2024-06-13 05:10:55,788 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:10:55,788 logger.py[line:35] INFO Score for NLAll is: 0.8913043478260869
2024-06-13 05:10:55,788 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:10:55,788 logger.py[line:35] INFO Score for MDtype is: 0.8571428571428571
2024-06-13 05:10:55,788 logger.py[line:35] INFO Score for MParam is: 0.84
2024-06-13 05:10:55,788 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:10:55,788 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:10:55,789 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:10:55,789 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:10:55,789 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:10:55,789 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:10:55,789 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-LMerg70
2024-06-13 05:10:55,789 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:10:59,984 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>}
2024-06-13 05:11:01,055 logger.py[line:35] INFO Changing 2/2 of layer conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam's configuration
2024-06-13 05:11:01,055 logger.py[line:35] INFO changing config data_format in layer conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam: from channels_last to channels_first
2024-06-13 05:11:01,055 logger.py[line:35] INFO changing config padding in layer conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam: from ((3, 3), (3, 3)) to [1, 1]
2024-06-13 05:11:01,055 logger.py[line:35] INFO Changing 3/5 of layer conv4_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam's configuration
2024-06-13 05:11:01,055 logger.py[line:35] INFO changing config momentum in layer conv4_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam: from 0.99 to 0.5691565615307888
2024-06-13 05:11:01,056 logger.py[line:35] INFO changing config center in layer conv4_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam: from True to True
2024-06-13 05:11:01,056 logger.py[line:35] INFO changing config axis in layer conv4_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 05:11:01,056 logger.py[line:35] INFO changing config scale in layer conv4_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam: from True to True
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam': <KerasTensor: shape=(None, 9, 9, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam': <KerasTensor: shape=(None, 7, 8, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam': <KerasTensor: shape=(None, 4, 6, 5) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam': <KerasTensor: shape=(None, 9, 9, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam': <KerasTensor: shape=(None, 9, 9, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MParam')>}
2024-06-13 05:11:02,190 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 31/2170
The Configuration Coverage is: 122/2049
The NDims Coverage Is: 20/117
The DType Coverage Is: 23/354
The Shape Coverage Is: 47/295
The Input Coverage Is: 90/766
2024-06-13 05:11:04,381 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:11:04,828 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,1,1024,256) (1,1,14,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,1,1024,256) (1,1,14,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,1,1024,256) (1,1,14,1) 
2024-06-13 05:11:41,599 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:11:41,600 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [64, 5, 7, 7], expected input[102, 3, 224, 226] to have 5 channels, but got 3 channels instead

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:11:44,044 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 39s
2024-06-13 05:11:44,044 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-LMerg70-MParam5 crash on backend pytorch when predicting
2024-06-13 05:11:44,066 logger.py[line:35] INFO coverage_c=12531
2024-06-13 05:11:44,119 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-LMerg70-MParam5
2024-06-13 05:11:44,119 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:11:44,120 logger.py[line:35] INFO after_prediction
2024-06-13 05:11:44,264 logger.py[line:35] INFO INFO: Mutation progress 6/100
2024-06-13 05:11:44,264 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:11:44,264 logger.py[line:35] INFO Score for NLAll is: 0.8913043478260869
2024-06-13 05:11:44,264 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:11:44,264 logger.py[line:35] INFO Score for MDtype is: 0.8571428571428571
2024-06-13 05:11:44,264 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:11:44,264 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:11:44,264 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:11:44,264 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:11:44,264 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:11:44,264 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:11:44,265 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:11:44,265 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-NLAll94
2024-06-13 05:11:44,265 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:11:47,086 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:11:47,741 logger.py[line:35] INFO Generating model using MParam
2024-06-13 05:11:47,744 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_MParam')>}
2024-06-13 05:11:47,927 logger.py[line:35] INFO Changing 2/2 of layer global_max_pooling1d_insert_copy_MParam's configuration
2024-06-13 05:11:47,927 logger.py[line:35] INFO changing config keepdims in layer global_max_pooling1d_insert_copy_MParam: from False to True
2024-06-13 05:11:47,927 logger.py[line:35] INFO changing config data_format in layer global_max_pooling1d_insert_copy_MParam: from channels_last to channels_first
2024-06-13 05:11:47,930 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py", line 699, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: Exception encountered when calling layer "custom_pad_layer_copy_MParam" (type CustomPadLayer).

in user code:

    File "/root/implementations/scripts/generation/custom_layers.py", line 71, in call  *
        output = tf.pad(inputs, paddings=tf.constant([[0, 0]] + self.padding), mode="CONSTANT",

    ValueError: Shape must be rank 3 but is rank 4 for '{{node custom_pad_layer_copy_MParam/PadV2}} = PadV2[T=DT_FLOAT, Tpaddings=DT_INT32](Placeholder, custom_pad_layer_copy_MParam/Const, custom_pad_layer_copy_MParam/PadV2/constant_values)' with input shapes: [?,1,2,1], [3,2], [].


Call arguments received:
   inputs=tf.Tensor(shape=(None, 1, 2, 1), dtype=float32)
   kwargs={'training': 'None'}
2024-06-13 05:11:48,508 logger.py[line:35] INFO INFO: Mutation progress 6/100
2024-06-13 05:11:48,508 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:11:48,508 logger.py[line:35] INFO Score for NLAll is: 0.8913043478260869
2024-06-13 05:11:48,508 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:11:48,508 logger.py[line:35] INFO Score for MDtype is: 0.8571428571428571
2024-06-13 05:11:48,508 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:11:48,508 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:11:48,508 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:11:48,508 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:11:48,508 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:11:48,508 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:11:48,509 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:11:48,509 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-NLAll58
2024-06-13 05:11:48,509 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:11:51,330 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:11:51,929 logger.py[line:35] INFO Generating model using NLAll
2024-06-13 05:11:51,932 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_NLAll')>}
2024-06-13 05:11:52,107 logger.py[line:35] INFO Insert 4 out of 36 Global New Layers
2024-06-13 05:11:52,107 logger.py[line:35] INFO insert SimpleRNN after permute_insert_copy_NLAll
2024-06-13 05:11:52,107 logger.py[line:35] INFO insert SeparableConv1D after permute_insert_copy_NLAll
2024-06-13 05:11:52,107 logger.py[line:35] INFO insert GRU after permute_insert_copy_NLAll
2024-06-13 05:11:52,107 logger.py[line:35] INFO insert Permute after repeat_vector_insert_copy_NLAll_copy_NLAll
2024-06-13 05:11:52,107 logger.py[line:35] INFO Insert 2 out of 8 Local New Layers
2024-06-13 05:11:52,107 logger.py[line:35] INFO insert GlobalMaxPooling1D after permute_insert_copy_NLAll
2024-06-13 05:11:52,107 logger.py[line:35] INFO insert LSTM after permute_insert_copy_NLAll
2024-06-13 05:11:52,107 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 2
2024-06-13 05:11:52,108 logger.py[line:35] INFO insert RepeatVector after custom_crop_layer_copy_NLAll_copy_NLAll
2024-06-13 05:11:52,108 logger.py[line:35] INFO insert AveragePooling3D after custom_expand_layer_2_insert_copy_NLAll_copy_NLAll
2024-06-13 05:11:52,111 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.pooling.AveragePooling3D object at 0x7f51200de350>
2024-06-13 05:11:52,211 logger.py[line:35] INFO Converting output shape (None, 1, 1, 1, 25) to actual shape [None, 1, 1, 1, 25]
[DEBUG] Inserting layer: <keras.layers.core.repeat_vector.RepeatVector object at 0x7f51200f3d90>
2024-06-13 05:11:52,240 logger.py[line:35] INFO Converting output shape (None, 2, 25) to actual shape [None, 25]
[DEBUG] Inserting layer: <keras.layers.core.permute.Permute object at 0x7f51200fba10>
2024-06-13 05:11:52,250 logger.py[line:35] INFO Converting output shape (None, 25, 2) to actual shape [None, 2, 25]
2024-06-13 05:11:52,269 recurrent_v2.py[line:1127] WARNING Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.recurrent_v2.LSTM object at 0x7f5120117050>
2024-06-13 05:11:52,361 logger.py[line:35] INFO Converting output shape (None, 25, 50) to actual shape [None, 25, 2]
model outputs {'dense_1_copy_NLAll_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_NLAll')>}
2024-06-13 05:11:52,401 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:11:53,002 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:11:53,014 recurrent_v2.py[line:1127] WARNING Layer lstm_insert will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 36/2170
The Configuration Coverage is: 140/2049
The NDims Coverage Is: 23/117
The DType Coverage Is: 27/354
The Shape Coverage Is: 51/295
The Input Coverage Is: 101/766
2024-06-13 05:11:53,292 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:11:53,738 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (50) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:12:02,966 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 9s
2024-06-13 05:12:02,967 logger.py[line:35] INFO lstm2-NLAll38-NLAll58-NLAll6 crash on backend pytorch when predicting
2024-06-13 05:12:02,988 logger.py[line:35] INFO coverage_c=12531
2024-06-13 05:12:03,090 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-NLAll58-NLAll6
2024-06-13 05:12:03,090 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:12:03,090 logger.py[line:35] INFO after_prediction
2024-06-13 05:12:03,212 logger.py[line:35] INFO INFO: Mutation progress 7/100
2024-06-13 05:12:03,212 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:12:03,212 logger.py[line:35] INFO Score for NLAll is: 0.8857142857142857
2024-06-13 05:12:03,212 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:12:03,212 logger.py[line:35] INFO Score for MDtype is: 0.8571428571428571
2024-06-13 05:12:03,212 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:12:03,212 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:12:03,212 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:12:03,212 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:12:03,212 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:12:03,212 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:12:03,213 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:12:03,213 logger.py[line:35] INFO Choose seed: densenet121-MDims75
2024-06-13 05:12:03,213 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:12:08,541 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_MDims': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MDims_copy_NLAll')>}
2024-06-13 05:12:11,049 logger.py[line:35] INFO Insert 4 out of 18 Global New Layers
2024-06-13 05:12:11,050 logger.py[line:35] INFO insert TimeDistributed after conv2_block5_1_bn_copy_MDims_copy_NLAll
2024-06-13 05:12:11,050 logger.py[line:35] INFO insert SeparableConv2D after conv4_block6_0_bn_copy_MDims_copy_NLAll
2024-06-13 05:12:11,051 logger.py[line:35] INFO insert SpatialDropout2D after conv3_block3_1_conv_copy_MDims_copy_NLAll
2024-06-13 05:12:11,051 logger.py[line:35] INFO insert ConvLSTM3D after conv4_block23_0_bn_copy_MDims_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.wrappers.TimeDistributed object at 0x7feb2c496e90>
2024-06-13 05:12:11,224 logger.py[line:35] INFO Converting output shape (None, 56, 56, 128) to actual shape [None, 56, 56, 128]
[DEBUG] Inserting layer: <keras.layers.core.spatial_dropout.SpatialDropout2D object at 0x7feb2c414b90>
2024-06-13 05:12:11,355 logger.py[line:35] INFO Converting output shape (None, 28, 28, 128) to actual shape [None, 28, 28, 128]
[DEBUG] Inserting layer: <keras.layers.convolutional.SeparableConv2D object at 0x7feb2c32f0d0>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/initializers/initializers_v2.py", line 674, in __call__
    'Identity matrix initializer can only be used for 2D matrices. '
ValueError: Identity matrix initializer can only be used for 2D matrices. Received: shape=(1, 1, 416, 416) of rank 4.
2024-06-13 05:12:12,464 logger.py[line:35] INFO INFO: Mutation progress 7/100
2024-06-13 05:12:12,464 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:12:12,464 logger.py[line:35] INFO Score for NLAll is: 0.8857142857142857
2024-06-13 05:12:12,465 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:12:12,465 logger.py[line:35] INFO Score for MDtype is: 0.8571428571428571
2024-06-13 05:12:12,465 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:12:12,465 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:12:12,465 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:12:12,465 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:12:12,465 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:12:12,465 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:12:12,465 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:12:12,465 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-NLAll54-NLAll124-MDtype127
2024-06-13 05:12:12,465 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:12:15,290 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:12:15,992 logger.py[line:35] INFO Generating model using MDtype
2024-06-13 05:12:15,995 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_MDtype')>}
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 91, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dtype(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 403, in mutate_dtype
    mode=mutation_mode
  File "/root/implementations/scripts/tools/architecture_utils.py", line 990, in choose_layers_for_mdtype
    current_dtype_set = set(input_diversity[layer_class]["dtype"])
KeyError: 'GlobalMaxPooling3D'
2024-06-13 05:12:16,629 logger.py[line:35] INFO INFO: Mutation progress 7/100
2024-06-13 05:12:16,629 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:12:16,629 logger.py[line:35] INFO Score for NLAll is: 0.8857142857142857
2024-06-13 05:12:16,629 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:12:16,629 logger.py[line:35] INFO Score for MDtype is: 0.8571428571428571
2024-06-13 05:12:16,629 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:12:16,629 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:12:16,629 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:12:16,629 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:12:16,629 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:12:16,629 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:12:16,630 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:12:16,630 logger.py[line:35] INFO Choose seed: mobilenet.v2-MParam43
2024-06-13 05:12:16,630 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:12:20,462 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype')>}
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 91, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dtype(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 403, in mutate_dtype
    mode=mutation_mode
  File "/root/implementations/scripts/tools/architecture_utils.py", line 990, in choose_layers_for_mdtype
    current_dtype_set = set(input_diversity[layer_class]["dtype"])
KeyError: 'DepthwiseConv2D'
2024-06-13 05:12:21,735 logger.py[line:35] INFO INFO: Mutation progress 7/100
2024-06-13 05:12:21,735 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:12:21,735 logger.py[line:35] INFO Score for NLAll is: 0.8857142857142857
2024-06-13 05:12:21,735 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:12:21,735 logger.py[line:35] INFO Score for MDtype is: 0.8571428571428571
2024-06-13 05:12:21,735 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:12:21,735 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:12:21,735 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:12:21,735 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:12:21,735 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:12:21,735 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:12:21,736 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:12:21,736 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4
2024-06-13 05:12:21,736 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:12:28,962 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype')>}
2024-06-13 05:12:32,415 logger.py[line:35] INFO Change 3 Layer's DType Out Of 5 Layer classes
2024-06-13 05:12:32,415 logger.py[line:35] INFO Changing 3 out of 5 Layer's DType.
2024-06-13 05:12:32,417 logger.py[line:35] INFO Selecting a Global DType float16 For Layer max_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype
2024-06-13 05:12:32,419 logger.py[line:35] INFO Selecting a Global DType half For Layer average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype
2024-06-13 05:12:32,422 logger.py[line:35] INFO Selecting a Global DType float32 For Layer batch_normalization_16_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype')>}
2024-06-13 05:12:36,184 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 36/2170
The Configuration Coverage is: 140/2049
The NDims Coverage Is: 23/117
The DType Coverage Is: 29/354
The Shape Coverage Is: 51/295
The Input Coverage Is: 103/766
2024-06-13 05:12:42,425 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:12:42,874 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (1044) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:13:42,917 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 1m, 0s
2024-06-13 05:13:42,917 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MDtype7 crash on backend pytorch when predicting
2024-06-13 05:13:42,939 logger.py[line:35] INFO coverage_c=12531
2024-06-13 05:13:42,991 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MDtype7
2024-06-13 05:13:42,991 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:13:42,991 logger.py[line:35] INFO after_prediction
2024-06-13 05:13:43,165 logger.py[line:35] INFO INFO: Mutation progress 8/100
2024-06-13 05:13:43,165 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:13:43,165 logger.py[line:35] INFO Score for NLAll is: 0.8857142857142857
2024-06-13 05:13:43,165 logger.py[line:35] INFO Score for Edge is: 0.8584905660377359
2024-06-13 05:13:43,165 logger.py[line:35] INFO Score for MDtype is: 0.8515625
2024-06-13 05:13:43,166 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:13:43,166 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:13:43,166 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:13:43,166 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:13:43,166 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:13:43,166 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:13:43,166 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:13:43,166 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-NLAll99
2024-06-13 05:13:43,166 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:13:47,350 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge')>}
Choosing 10 To Insert
2024-06-13 05:13:48,343 logger.py[line:35] INFO Insert 8 Global New Edges
2024-06-13 05:13:48,344 logger.py[line:35] INFO Insert 2 Local New Edges
2024-06-13 05:13:48,344 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'ZeroPadding2D')
2024-06-13 05:13:49,338 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'ZeroPadding2D'] by Connecting conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge
2024-06-13 05:13:50,259 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'ZeroPadding2D'] by Connecting conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge
2024-06-13 05:13:50,259 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'GlobalMaxPooling2D')
2024-06-13 05:13:51,459 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'GlobalMaxPooling2D'] by Connecting pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and global_max_pooling2d_insert_copy_Edge
2024-06-13 05:13:52,379 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'GlobalMaxPooling2D'] by Connecting pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and global_max_pooling2d_insert_copy_Edge
2024-06-13 05:13:52,379 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'GlobalMaxPooling2D')
2024-06-13 05:13:53,391 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'GlobalMaxPooling2D'] by Connecting conv4_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and global_max_pooling2d_insert_copy_Edge_2
2024-06-13 05:13:54,301 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'GlobalMaxPooling2D'] by Connecting conv4_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and global_max_pooling2d_insert_copy_Edge_2
2024-06-13 05:13:54,302 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'GlobalMaxPooling2D')
2024-06-13 05:13:55,484 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'GlobalMaxPooling2D'] by Connecting conv4_block6_2_bn_copy_LMerg_merge1_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and global_max_pooling2d_insert_copy_Edge_1
2024-06-13 05:13:56,405 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'GlobalMaxPooling2D'] by Connecting conv4_block6_2_bn_copy_LMerg_merge1_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and global_max_pooling2d_insert_copy_Edge_1
2024-06-13 05:13:56,405 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'GlobalMaxPooling2D')
2024-06-13 05:13:57,406 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'GlobalMaxPooling2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and global_max_pooling2d_insert_copy_Edge_2_2
2024-06-13 05:13:58,508 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'GlobalMaxPooling2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and global_max_pooling2d_insert_copy_Edge_2_2
2024-06-13 05:13:58,508 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'GlobalAveragePooling2D')
2024-06-13 05:13:59,517 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'GlobalAveragePooling2D'] by Connecting conv4_block3_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge
2024-06-13 05:14:00,431 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'GlobalAveragePooling2D'] by Connecting conv4_block3_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge
2024-06-13 05:14:00,431 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'GlobalAveragePooling2D')
2024-06-13 05:14:01,433 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'GlobalAveragePooling2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge_1
2024-06-13 05:14:02,526 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'GlobalAveragePooling2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge_1
2024-06-13 05:14:02,526 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'MaxPooling2D')
2024-06-13 05:14:03,541 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'MaxPooling2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge
2024-06-13 05:14:04,461 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'MaxPooling2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge
2024-06-13 05:14:04,461 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'MaxPooling2D')
2024-06-13 05:14:05,669 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'MaxPooling2D'] by Connecting conv4_block3_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge_1
2024-06-13 05:14:06,591 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'MaxPooling2D'] by Connecting conv4_block3_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge_1
2024-06-13 05:14:06,591 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'BatchNormalization')
2024-06-13 05:14:07,606 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'BatchNormalization'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge_2 and conv3_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge
2024-06-13 05:14:08,534 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'BatchNormalization'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge_2 and conv3_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_Edge
2024-06-13 05:14:08,697 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 45/2170
The Configuration Coverage is: 142/2049
The NDims Coverage Is: 24/117
The DType Coverage Is: 30/354
The Shape Coverage Is: 56/295
The Input Coverage Is: 110/766
2024-06-13 05:14:10,713 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:14:11,161 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:14:39,352 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:14:39,352 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
TypeError: max() received an invalid combination of arguments - got (Tensor, dim=tuple, keepdim=bool), but expected one of:
 * (Tensor input)
 * (Tensor input, Tensor other, *, Tensor out)
 * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)
 * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:14:42,776 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 31s
2024-06-13 05:14:42,776 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-NLAll99-Edge8 crash on backend pytorch when predicting
2024-06-13 05:14:42,798 logger.py[line:35] INFO coverage_c=12653
2024-06-13 05:14:42,851 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-NLAll99-Edge8
2024-06-13 05:14:42,851 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:14:42,852 logger.py[line:35] INFO after_prediction
2024-06-13 05:14:42,999 logger.py[line:35] INFO INFO: Mutation progress 9/100
2024-06-13 05:14:42,999 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:14:42,999 logger.py[line:35] INFO Score for NLAll is: 0.8857142857142857
2024-06-13 05:14:42,999 logger.py[line:35] INFO Score for Edge is: 0.8518518518518519
2024-06-13 05:14:42,999 logger.py[line:35] INFO Score for MDtype is: 0.8515625
2024-06-13 05:14:43,000 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:14:43,000 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:14:43,000 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:14:43,000 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:14:43,000 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:14:43,000 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:14:43,000 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:14:43,000 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91
2024-06-13 05:14:43,000 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:14:45,824 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:14:46,441 logger.py[line:35] INFO Generating model using MDtype
2024-06-13 05:14:46,444 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDtype')>}
2024-06-13 05:14:46,624 logger.py[line:35] INFO Change 1 Layer's DType Out Of 4 Layer classes
2024-06-13 05:14:46,624 logger.py[line:35] INFO Changing 1 out of 4 Layer's DType.
2024-06-13 05:14:46,624 logger.py[line:35] INFO Selecting a Global DType float16 For Layer up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDtype
2024-06-13 05:14:46,627 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDtype')>}
2024-06-13 05:14:46,825 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:14:47,447 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 45/2170
The Configuration Coverage is: 142/2049
The NDims Coverage Is: 24/117
The DType Coverage Is: 31/354
The Shape Coverage Is: 56/295
The Input Coverage Is: 111/766
2024-06-13 05:14:47,645 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:14:48,089 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (47) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:14:56,015 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 7s
2024-06-13 05:14:56,016 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-MDtype9 crash on backend pytorch when predicting
2024-06-13 05:14:56,038 logger.py[line:35] INFO coverage_c=12653
2024-06-13 05:14:56,141 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-MDtype9
2024-06-13 05:14:56,141 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:14:56,141 logger.py[line:35] INFO after_prediction
2024-06-13 05:14:56,263 logger.py[line:35] INFO INFO: Mutation progress 10/100
2024-06-13 05:14:56,263 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:14:56,263 logger.py[line:35] INFO Score for NLAll is: 0.8857142857142857
2024-06-13 05:14:56,263 logger.py[line:35] INFO Score for Edge is: 0.8518518518518519
2024-06-13 05:14:56,263 logger.py[line:35] INFO Score for MDtype is: 0.8461538461538461
2024-06-13 05:14:56,263 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:14:56,263 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:14:56,263 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:14:56,263 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:14:56,263 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:14:56,263 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:14:56,264 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:14:56,264 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42
2024-06-13 05:14:56,264 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:15:00,508 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll')>}
2024-06-13 05:15:01,975 logger.py[line:35] INFO Insert 10 out of 16 Global New Layers
2024-06-13 05:15:01,976 logger.py[line:35] INFO insert SeparableConv2D after conv5_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:15:01,976 logger.py[line:35] INFO insert TimeDistributed after conv4_block6_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:15:01,976 logger.py[line:35] INFO insert ConvLSTM1D after conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:15:01,976 logger.py[line:35] INFO insert LayerNormalization after conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:15:01,977 logger.py[line:35] INFO insert GaussianNoise after conv4_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:15:01,977 logger.py[line:35] INFO insert ActivityRegularization after conv3_block2_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:15:01,977 logger.py[line:35] INFO insert ThresholdedReLU after conv5_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:15:01,977 logger.py[line:35] INFO insert PReLU after conv4_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:15:01,978 logger.py[line:35] INFO insert LeakyReLU after conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:15:01,978 logger.py[line:35] INFO insert AlphaDropout after conv3_block2_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:15:01,978 logger.py[line:35] INFO Insert 1 out of 14 Local New Layers
2024-06-13 05:15:01,978 logger.py[line:35] INFO insert GlobalMaxPooling2D after cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.advanced_activations.LeakyReLU object at 0x7f9f30651fd0>
2024-06-13 05:15:01,985 logger.py[line:35] INFO Converting output shape (None, 230, 230, 3) to actual shape [None, 230, 230, 3]
[DEBUG] Inserting layer: <keras.layers.noise.AlphaDropout object at 0x7f9f30553a50>
2024-06-13 05:15:02,271 logger.py[line:35] INFO Converting output shape (None, 28, 28, 512) to actual shape [None, 28, 28, 512]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.PReLU object at 0x7f9f304c0b90>
2024-06-13 05:15:02,424 logger.py[line:35] INFO Converting output shape (None, 14, 14, 256) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.noise.GaussianNoise object at 0x7f9f304c0510>
2024-06-13 05:15:02,560 logger.py[line:35] INFO Converting output shape (None, 14, 14, 256) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.wrappers.TimeDistributed object at 0x7f9f30394590>
2024-06-13 05:15:02,735 logger.py[line:35] INFO Converting output shape (None, 14, 14, 1024) to actual shape [None, 14, 14, 1024]
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 62, in new_layer_addition
    layer_list = selected_layer(output_shape)
  File "/root/implementations/scripts/generation/layer_pools.py", line 463, in conv_lstm_1d
    inserted_layer = ConfigurationUtils.random_config(candidate_layer)
  File "/root/implementations/scripts/generation/layer_pools.py", line 57, in random_config
    new_layer = layer.from_config(layer_config)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 970, in from_config
    return cls(**config)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 1134, in __init__
    **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 842, in __init__
    **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 141, in __init__
    'Unrolling is not possible with convolutional RNNs. '
TypeError: Unrolling is not possible with convolutional RNNs. Received: unroll=True
2024-06-13 05:15:03,474 logger.py[line:35] INFO INFO: Mutation progress 10/100
2024-06-13 05:15:03,474 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:15:03,474 logger.py[line:35] INFO Score for NLAll is: 0.8857142857142857
2024-06-13 05:15:03,474 logger.py[line:35] INFO Score for Edge is: 0.8518518518518519
2024-06-13 05:15:03,475 logger.py[line:35] INFO Score for MDtype is: 0.8461538461538461
2024-06-13 05:15:03,475 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:15:03,475 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:15:03,475 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:15:03,475 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:15:03,475 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:15:03,475 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:15:03,475 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:15:03,475 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype58-Edge78
2024-06-13 05:15:03,475 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:15:07,506 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_Edge_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_Edge_copy_MDtype')>, 'avg_pool_copy_Edge_2_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_Edge_copy_MDtype')>, 'pool1_pool_copy_Edge_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 4, 4, 512) dtype=float32 (created by layer 'pool1_pool_copy_Edge_copy_MDtype_copy_Edge_2_copy_MDtype')>, 'pool1_pad_copy_Edge_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 12, 12, 512) dtype=float32 (created by layer 'pool1_pad_copy_Edge_copy_MDtype_copy_Edge_2_copy_MDtype')>}
2024-06-13 05:15:08,490 logger.py[line:35] INFO Change 3 Layer's DType Out Of 6 Layer classes
2024-06-13 05:15:08,490 logger.py[line:35] INFO Changing 3 out of 6 Layer's DType.
2024-06-13 05:15:08,491 logger.py[line:35] INFO Selecting a Global DType double For Layer conv3_block4_3_conv_copy_Edge_copy_MDtype_copy_Edge_copy_MDtype
2024-06-13 05:15:08,492 logger.py[line:35] INFO Selecting a Global DType float16 For Layer pool1_pool_copy_Edge_copy_MDtype_copy_Edge_2_copy_MDtype
2024-06-13 05:15:08,492 logger.py[line:35] INFO Selecting a Global DType float16 For Layer conv1_pad_copy_Edge_copy_MDtype_copy_Edge_copy_MDtype
model outputs {'predictions_copy_Edge_copy_MDtype_copy_Edge_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_Edge_copy_MDtype')>, 'avg_pool_copy_Edge_2_copy_MDtype_copy_Edge_copy_MDtype': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_Edge_copy_MDtype')>, 'pool1_pool_copy_Edge_copy_MDtype_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 4, 4, 512) dtype=float32 (created by layer 'custom_cast_layer_5')>, 'pool1_pad_copy_Edge_copy_MDtype_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 12, 12, 512) dtype=float32 (created by layer 'pool1_pad_copy_Edge_copy_MDtype_copy_Edge_2_copy_MDtype')>}
2024-06-13 05:15:09,497 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 46/2170
The Configuration Coverage is: 142/2049
The NDims Coverage Is: 24/117
The DType Coverage Is: 32/354
The Shape Coverage Is: 56/295
The Input Coverage Is: 112/766
2024-06-13 05:15:11,570 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:15:12,013 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:15:41,601 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:15:41,601 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[103, 6, 227, 227] to have 3 channels, but got 6 channels instead

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:15:44,019 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 32s
2024-06-13 05:15:44,019 logger.py[line:35] INFO resnet50-Edge65-MDtype58-Edge78-MDtype10 crash on backend pytorch when predicting
2024-06-13 05:15:44,041 logger.py[line:35] INFO coverage_c=12659
2024-06-13 05:15:44,096 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-Edge65-MDtype58-Edge78-MDtype10
2024-06-13 05:15:44,096 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:15:44,096 logger.py[line:35] INFO after_prediction
2024-06-13 05:15:44,226 logger.py[line:35] INFO INFO: Mutation progress 11/100
2024-06-13 05:15:44,226 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:15:44,226 logger.py[line:35] INFO Score for NLAll is: 0.8857142857142857
2024-06-13 05:15:44,226 logger.py[line:35] INFO Score for Edge is: 0.8518518518518519
2024-06-13 05:15:44,226 logger.py[line:35] INFO Score for MDtype is: 0.8409090909090909
2024-06-13 05:15:44,226 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:15:44,226 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:15:44,226 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:15:44,226 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:15:44,226 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:15:44,226 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:15:44,226 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:15:44,227 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype60
2024-06-13 05:15:44,227 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:15:47,541 logger.py[line:35] INFO Generating model using MDtype
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype')>}
2024-06-13 05:15:47,646 logger.py[line:35] INFO Change 3 Layer's DType Out Of 5 Layer classes
2024-06-13 05:15:47,646 logger.py[line:35] INFO Changing 3 out of 5 Layer's DType.
2024-06-13 05:15:47,646 logger.py[line:35] INFO Selecting a Global DType float64 For Layer dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype
2024-06-13 05:15:47,646 logger.py[line:35] INFO Selecting a Global DType double For Layer max_pooling2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype
2024-06-13 05:15:47,646 logger.py[line:35] INFO Selecting a Global DType half For Layer conv2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype')>}
2024-06-13 05:15:47,781 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 46/2170
The Configuration Coverage is: 142/2049
The NDims Coverage Is: 24/117
The DType Coverage Is: 33/354
The Shape Coverage Is: 56/295
The Input Coverage Is: 113/766
2024-06-13 05:15:48,598 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:15:49,043 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (35) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:16:09,034 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 19s
2024-06-13 05:16:09,034 logger.py[line:35] INFO alexnet-SpecialI120-MDims44-MDtype60-MDtype11 crash on backend pytorch when predicting
2024-06-13 05:16:09,056 logger.py[line:35] INFO coverage_c=12659
2024-06-13 05:16:09,109 logger.py[line:35] INFO Fail on backend: pytorch of model alexnet-SpecialI120-MDims44-MDtype60-MDtype11
2024-06-13 05:16:09,109 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:16:09,109 logger.py[line:35] INFO after_prediction
2024-06-13 05:16:09,226 logger.py[line:35] INFO INFO: Mutation progress 12/100
2024-06-13 05:16:09,226 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:16:09,226 logger.py[line:35] INFO Score for NLAll is: 0.8857142857142857
2024-06-13 05:16:09,226 logger.py[line:35] INFO Score for Edge is: 0.8518518518518519
2024-06-13 05:16:09,226 logger.py[line:35] INFO Score for MDtype is: 0.835820895522388
2024-06-13 05:16:09,226 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:16:09,226 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:16:09,226 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:16:09,226 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:16:09,226 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:16:09,226 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:16:09,226 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:16:09,226 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype58
2024-06-13 05:16:09,226 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:16:13,336 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_Edge_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_NLAll')>, 'cropping2d_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'cropping2d_copy_MDtype_copy_NLAll')>, 'avg_pool_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_NLAll')>}
2024-06-13 05:16:14,653 logger.py[line:35] INFO Insert 3 out of 16 Global New Layers
2024-06-13 05:16:14,654 logger.py[line:35] INFO insert ThresholdedReLU after conv4_block3_3_bn_copy_Edge_copy_MDtype_copy_NLAll
2024-06-13 05:16:14,654 logger.py[line:35] INFO insert Softmax after conv4_block3_1_conv_copy_Edge_copy_MDtype_copy_NLAll
2024-06-13 05:16:14,654 logger.py[line:35] INFO insert SeparableConv2D after conv4_block2_2_conv_copy_Edge_copy_MDtype_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.convolutional.SeparableConv2D object at 0x7f55206bcc50>
2024-06-13 05:16:15,165 logger.py[line:35] INFO Converting output shape (None, 256, 11, 254) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.Softmax object at 0x7f55207e9d50>
2024-06-13 05:16:15,311 logger.py[line:35] INFO Converting output shape (None, 14, 14, 256) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ThresholdedReLU object at 0x7f5520631550>
2024-06-13 05:16:15,353 logger.py[line:35] INFO Converting output shape (None, 14, 14, 1024) to actual shape [None, 14, 14, 1024]
model outputs {'predictions_copy_Edge_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_NLAll')>, 'cropping2d_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'cropping2d_copy_MDtype_copy_NLAll')>, 'avg_pool_copy_Edge_2_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_NLAll')>}
2024-06-13 05:16:15,778 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 50/2170
The Configuration Coverage is: 162/2049
The NDims Coverage Is: 27/117
The DType Coverage Is: 36/354
The Shape Coverage Is: 59/295
The Input Coverage Is: 122/766
2024-06-13 05:16:17,861 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:16:18,306 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:16:45,463 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:16:45,464 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/batchnorm.py", line 65, in forward
    return self.bnu.forward(X)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 179, in forward
    self.eps,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2283, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: running_mean should contain 254 elements not 256

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:16:50,013 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 31s
2024-06-13 05:16:50,014 logger.py[line:35] INFO resnet50-Edge65-MDtype58-NLAll12 crash on backend pytorch when predicting
2024-06-13 05:16:50,035 logger.py[line:35] INFO coverage_c=13067
2024-06-13 05:16:50,091 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-Edge65-MDtype58-NLAll12
2024-06-13 05:16:50,091 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:16:50,092 logger.py[line:35] INFO after_prediction
2024-06-13 05:16:50,223 logger.py[line:35] INFO INFO: Mutation progress 13/100
2024-06-13 05:16:50,223 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:16:50,223 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:16:50,223 logger.py[line:35] INFO Score for Edge is: 0.8518518518518519
2024-06-13 05:16:50,223 logger.py[line:35] INFO Score for MDtype is: 0.835820895522388
2024-06-13 05:16:50,223 logger.py[line:35] INFO Score for MDims is: 0.8289473684210527
2024-06-13 05:16:50,223 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:16:50,223 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:16:50,223 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:16:50,223 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:16:50,223 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:16:50,224 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:16:50,224 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99
2024-06-13 05:16:50,224 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:16:57,571 logger.py[line:35] INFO Generating model using MDims
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MDims')>}
2024-06-13 05:17:01,202 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 05:17:01,202 logger.py[line:35] INFO Global Layer Class: 1; Local Layer Class: 0; Total Layer Class: 1
2024-06-13 05:17:01,202 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 05:17:01,205 logger.py[line:35] INFO Selecting a Global NDims 5 For Layer batch_normalization_6_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MDims
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MDims': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MDims')>}
2024-06-13 05:17:05,063 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 50/2170
The Configuration Coverage is: 164/2049
The NDims Coverage Is: 28/117
The DType Coverage Is: 36/354
The Shape Coverage Is: 59/295
The Input Coverage Is: 123/766
2024-06-13 05:17:11,251 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:17:11,697 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (1044) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:18:12,036 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 1m, 0s
2024-06-13 05:18:12,037 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99-MDims13 crash on backend pytorch when predicting
2024-06-13 05:18:12,058 logger.py[line:35] INFO coverage_c=13067
2024-06-13 05:18:12,115 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99-MDims13
2024-06-13 05:18:12,115 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:18:12,115 logger.py[line:35] INFO after_prediction
2024-06-13 05:18:12,340 logger.py[line:35] INFO INFO: Mutation progress 14/100
2024-06-13 05:18:12,341 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:18:12,341 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:18:12,341 logger.py[line:35] INFO Score for Edge is: 0.8518518518518519
2024-06-13 05:18:12,341 logger.py[line:35] INFO Score for MDtype is: 0.835820895522388
2024-06-13 05:18:12,341 logger.py[line:35] INFO Score for MParam is: 0.8269230769230769
2024-06-13 05:18:12,341 logger.py[line:35] INFO Score for MDims is: 0.8205128205128205
2024-06-13 05:18:12,341 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:18:12,341 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:18:12,341 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:18:12,341 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:18:12,341 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:18:12,341 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype64
2024-06-13 05:18:12,341 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:18:15,674 logger.py[line:35] INFO Generating model using MParam
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam')>}
2024-06-13 05:18:15,778 logger.py[line:35] INFO Changing 2/5 of layer batch_normalization_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam's configuration
2024-06-13 05:18:15,778 logger.py[line:35] INFO changing config momentum in layer batch_normalization_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from 0.99 to 0.932301967985678
2024-06-13 05:18:15,779 logger.py[line:35] INFO changing config scale in layer batch_normalization_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from True to False
2024-06-13 05:18:15,779 logger.py[line:35] INFO changing config epsilon in layer batch_normalization_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from 0.001 to 0.17155193386076772
2024-06-13 05:18:15,779 logger.py[line:35] INFO Changing 1/1 of layer flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam's configuration
2024-06-13 05:18:15,779 logger.py[line:35] INFO changing config data_format in layer flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from channels_last to channels_first
2024-06-13 05:18:15,779 logger.py[line:35] INFO Changing 1/15 of layer conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam's configuration
2024-06-13 05:18:15,779 logger.py[line:35] INFO changing config strides in layer conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from (2, 2) to [3, 2]
2024-06-13 05:18:15,779 logger.py[line:35] INFO changing config use_bias in layer conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from True to True
2024-06-13 05:18:15,779 logger.py[line:35] INFO Changing 3/4 of layer max_pooling2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam's configuration
2024-06-13 05:18:15,779 logger.py[line:35] INFO changing config data_format in layer max_pooling2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from channels_last to channels_first
2024-06-13 05:18:15,779 logger.py[line:35] INFO changing config strides in layer max_pooling2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from (2, 2) to [2, 3]
2024-06-13 05:18:15,779 logger.py[line:35] INFO changing config pool_size in layer max_pooling2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from (3, 3) to [1, 3]
2024-06-13 05:18:15,779 logger.py[line:35] INFO changing config padding in layer max_pooling2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from valid to same
2024-06-13 05:18:15,779 logger.py[line:35] INFO Changing 3/4 of layer max_pooling2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam's configuration
2024-06-13 05:18:15,779 logger.py[line:35] INFO changing config strides in layer max_pooling2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from (2, 2) to None
2024-06-13 05:18:15,780 logger.py[line:35] INFO changing config pool_size in layer max_pooling2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from (2, 2) to [3, 2]
2024-06-13 05:18:15,780 logger.py[line:35] INFO changing config padding in layer max_pooling2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from valid to same
2024-06-13 05:18:15,780 logger.py[line:35] INFO changing config data_format in layer max_pooling2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from channels_last to channels_first
2024-06-13 05:18:15,780 logger.py[line:35] INFO Changing 3/4 of layer max_pooling2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam's configuration
2024-06-13 05:18:15,780 logger.py[line:35] INFO changing config pool_size in layer max_pooling2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from (3, 3) to [7, 1]
2024-06-13 05:18:15,780 logger.py[line:35] INFO changing config padding in layer max_pooling2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from valid to same
2024-06-13 05:18:15,780 logger.py[line:35] INFO changing config strides in layer max_pooling2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from (2, 2) to None
2024-06-13 05:18:15,780 logger.py[line:35] INFO changing config data_format in layer max_pooling2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam: from channels_last to channels_first
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MParam')>}
2024-06-13 05:18:15,904 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 50/2170
The Configuration Coverage is: 176/2049
The NDims Coverage Is: 28/117
The DType Coverage Is: 36/354
The Shape Coverage Is: 60/295
The Input Coverage Is: 124/766
2024-06-13 05:18:16,721 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:18:17,164 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (38) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:18:39,057 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 21s
2024-06-13 05:18:39,057 logger.py[line:35] INFO alexnet-SpecialI120-MDims44-MDtype64-MParam14 crash on backend pytorch when predicting
2024-06-13 05:18:39,079 logger.py[line:35] INFO coverage_c=13067
2024-06-13 05:18:39,133 logger.py[line:35] INFO Fail on backend: pytorch of model alexnet-SpecialI120-MDims44-MDtype64-MParam14
2024-06-13 05:18:39,134 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:18:39,134 logger.py[line:35] INFO after_prediction
2024-06-13 05:18:39,249 logger.py[line:35] INFO INFO: Mutation progress 15/100
2024-06-13 05:18:39,249 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:18:39,249 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:18:39,249 logger.py[line:35] INFO Score for Edge is: 0.8518518518518519
2024-06-13 05:18:39,250 logger.py[line:35] INFO Score for MDtype is: 0.835820895522388
2024-06-13 05:18:39,250 logger.py[line:35] INFO Score for MDims is: 0.8205128205128205
2024-06-13 05:18:39,250 logger.py[line:35] INFO Score for MParam is: 0.8148148148148148
2024-06-13 05:18:39,250 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:18:39,250 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:18:39,250 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:18:39,250 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:18:39,250 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:18:39,250 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype64
2024-06-13 05:18:39,250 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:18:42,530 logger.py[line:35] INFO Generating model using MDtype
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype')>}
2024-06-13 05:18:42,636 logger.py[line:35] INFO Change 3 Layer's DType Out Of 5 Layer classes
2024-06-13 05:18:42,636 logger.py[line:35] INFO Changing 3 out of 5 Layer's DType.
2024-06-13 05:18:42,636 logger.py[line:35] INFO Selecting a Global DType float16 For Layer dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype
2024-06-13 05:18:42,636 logger.py[line:35] INFO Selecting a Global DType float32 For Layer max_pooling2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype
2024-06-13 05:18:42,636 logger.py[line:35] INFO Selecting a Global DType float16 For Layer flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype')>}
2024-06-13 05:18:42,771 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 50/2170
The Configuration Coverage is: 176/2049
The NDims Coverage Is: 28/117
The DType Coverage Is: 38/354
The Shape Coverage Is: 60/295
The Input Coverage Is: 126/766
2024-06-13 05:18:43,600 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:18:44,043 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (34) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:19:04,433 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 20s
2024-06-13 05:19:04,433 logger.py[line:35] INFO alexnet-SpecialI120-MDims44-MDtype64-MDtype15 crash on backend pytorch when predicting
2024-06-13 05:19:04,455 logger.py[line:35] INFO coverage_c=13067
2024-06-13 05:19:04,511 logger.py[line:35] INFO Fail on backend: pytorch of model alexnet-SpecialI120-MDims44-MDtype64-MDtype15
2024-06-13 05:19:04,511 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:19:04,511 logger.py[line:35] INFO after_prediction
2024-06-13 05:19:04,622 logger.py[line:35] INFO INFO: Mutation progress 16/100
2024-06-13 05:19:04,622 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:19:04,622 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:19:04,623 logger.py[line:35] INFO Score for Edge is: 0.8518518518518519
2024-06-13 05:19:04,623 logger.py[line:35] INFO Score for MDtype is: 0.8308823529411765
2024-06-13 05:19:04,623 logger.py[line:35] INFO Score for MDims is: 0.8205128205128205
2024-06-13 05:19:04,623 logger.py[line:35] INFO Score for MParam is: 0.8148148148148148
2024-06-13 05:19:04,623 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:19:04,623 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:19:04,623 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:19:04,623 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:19:04,623 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:19:04,623 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7
2024-06-13 05:19:04,623 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:19:08,867 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_Edge')>, 'cropping2d': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_Edge')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_Edge')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_Edge')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2_copy_Edge')>, 'cropping2d_1': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_1_copy_Edge')>, 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 20, 20, 256) dtype=float32 (created by layer 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_Edge')>, 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_Edge')>, 'cropping2d_2': <KerasTensor: shape=(None, 11, 11, 64) dtype=float32 (created by layer 'cropping2d_2_copy_Edge')>}
Choosing 3 To Insert
2024-06-13 05:19:09,892 logger.py[line:35] INFO Insert 3 Global New Edges
2024-06-13 05:19:09,892 logger.py[line:35] INFO Candidate Edge: ('Cropping2D', 'BatchNormalization')
2024-06-13 05:19:10,926 logger.py[line:35] INFO Trying Adding Edge: ['Cropping2D', 'BatchNormalization'] by Connecting cropping2d_2_copy_Edge and conv3_block4_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_Edge
2024-06-13 05:19:11,872 logger.py[line:35] INFO Successfully Add Edge: ['Cropping2D', 'BatchNormalization'] by Connecting cropping2d_2_copy_Edge and conv3_block4_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_Edge
2024-06-13 05:19:11,872 logger.py[line:35] INFO Candidate Edge: ('Cropping2D', 'Cropping2D')
2024-06-13 05:19:13,098 logger.py[line:35] INFO Trying Adding Edge: ['Cropping2D', 'Cropping2D'] by Connecting cropping2d_copy_Edge and cropping2d_copy_Edge
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 75, in generate_model_by_model_mutation
    return InteractionMutationUtils.connect_layers(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 209, in connect_layers
    Edge_model = ArchitectureUtils.connect_two_layers(Edge_model, layer1_name, layer2_name)
  File "/root/implementations/scripts/tools/architecture_utils.py", line 635, in connect_two_layers
    edge_output = right_cloned_layer(left_output)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional.py", line 3554, in call
    raise ValueError('Argument `cropping` must be '
ValueError: Exception encountered when calling layer "cropping2d_copy_Edge_2" (type Cropping2D).

Argument `cropping` must be greater than the input shape. Received: inputs.shape=(None, 10, 10, 64), and cropping=((26, 26), (26, 26))

Call arguments received:
   inputs=tf.Tensor(shape=(None, 10, 10, 64), dtype=float32)
2024-06-13 05:19:14,608 logger.py[line:35] INFO INFO: Mutation progress 16/100
2024-06-13 05:19:14,608 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:19:14,608 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:19:14,608 logger.py[line:35] INFO Score for Edge is: 0.8518518518518519
2024-06-13 05:19:14,608 logger.py[line:35] INFO Score for MDtype is: 0.8308823529411765
2024-06-13 05:19:14,608 logger.py[line:35] INFO Score for MDims is: 0.8205128205128205
2024-06-13 05:19:14,608 logger.py[line:35] INFO Score for MParam is: 0.8148148148148148
2024-06-13 05:19:14,608 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:19:14,608 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:19:14,609 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:19:14,609 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:19:14,609 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:19:14,609 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MDtype113-MDtype54-SpecialI59
2024-06-13 05:19:14,609 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:19:17,449 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:19:18,121 logger.py[line:35] INFO Generating model using Edge
2024-06-13 05:19:18,125 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_Edge')>}
Choosing 1 To Insert
2024-06-13 05:19:18,282 logger.py[line:35] INFO Insert 1 Global New Edges
2024-06-13 05:19:18,282 logger.py[line:35] INFO Candidate Edge: ('RepeatVector', 'LSTM')
2024-06-13 05:19:18,290 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:19:18,443 logger.py[line:35] INFO Trying Adding Edge: ['RepeatVector', 'LSTM'] by Connecting repeat_vector_insert_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_Edge and lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_Edge
2024-06-13 05:19:18,450 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:19:18,542 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:19:18,695 logger.py[line:35] INFO Successfully Add Edge: ['RepeatVector', 'LSTM'] by Connecting repeat_vector_insert_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_Edge and lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_Edge
2024-06-13 05:19:18,723 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:19:19,321 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:19:19,331 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 51/2170
The Configuration Coverage is: 176/2049
The NDims Coverage Is: 28/117
The DType Coverage Is: 38/354
The Shape Coverage Is: 61/295
The Input Coverage Is: 127/766
2024-06-13 05:19:19,585 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:19:20,028 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:19:28,606 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:19:28,607 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 208, in forward
    outputs = op((self,), activations, *in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/loop.py", line 95, in forward
    while i < M and cond:
RuntimeError: t == DeviceType::CUDAINTERNAL ASSERT FAILED at "/root/dl_libraries/pytorch/c10/cuda/impl/CUDAGuardImpl.h":24, please report a bug to PyTorch. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:19:30,907 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 10s
2024-06-13 05:19:30,907 logger.py[line:35] INFO lstm2-NLAll38-SpecialI47-MDtype113-MDtype54-SpecialI59-Edge16 crash on backend pytorch when predicting
2024-06-13 05:19:30,929 logger.py[line:35] INFO coverage_c=13471
2024-06-13 05:19:30,984 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-SpecialI47-MDtype113-MDtype54-SpecialI59-Edge16
2024-06-13 05:19:30,984 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:19:30,985 logger.py[line:35] INFO after_prediction
2024-06-13 05:19:31,094 logger.py[line:35] INFO INFO: Mutation progress 17/100
2024-06-13 05:19:31,094 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:19:31,094 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:19:31,094 logger.py[line:35] INFO Score for Edge is: 0.8454545454545455
2024-06-13 05:19:31,094 logger.py[line:35] INFO Score for MDtype is: 0.8308823529411765
2024-06-13 05:19:31,094 logger.py[line:35] INFO Score for MDims is: 0.8205128205128205
2024-06-13 05:19:31,094 logger.py[line:35] INFO Score for MParam is: 0.8148148148148148
2024-06-13 05:19:31,094 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:19:31,094 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:19:31,094 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:19:31,094 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:19:31,095 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:19:31,095 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102
2024-06-13 05:19:31,095 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:19:38,351 logger.py[line:35] INFO Generating model using LMerg
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 05:19:41,935 logger.py[line:35] INFO Insert 2 out of 5 Global New Layers
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 72, in generate_model_by_model_mutation
    return InteractionMutationUtils.merge_layers(model=model, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 165, in merge_layers
    assert len(selected_layer_name_list) == 1
AssertionError
2024-06-13 05:19:42,634 logger.py[line:35] INFO INFO: Mutation progress 17/100
2024-06-13 05:19:42,634 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:19:42,634 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:19:42,634 logger.py[line:35] INFO Score for Edge is: 0.8454545454545455
2024-06-13 05:19:42,634 logger.py[line:35] INFO Score for MDtype is: 0.8308823529411765
2024-06-13 05:19:42,634 logger.py[line:35] INFO Score for MDims is: 0.8205128205128205
2024-06-13 05:19:42,634 logger.py[line:35] INFO Score for MParam is: 0.8148148148148148
2024-06-13 05:19:42,634 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:19:42,634 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:19:42,634 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:19:42,634 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 05:19:42,635 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:19:42,635 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7
2024-06-13 05:19:42,635 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:19:46,903 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam')>, 'cropping2d': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_MParam')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_MParam')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_MParam')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2_copy_MParam')>, 'cropping2d_1': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_1_copy_MParam')>, 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 20, 20, 256) dtype=float32 (created by layer 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_MParam')>, 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_MParam')>, 'cropping2d_2': <KerasTensor: shape=(None, 11, 11, 64) dtype=float32 (created by layer 'cropping2d_2_copy_MParam')>}
2024-06-13 05:19:47,938 logger.py[line:35] INFO Changing 1/5 of layer conv3_block4_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 05:19:47,938 logger.py[line:35] INFO changing config axis in layer conv3_block4_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 05:19:47,939 logger.py[line:35] INFO changing config epsilon in layer conv3_block4_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from 1.001e-05 to 0.6770707736162288
2024-06-13 05:19:47,939 logger.py[line:35] INFO Changing 1/15 of layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 05:19:47,939 logger.py[line:35] INFO changing config padding in layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from valid to valid
2024-06-13 05:19:47,939 logger.py[line:35] INFO changing config dilation_rate in layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from (1, 1) to [3, 2]
2024-06-13 05:19:47,939 logger.py[line:35] INFO Changing 2/15 of layer conv3_block4_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 05:19:47,939 logger.py[line:35] INFO changing config activation in layer conv3_block4_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from linear to hard_sigmoid
2024-06-13 05:19:47,939 logger.py[line:35] INFO changing config bias_constraint in layer conv3_block4_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from None to UnitNorm
2024-06-13 05:19:47,939 logger.py[line:35] INFO changing config kernel_constraint in layer conv3_block4_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from None to Constraint
2024-06-13 05:19:47,939 logger.py[line:35] INFO Changing 3/15 of layer conv4_block1_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 05:19:47,939 logger.py[line:35] INFO changing config data_format in layer conv4_block1_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from channels_last to channels_first
2024-06-13 05:19:47,939 logger.py[line:35] INFO changing config filters in layer conv4_block1_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from 256 to 3
2024-06-13 05:19:47,940 logger.py[line:35] INFO changing config padding in layer conv4_block1_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from same to same
2024-06-13 05:19:47,940 logger.py[line:35] INFO changing config kernel_regularizer in layer conv4_block1_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from None to l1
2024-06-13 05:19:47,940 logger.py[line:35] INFO Changing 1/5 of layer conv4_block1_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 05:19:47,940 logger.py[line:35] INFO changing config center in layer conv4_block1_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from True to True
2024-06-13 05:19:47,940 logger.py[line:35] INFO changing config epsilon in layer conv4_block1_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from 1.001e-05 to 0.00593850598197021
2024-06-13 05:19:47,940 logger.py[line:35] INFO Changing 3/15 of layer conv5_block3_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 05:19:47,940 logger.py[line:35] INFO changing config strides in layer conv5_block3_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from (1, 1) to [1, 4]
2024-06-13 05:19:47,940 logger.py[line:35] INFO changing config dilation_rate in layer conv5_block3_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from (1, 1) to [1, 2]
2024-06-13 05:19:47,940 logger.py[line:35] INFO changing config padding in layer conv5_block3_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from same to same
2024-06-13 05:19:47,940 logger.py[line:35] INFO changing config activity_regularizer in layer conv5_block3_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from None to l1
2024-06-13 05:19:47,941 logger.py[line:35] INFO Changing 2/15 of layer conv3_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 05:19:47,941 logger.py[line:35] INFO changing config bias_constraint in layer conv3_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from None to UnitNorm
2024-06-13 05:19:47,941 logger.py[line:35] INFO changing config activation in layer conv3_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from linear to softplus
2024-06-13 05:19:47,941 logger.py[line:35] INFO changing config bias_regularizer in layer conv3_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from None to l2
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/merge.py", line 79, in _compute_elemwise_op_output_shape
    'Inputs have incompatible shapes. '
ValueError: Inputs have incompatible shapes. Received shapes (14, 14, 1024) and (3, 14, 1024)
2024-06-13 05:19:49,070 logger.py[line:35] INFO INFO: Mutation progress 17/100
2024-06-13 05:19:49,071 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:19:49,071 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:19:49,071 logger.py[line:35] INFO Score for Edge is: 0.8454545454545455
2024-06-13 05:19:49,071 logger.py[line:35] INFO Score for MDtype is: 0.8308823529411765
2024-06-13 05:19:49,071 logger.py[line:35] INFO Score for MDims is: 0.8205128205128205
2024-06-13 05:19:49,071 logger.py[line:35] INFO Score for MParam is: 0.8148148148148148
2024-06-13 05:19:49,071 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:19:49,071 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:19:49,071 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:19:49,071 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:19:49,071 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:19:49,071 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype64-Edge69
2024-06-13 05:19:49,071 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:19:52,445 logger.py[line:35] INFO Generating model using MDtype
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MDtype')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1': <KerasTensor: shape=(None, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MDtype')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2': <KerasTensor: shape=(None, 8, 8, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_copy_MDtype')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1': <KerasTensor: shape=(None, 16384) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MDtype')>, 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 1, 1, 256) dtype=float32 (created by layer 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MDtype')>, 'conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MDtype')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 8, 8, 96) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_MDtype')>, 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MDtype')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1_copy_MDtype')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2_copy_MDtype')>, 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 256) dtype=float64 (created by layer 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MDtype')>}
2024-06-13 05:19:52,590 logger.py[line:35] INFO Change 3 Layer's DType Out Of 5 Layer classes
2024-06-13 05:19:52,590 logger.py[line:35] INFO Changing 3 out of 5 Layer's DType.
2024-06-13 05:19:52,591 logger.py[line:35] INFO Selecting a Global DType float32 For Layer flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_copy_MDtype
2024-06-13 05:19:52,591 logger.py[line:35] INFO Selecting a Global DType double For Layer dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_copy_MDtype
2024-06-13 05:19:52,591 logger.py[line:35] INFO Selecting a Global DType double For Layer conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_copy_MDtype
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MDtype')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MDtype': <KerasTensor: shape=(None, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MDtype')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_copy_MDtype': <KerasTensor: shape=(None, 8, 8, 256) dtype=float32 (created by layer 'custom_cast_layer_5')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MDtype': <KerasTensor: shape=(None, 16384) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MDtype')>, 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 1, 1, 256) dtype=float32 (created by layer 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MDtype')>, 'conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MDtype')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_MDtype': <KerasTensor: shape=(None, 8, 8, 96) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_MDtype')>, 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MDtype')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1_copy_MDtype': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1_copy_MDtype')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2_copy_MDtype': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2_copy_MDtype')>, 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 3, 3, 256) dtype=float64 (created by layer 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MDtype')>}
2024-06-13 05:19:52,847 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 51/2170
The Configuration Coverage is: 176/2049
The NDims Coverage Is: 28/117
The DType Coverage Is: 38/354
The Shape Coverage Is: 61/295
The Input Coverage Is: 127/766
2024-06-13 05:19:53,910 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:19:54,356 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:20:19,379 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:20:19,380 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/batchnorm.py", line 65, in forward
    return self.bnu.forward(X)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 179, in forward
    self.eps,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2283, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: Expected weight to have type Float but got Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:20:22,657 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 28s
2024-06-13 05:20:22,657 logger.py[line:35] INFO alexnet-SpecialI120-MDims44-MDtype64-Edge69-MDtype17 crash on backend pytorch when predicting
2024-06-13 05:20:22,679 logger.py[line:35] INFO coverage_c=13504
2024-06-13 05:20:22,693 logger.py[line:35] INFO Fail on backend: pytorch of model alexnet-SpecialI120-MDims44-MDtype64-Edge69-MDtype17
2024-06-13 05:20:22,693 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:20:22,693 logger.py[line:35] INFO after_prediction
2024-06-13 05:20:22,805 logger.py[line:35] INFO INFO: Mutation progress 18/100
2024-06-13 05:20:22,805 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:20:22,805 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:20:22,805 logger.py[line:35] INFO Score for Edge is: 0.8454545454545455
2024-06-13 05:20:22,805 logger.py[line:35] INFO Score for MDtype is: 0.8260869565217391
2024-06-13 05:20:22,805 logger.py[line:35] INFO Score for MDims is: 0.8205128205128205
2024-06-13 05:20:22,805 logger.py[line:35] INFO Score for MParam is: 0.8148148148148148
2024-06-13 05:20:22,805 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:20:22,805 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:20:22,805 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:20:22,805 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:20:22,806 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:20:22,806 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MDtype113
2024-06-13 05:20:22,806 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:20:25,659 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:20:26,321 logger.py[line:35] INFO Generating model using MDims
2024-06-13 05:20:26,326 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDims')>}
2024-06-13 05:20:26,475 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 05:20:26,475 logger.py[line:35] INFO Global Layer Class: 1; Local Layer Class: 0; Total Layer Class: 1
2024-06-13 05:20:26,475 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 05:20:26,475 logger.py[line:35] INFO Selecting a Global NDims 5 For Layer dropout_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDims
2024-06-13 05:20:26,479 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDims': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDims')>}
2024-06-13 05:20:26,660 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:20:27,244 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 51/2170
The Configuration Coverage is: 176/2049
The NDims Coverage Is: 29/117
The DType Coverage Is: 38/354
The Shape Coverage Is: 61/295
The Input Coverage Is: 128/766
2024-06-13 05:20:27,425 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:20:27,869 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (41) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:20:35,594 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 7s
2024-06-13 05:20:35,594 logger.py[line:35] INFO lstm2-NLAll38-SpecialI47-MDtype113-MDims18 crash on backend pytorch when predicting
2024-06-13 05:20:35,616 logger.py[line:35] INFO coverage_c=13504
2024-06-13 05:20:35,731 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-SpecialI47-MDtype113-MDims18
2024-06-13 05:20:35,731 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:20:35,731 logger.py[line:35] INFO after_prediction
2024-06-13 05:20:35,850 logger.py[line:35] INFO INFO: Mutation progress 19/100
2024-06-13 05:20:35,851 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:20:35,851 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:20:35,851 logger.py[line:35] INFO Score for Edge is: 0.8454545454545455
2024-06-13 05:20:35,851 logger.py[line:35] INFO Score for MDtype is: 0.8260869565217391
2024-06-13 05:20:35,851 logger.py[line:35] INFO Score for MParam is: 0.8148148148148148
2024-06-13 05:20:35,851 logger.py[line:35] INFO Score for MDims is: 0.8125
2024-06-13 05:20:35,851 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:20:35,851 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:20:35,851 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:20:35,851 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:20:35,851 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:20:35,851 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-NLAll95
2024-06-13 05:20:35,851 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:20:38,714 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:20:39,810 logger.py[line:35] INFO Generating model using MParam
2024-06-13 05:20:39,813 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_MParam')>}
2024-06-13 05:20:40,475 logger.py[line:35] INFO Changing 2/21 of layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_MParam's configuration
2024-06-13 05:20:40,475 logger.py[line:35] INFO changing config recurrent_regularizer in layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_MParam: from None to l2
2024-06-13 05:20:40,475 logger.py[line:35] INFO changing config units in layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_MParam: from 25 to 1
2024-06-13 05:20:40,475 logger.py[line:35] INFO changing config recurrent_activation in layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_MParam: from hard_sigmoid to elu
2024-06-13 05:20:40,478 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:20:40,482 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_MParam': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_MParam')>}
2024-06-13 05:20:41,042 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:20:41,666 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 52/2170
The Configuration Coverage is: 179/2049
The NDims Coverage Is: 30/117
The DType Coverage Is: 39/354
The Shape Coverage Is: 64/295
The Input Coverage Is: 133/766
2024-06-13 05:20:42,204 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:20:42,654 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (60) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:20:51,481 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 8s
2024-06-13 05:20:51,482 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-NLAll95-MParam19 crash on backend pytorch when predicting
2024-06-13 05:20:51,504 logger.py[line:35] INFO coverage_c=13672
2024-06-13 05:20:51,608 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-NLAll95-MParam19
2024-06-13 05:20:51,608 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:20:51,608 logger.py[line:35] INFO after_prediction
2024-06-13 05:20:51,737 logger.py[line:35] INFO INFO: Mutation progress 20/100
2024-06-13 05:20:51,737 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:20:51,737 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:20:51,737 logger.py[line:35] INFO Score for Edge is: 0.8454545454545455
2024-06-13 05:20:51,737 logger.py[line:35] INFO Score for MDtype is: 0.8260869565217391
2024-06-13 05:20:51,737 logger.py[line:35] INFO Score for MDims is: 0.8125
2024-06-13 05:20:51,737 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:20:51,737 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:20:51,737 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:20:51,737 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:20:51,737 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:20:51,737 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:20:51,737 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-NLAll94
2024-06-13 05:20:51,737 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:20:54,604 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:20:55,333 logger.py[line:35] INFO Generating model using NLAll
2024-06-13 05:20:55,336 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll')>}
2024-06-13 05:20:55,562 logger.py[line:35] INFO Insert 7 out of 31 Global New Layers
2024-06-13 05:20:55,563 logger.py[line:35] INFO insert GlobalMaxPooling3D after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:20:55,563 logger.py[line:35] INFO insert MaxPooling3D after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:20:55,563 logger.py[line:35] INFO insert MaxPooling1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:20:55,563 logger.py[line:35] INFO insert AveragePooling1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:20:55,563 logger.py[line:35] INFO insert SimpleRNN after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:20:55,563 logger.py[line:35] INFO insert ELU after global_max_pooling1d_insert_copy_NLAll
2024-06-13 05:20:55,563 logger.py[line:35] INFO insert ZeroPadding3D after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:20:55,563 logger.py[line:35] INFO Insert 4 out of 9 Local New Layers
2024-06-13 05:20:55,563 logger.py[line:35] INFO insert ThresholdedReLU after global_max_pooling1d_insert_copy_NLAll
2024-06-13 05:20:55,563 logger.py[line:35] INFO insert UpSampling3D after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:20:55,563 logger.py[line:35] INFO insert Softmax after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:20:55,563 logger.py[line:35] INFO insert Dropout after dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:20:55,563 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 3
2024-06-13 05:20:55,564 logger.py[line:35] INFO insert LocallyConnected2D after custom_drop_dim_layer_1_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:20:55,565 logger.py[line:35] INFO insert ZeroPadding1D after custom_expand_layer_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:20:55,566 logger.py[line:35] INFO insert ConvLSTM2D after custom_expand_layer_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:20:55,569 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.convolutional.ZeroPadding1D object at 0x7f8f2064b810>
2024-06-13 05:20:55,667 logger.py[line:35] INFO Converting output shape (None, 6, 25) to actual shape [None, 1, 25]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.Softmax object at 0x7f8f2066ae50>
2024-06-13 05:20:55,704 logger.py[line:35] INFO Converting output shape (None, 1, 9, 9, 225) to actual shape [None, 1, 9, 9, 225]
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 62, in new_layer_addition
    layer_list = selected_layer(output_shape)
  File "/root/implementations/scripts/generation/layer_pools.py", line 476, in conv_lstm_2d
    inserted_layer = ConfigurationUtils.random_config(candidate_layer)
  File "/root/implementations/scripts/generation/layer_pools.py", line 57, in random_config
    new_layer = layer.from_config(layer_config)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 970, in from_config
    return cls(**config)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 1300, in __init__
    **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 842, in __init__
    **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 141, in __init__
    'Unrolling is not possible with convolutional RNNs. '
TypeError: Unrolling is not possible with convolutional RNNs. Received: unroll=True
2024-06-13 05:20:56,191 logger.py[line:35] INFO INFO: Mutation progress 20/100
2024-06-13 05:20:56,192 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:20:56,192 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:20:56,192 logger.py[line:35] INFO Score for Edge is: 0.8454545454545455
2024-06-13 05:20:56,192 logger.py[line:35] INFO Score for MDtype is: 0.8260869565217391
2024-06-13 05:20:56,192 logger.py[line:35] INFO Score for MDims is: 0.8125
2024-06-13 05:20:56,192 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:20:56,192 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:20:56,192 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:20:56,192 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:20:56,192 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:20:56,192 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:20:56,192 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7
2024-06-13 05:20:56,192 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:21:00,479 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_Edge')>, 'cropping2d': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_Edge')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_Edge')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_Edge')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2_copy_Edge')>, 'cropping2d_1': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_1_copy_Edge')>, 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 20, 20, 256) dtype=float32 (created by layer 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_Edge')>, 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_Edge')>, 'cropping2d_2': <KerasTensor: shape=(None, 11, 11, 64) dtype=float32 (created by layer 'cropping2d_2_copy_Edge')>}
Choosing 1 To Insert
2024-06-13 05:21:01,508 logger.py[line:35] INFO Insert 1 Global New Edges
2024-06-13 05:21:01,508 logger.py[line:35] INFO Candidate Edge: ('Cropping2D', 'MaxPooling2D')
2024-06-13 05:21:02,545 logger.py[line:35] INFO Trying Adding Edge: ['Cropping2D', 'MaxPooling2D'] by Connecting cropping2d_2_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_copy_Edge
2024-06-13 05:21:03,480 logger.py[line:35] INFO Successfully Add Edge: ['Cropping2D', 'MaxPooling2D'] by Connecting cropping2d_2_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_copy_Edge
2024-06-13 05:21:03,634 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 53/2170
The Configuration Coverage is: 180/2049
The NDims Coverage Is: 30/117
The DType Coverage Is: 40/354
The Shape Coverage Is: 64/295
The Input Coverage Is: 134/766
2024-06-13 05:21:05,898 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:21:06,342 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:21:41,528 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:21:41,528 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/batchnorm.py", line 65, in forward
    return self.bnu.forward(X)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 179, in forward
    self.eps,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2283, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: running_mean should contain 6 elements not 3

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:21:43,906 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 37s
2024-06-13 05:21:43,906 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7-Edge20 crash on backend pytorch when predicting
2024-06-13 05:21:43,928 logger.py[line:35] INFO coverage_c=13672
2024-06-13 05:21:43,934 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7-Edge20
2024-06-13 05:21:43,934 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:21:43,934 logger.py[line:35] INFO after_prediction
2024-06-13 05:21:44,066 logger.py[line:35] INFO INFO: Mutation progress 21/100
2024-06-13 05:21:44,066 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:21:44,066 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:21:44,066 logger.py[line:35] INFO Score for Edge is: 0.8392857142857143
2024-06-13 05:21:44,066 logger.py[line:35] INFO Score for MDtype is: 0.8260869565217391
2024-06-13 05:21:44,066 logger.py[line:35] INFO Score for MDims is: 0.8125
2024-06-13 05:21:44,066 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:21:44,066 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:21:44,066 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:21:44,066 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:21:44,066 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:21:44,066 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:21:44,066 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4
2024-06-13 05:21:44,066 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:21:51,394 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge')>}
Choosing 1 To Insert
2024-06-13 05:21:55,075 logger.py[line:35] INFO Insert 1 Global New Edges
2024-06-13 05:21:55,076 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'Conv2D')
2024-06-13 05:21:59,535 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'Conv2D'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and block35_5_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 05:22:03,074 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'Conv2D'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and block35_5_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 05:22:03,374 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 54/2170
The Configuration Coverage is: 180/2049
The NDims Coverage Is: 30/117
The DType Coverage Is: 40/354
The Shape Coverage Is: 64/295
The Input Coverage Is: 134/766
2024-06-13 05:22:09,849 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:22:10,298 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
2024-06-13 05:23:11,823 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:23:11,825 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: expected scalar type Float but found Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:23:15,443 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 1m, 5s
2024-06-13 05:23:15,443 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-Edge21 crash on backend pytorch when predicting
2024-06-13 05:23:15,465 logger.py[line:35] INFO coverage_c=13786
2024-06-13 05:23:15,521 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-Edge21
2024-06-13 05:23:15,521 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:23:15,521 logger.py[line:35] INFO after_prediction
2024-06-13 05:23:15,706 logger.py[line:35] INFO INFO: Mutation progress 22/100
2024-06-13 05:23:15,706 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:23:15,706 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:23:15,706 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:23:15,706 logger.py[line:35] INFO Score for MDtype is: 0.8260869565217391
2024-06-13 05:23:15,706 logger.py[line:35] INFO Score for MDims is: 0.8125
2024-06-13 05:23:15,707 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:23:15,707 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:23:15,707 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:23:15,707 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:23:15,707 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:23:15,707 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:23:15,707 logger.py[line:35] INFO Choose seed: alexnet-Edge76
2024-06-13 05:23:15,707 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:23:19,051 logger.py[line:35] INFO Generating model using MDims
model outputs {'dense_3_copy_Edge': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_Edge_copy_MDims')>, 'dropout_2_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'dropout_2_copy_Edge_2_copy_MDims')>}
2024-06-13 05:23:19,143 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 3 Layer classes
2024-06-13 05:23:19,143 logger.py[line:35] INFO Global Layer Class: 3; Local Layer Class: 0; Total Layer Class: 3
2024-06-13 05:23:19,143 logger.py[line:35] INFO Changing 1 out of 3 Layer's NDims.
2024-06-13 05:23:19,143 logger.py[line:35] INFO Selecting a Global NDims 3 For Layer flatten_1_copy_Edge_copy_MDims
model outputs {'dense_3_copy_Edge_copy_MDims': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_Edge_copy_MDims')>, 'dropout_2_copy_Edge_2_copy_MDims': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'dropout_2_copy_Edge_2_copy_MDims')>}
2024-06-13 05:23:19,331 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 54/2170
The Configuration Coverage is: 180/2049
The NDims Coverage Is: 31/117
The DType Coverage Is: 40/354
The Shape Coverage Is: 64/295
The Input Coverage Is: 135/766
2024-06-13 05:23:20,201 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:23:20,657 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:23:41,203 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:23:41,203 logger.py[line:35] INFO Now pytorch is using: cuda
2024-06-13 05:23:43,861 logger.py[line:35] INFO SUCCESS:Get prediction for alexnet-Edge76-MDims22 successfully on pytorch!
2024-06-13 05:23:44,605 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 23s
2024-06-13 05:23:44,605 logger.py[line:35] INFO loading the redis
2024-06-13 05:23:44,608 logger.py[line:35] INFO finish loading from redis
2024-06-13 05:23:44,630 logger.py[line:35] INFO coverage_c=14082
2024-06-13 05:23:44,725 logger.py[line:35] INFO Success on backend: pytorch of model alexnet-Edge76-MDims22
2024-06-13 05:23:44,726 logger.py[line:35] INFO Traceback (most recent call last):
  File "/root/implementations/scripts/generation/run.py", line 562, in gen
    model_name=new_model_name)
  File "/root/implementations/scripts/generation/run.py", line 432, in analyze_inference_result
    if (len(predict_output) >= 2 or len(predict_output) == len(self.backends)) and status["tensorflow"] == 0:
KeyError: 'tensorflow'

2024-06-13 05:23:44,746 logger.py[line:35] INFO INFO: Mutation progress 22/100
2024-06-13 05:23:44,746 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:23:44,746 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:23:44,746 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:23:44,746 logger.py[line:35] INFO Score for MDtype is: 0.8260869565217391
2024-06-13 05:23:44,746 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:23:44,746 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:23:44,746 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:23:44,746 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:23:44,746 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:23:44,746 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:23:44,747 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:23:44,747 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94
2024-06-13 05:23:44,747 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:23:49,100 logger.py[line:35] INFO Generating model using MDims
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDims')>}
2024-06-13 05:23:50,088 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 05:23:50,088 logger.py[line:35] INFO Global Layer Class: 1; Local Layer Class: 0; Total Layer Class: 1
2024-06-13 05:23:50,088 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 05:23:50,089 logger.py[line:35] INFO Selecting a Global NDims 3 For Layer conv5_block3_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDims
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 88, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dims(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 377, in mutate_dims
    new_model = InputMutationUtils.mdims(MDims_model, selected_layer_ndims_pair, revert_shape=True)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 349, in mdims
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 340, in mdims_layer_addition
    layer_input = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/normalization/batch_normalization.py", line 313, in build
    f'Invalid axis. Expected 0 <= axis < inputs.rank (with '
ValueError: Invalid axis. Expected 0 <= axis < inputs.rank (with inputs.rank=3). Received: layer.axis=ListWrapper([3])
2024-06-13 05:23:51,686 logger.py[line:35] INFO INFO: Mutation progress 22/100
2024-06-13 05:23:51,687 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:23:51,687 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:23:51,687 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:23:51,687 logger.py[line:35] INFO Score for MDtype is: 0.8260869565217391
2024-06-13 05:23:51,687 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:23:51,687 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:23:51,687 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:23:51,687 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:23:51,687 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:23:51,687 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:23:51,687 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:23:51,687 logger.py[line:35] INFO Choose seed: lenet-LMerg90-NLAll105-NLAll116-Edge130-LMerg32-LMerg63
2024-06-13 05:23:51,687 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:23:55,197 logger.py[line:35] INFO Generating model using MDtype
model outputs {'dense_15_copy_LMerg_copy_NLAll_copy_NLAll_copy_Edge_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_15_copy_LMerg_copy_NLAll_copy_NLAll_copy_Edge_copy_LMerg_copy_LMerg_copy_MDtype')>, 'dot_copy_ML_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 10, 10) dtype=float32 (created by layer 'dot_copy_ML_copy_LMerg_copy_MDtype')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_1_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 14, 14, 6) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_1_copy_LMerg_copy_LMerg_copy_MDtype')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_2_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 120) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_2_copy_LMerg_copy_LMerg_copy_MDtype')>, 'elu_insert_copy_Edge_1_2_1_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 120) dtype=float32 (created by layer 'elu_insert_copy_Edge_1_2_1_copy_LMerg_copy_LMerg_copy_MDtype')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_1_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 16) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_1_copy_LMerg_copy_LMerg_copy_MDtype')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_2_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 16) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_2_copy_LMerg_copy_LMerg_copy_MDtype')>, 'concatenate_copy_ML': <KerasTensor: shape=(None, 10, 4) dtype=float32 (created by layer 'concatenate_copy_ML_copy_MDtype')>}
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 91, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dtype(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 403, in mutate_dtype
    mode=mutation_mode
  File "/root/implementations/scripts/tools/architecture_utils.py", line 990, in choose_layers_for_mdtype
    current_dtype_set = set(input_diversity[layer_class]["dtype"])
KeyError: 'ELU'
2024-06-13 05:23:55,797 logger.py[line:35] INFO INFO: Mutation progress 22/100
2024-06-13 05:23:55,797 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:23:55,797 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:23:55,797 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:23:55,797 logger.py[line:35] INFO Score for MDtype is: 0.8260869565217391
2024-06-13 05:23:55,797 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:23:55,797 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:23:55,797 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:23:55,797 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:23:55,797 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:23:55,797 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:23:55,798 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:23:55,798 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype64-Edge69
2024-06-13 05:23:55,798 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:23:59,338 logger.py[line:35] INFO Generating model using MParam
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1': <KerasTensor: shape=(None, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MParam')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2': <KerasTensor: shape=(None, 8, 8, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_copy_MParam')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1': <KerasTensor: shape=(None, 16384) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MParam')>, 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 1, 1, 256) dtype=float32 (created by layer 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 8, 8, 96) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_MParam')>, 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1_copy_MParam')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2_copy_MParam')>, 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 256) dtype=float64 (created by layer 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>}
2024-06-13 05:23:59,483 logger.py[line:35] INFO Changing 1/15 of layer conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_copy_MParam's configuration
2024-06-13 05:23:59,483 logger.py[line:35] INFO changing config dilation_rate in layer conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_copy_MParam: from (1, 1) to [3, 4]
2024-06-13 05:23:59,483 logger.py[line:35] INFO changing config kernel_constraint in layer conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_copy_MParam: from None to NonNeg
2024-06-13 05:23:59,483 logger.py[line:35] INFO Changing 1/15 of layer conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 05:23:59,483 logger.py[line:35] INFO changing config kernel_regularizer in layer conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from None to l1
2024-06-13 05:23:59,484 logger.py[line:35] INFO changing config use_bias in layer conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from True to True
2024-06-13 05:23:59,484 logger.py[line:35] INFO Changing 1/4 of layer max_pooling2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 05:23:59,484 logger.py[line:35] INFO changing config padding in layer max_pooling2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from valid to same
2024-06-13 05:23:59,484 logger.py[line:35] INFO changing config data_format in layer max_pooling2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from channels_last to channels_last
2024-06-13 05:23:59,484 logger.py[line:35] INFO Changing 2/15 of layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_copy_MParam's configuration
2024-06-13 05:23:59,484 logger.py[line:35] INFO changing config data_format in layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_copy_MParam: from channels_last to channels_first
2024-06-13 05:23:59,484 logger.py[line:35] INFO changing config activity_regularizer in layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_copy_MParam: from None to l2
2024-06-13 05:23:59,484 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 05:23:59,484 logger.py[line:35] INFO changing config strides in layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_copy_MParam: from (1, 1) to [2, 2]
2024-06-13 05:23:59,484 logger.py[line:35] INFO Changing 1/4 of layer max_pooling2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 05:23:59,485 logger.py[line:35] INFO changing config padding in layer max_pooling2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from valid to valid
2024-06-13 05:23:59,485 logger.py[line:35] INFO changing config data_format in layer max_pooling2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from channels_last to channels_first
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1939, in _create_c_op
    raise ValueError(e.message)
ValueError: Exception encountered when calling layer "max_pooling2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam" (type MaxPooling2D).

Negative dimension size caused by subtracting 3 from 2 for '{{node max_pooling2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam/MaxPool}} = MaxPool[T=DT_FLOAT, data_format="NHWC", explicit_paddings=[], ksize=[1, 3, 3, 1], padding="VALID", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,384,2,256].

Call arguments received:
   inputs=tf.Tensor(shape=(None, 384, 2, 256), dtype=float32)
2024-06-13 05:24:00,002 logger.py[line:35] INFO INFO: Mutation progress 22/100
2024-06-13 05:24:00,002 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:24:00,002 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:24:00,002 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:24:00,003 logger.py[line:35] INFO Score for MDtype is: 0.8260869565217391
2024-06-13 05:24:00,003 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:24:00,003 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:24:00,003 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:24:00,003 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:24:00,003 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:24:00,003 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:24:00,003 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:24:00,003 logger.py[line:35] INFO Choose seed: lenet-LMerg90-NLAll105-NLAll116-Edge130-LMerg32-LMerg63
2024-06-13 05:24:00,003 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:24:03,568 logger.py[line:35] INFO Generating model using MDims
model outputs {'dense_15_copy_LMerg_copy_NLAll_copy_NLAll_copy_Edge_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_15_copy_LMerg_copy_NLAll_copy_NLAll_copy_Edge_copy_LMerg_copy_LMerg_copy_MDims')>, 'dot_copy_ML_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 10, 10) dtype=float32 (created by layer 'dot_copy_ML_copy_LMerg_copy_MDims')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_1_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 14, 14, 6) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_1_copy_LMerg_copy_LMerg_copy_MDims')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_2_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 120) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_2_copy_LMerg_copy_LMerg_copy_MDims')>, 'elu_insert_copy_Edge_1_2_1_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 120) dtype=float32 (created by layer 'elu_insert_copy_Edge_1_2_1_copy_LMerg_copy_LMerg_copy_MDims')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_1_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 16) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_1_copy_LMerg_copy_LMerg_copy_MDims')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_2_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 16) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_2_copy_LMerg_copy_LMerg_copy_MDims')>, 'concatenate_copy_ML': <KerasTensor: shape=(None, 10, 4) dtype=float32 (created by layer 'concatenate_copy_ML_copy_MDims')>}
2024-06-13 05:24:03,731 logger.py[line:35] INFO Change 4 Layer's Dimension Out Of 8 Layer classes
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 88, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dims(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 375, in mutate_dims
    mode=mutation_mode
  File "/root/implementations/scripts/tools/architecture_utils.py", line 1059, in choose_layers_for_mdims
    current_ndims_set = set(input_diversity[layer_class]["ndims"])
KeyError: 'ELU'
2024-06-13 05:24:04,181 logger.py[line:35] INFO INFO: Mutation progress 22/100
2024-06-13 05:24:04,181 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:24:04,181 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:24:04,181 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:24:04,181 logger.py[line:35] INFO Score for MDtype is: 0.8260869565217391
2024-06-13 05:24:04,181 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:24:04,181 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:24:04,181 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:24:04,181 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:24:04,181 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:24:04,181 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:24:04,182 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:24:04,182 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype58-Edge78
2024-06-13 05:24:04,182 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:24:08,330 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_Edge_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_Edge_copy_MDtype')>, 'avg_pool_copy_Edge_2_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_Edge_copy_MDtype')>, 'pool1_pool_copy_Edge_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 4, 4, 512) dtype=float32 (created by layer 'pool1_pool_copy_Edge_copy_MDtype_copy_Edge_2_copy_MDtype')>, 'pool1_pad_copy_Edge_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 12, 12, 512) dtype=float32 (created by layer 'pool1_pad_copy_Edge_copy_MDtype_copy_Edge_2_copy_MDtype')>}
2024-06-13 05:24:09,314 logger.py[line:35] INFO Change 3 Layer's DType Out Of 6 Layer classes
2024-06-13 05:24:09,314 logger.py[line:35] INFO Changing 3 out of 6 Layer's DType.
2024-06-13 05:24:09,315 logger.py[line:35] INFO Selecting a Global DType float32 For Layer pool1_pool_copy_Edge_copy_MDtype_copy_Edge_1_copy_MDtype
2024-06-13 05:24:09,316 logger.py[line:35] INFO Selecting a Global DType float32 For Layer conv1_pad_copy_Edge_copy_MDtype_copy_Edge_copy_MDtype
2024-06-13 05:24:09,316 logger.py[line:35] INFO Selecting a Global DType float16 For Layer cropping2d_copy_MDtype_copy_Edge_copy_MDtype
model outputs {'predictions_copy_Edge_copy_MDtype_copy_Edge_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_Edge_copy_MDtype')>, 'avg_pool_copy_Edge_2_copy_MDtype_copy_Edge_copy_MDtype': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_Edge_copy_MDtype')>, 'pool1_pool_copy_Edge_copy_MDtype_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 4, 4, 512) dtype=float32 (created by layer 'pool1_pool_copy_Edge_copy_MDtype_copy_Edge_2_copy_MDtype')>, 'pool1_pad_copy_Edge_copy_MDtype_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 12, 12, 512) dtype=float32 (created by layer 'pool1_pad_copy_Edge_copy_MDtype_copy_Edge_2_copy_MDtype')>}
2024-06-13 05:24:10,323 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 54/2170
The Configuration Coverage is: 180/2049
The NDims Coverage Is: 31/117
The DType Coverage Is: 41/354
The Shape Coverage Is: 64/295
The Input Coverage Is: 136/766
2024-06-13 05:24:12,441 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:24:12,893 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:24:42,736 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:24:42,736 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: expected scalar type Float but found Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:24:48,554 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 35s
2024-06-13 05:24:48,554 logger.py[line:35] INFO resnet50-Edge65-MDtype58-Edge78-MDtype22 crash on backend pytorch when predicting
2024-06-13 05:24:48,575 logger.py[line:35] INFO coverage_c=14245
2024-06-13 05:24:48,680 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-Edge65-MDtype58-Edge78-MDtype22
2024-06-13 05:24:48,681 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:24:48,681 logger.py[line:35] INFO after_prediction
2024-06-13 05:24:48,817 logger.py[line:35] INFO INFO: Mutation progress 23/100
2024-06-13 05:24:48,817 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:24:48,817 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:24:48,817 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:24:48,817 logger.py[line:35] INFO Score for MDtype is: 0.8214285714285714
2024-06-13 05:24:48,817 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:24:48,817 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:24:48,818 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:24:48,818 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:24:48,818 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:24:48,818 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:24:48,818 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:24:48,818 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82
2024-06-13 05:24:48,818 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:24:53,265 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge')>}
Choosing 1 To Insert
2024-06-13 05:24:54,352 logger.py[line:35] INFO Insert 1 Global New Edges
2024-06-13 05:24:54,352 logger.py[line:35] INFO Candidate Edge: ('Cropping2D', 'Cropping2D')
2024-06-13 05:24:55,428 logger.py[line:35] INFO Trying Adding Edge: ['Cropping2D', 'Cropping2D'] by Connecting cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 75, in generate_model_by_model_mutation
    return InteractionMutationUtils.connect_layers(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 209, in connect_layers
    Edge_model = ArchitectureUtils.connect_two_layers(Edge_model, layer1_name, layer2_name)
  File "/root/implementations/scripts/tools/architecture_utils.py", line 635, in connect_two_layers
    edge_output = right_cloned_layer(left_output)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional.py", line 3554, in call
    raise ValueError('Argument `cropping` must be '
ValueError: Exception encountered when calling layer "cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge_2" (type Cropping2D).

Argument `cropping` must be greater than the input shape. Received: inputs.shape=(None, 10, 10, 256), and cropping=((10, 10), (10, 10))

Call arguments received:
   inputs=tf.Tensor(shape=(None, 10, 10, 256), dtype=float32)
2024-06-13 05:24:57,037 logger.py[line:35] INFO INFO: Mutation progress 23/100
2024-06-13 05:24:57,038 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:24:57,038 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:24:57,038 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:24:57,038 logger.py[line:35] INFO Score for MDtype is: 0.8214285714285714
2024-06-13 05:24:57,038 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:24:57,038 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:24:57,038 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:24:57,038 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:24:57,038 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:24:57,038 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:24:57,038 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:24:57,038 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7
2024-06-13 05:24:57,038 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:25:01,439 logger.py[line:35] INFO Generating model using MDims
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MDims')>, 'cropping2d': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_MDims')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_MDims')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_MDims')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2_copy_MDims')>, 'cropping2d_1': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_1_copy_MDims')>, 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 20, 20, 256) dtype=float32 (created by layer 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_MDims')>, 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_MDims')>, 'cropping2d_2': <KerasTensor: shape=(None, 11, 11, 64) dtype=float32 (created by layer 'cropping2d_2_copy_MDims')>}
2024-06-13 05:25:02,478 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 05:25:02,478 logger.py[line:35] INFO Global Layer Class: 1; Local Layer Class: 0; Total Layer Class: 1
2024-06-13 05:25:02,479 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 05:25:02,480 logger.py[line:35] INFO Selecting a Global NDims 3 For Layer conv4_block2_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MDims
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 88, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dims(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 377, in mutate_dims
    new_model = InputMutationUtils.mdims(MDims_model, selected_layer_ndims_pair, revert_shape=True)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 349, in mdims
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 340, in mdims_layer_addition
    layer_input = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/normalization/batch_normalization.py", line 313, in build
    f'Invalid axis. Expected 0 <= axis < inputs.rank (with '
ValueError: Invalid axis. Expected 0 <= axis < inputs.rank (with inputs.rank=3). Received: layer.axis=ListWrapper([3])
2024-06-13 05:25:03,707 logger.py[line:35] INFO INFO: Mutation progress 23/100
2024-06-13 05:25:03,708 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:25:03,708 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:25:03,708 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:25:03,708 logger.py[line:35] INFO Score for MDtype is: 0.8214285714285714
2024-06-13 05:25:03,708 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:25:03,708 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:25:03,708 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:25:03,708 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:25:03,708 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:25:03,708 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:25:03,708 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:25:03,708 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81
2024-06-13 05:25:03,708 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:25:11,074 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype')>}
2024-06-13 05:25:14,705 logger.py[line:35] INFO Change 2 Layer's DType Out Of 5 Layer classes
2024-06-13 05:25:14,705 logger.py[line:35] INFO Changing 2 out of 5 Layer's DType.
2024-06-13 05:25:14,708 logger.py[line:35] INFO Selecting a Global DType float16 For Layer max_pooling2d_4_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype
2024-06-13 05:25:14,710 logger.py[line:35] INFO Selecting a Global DType float16 For Layer batch_normalization_196_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype')>}
2024-06-13 05:25:18,511 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 54/2170
The Configuration Coverage is: 180/2049
The NDims Coverage Is: 31/117
The DType Coverage Is: 42/354
The Shape Coverage Is: 64/295
The Input Coverage Is: 137/766
2024-06-13 05:25:24,800 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:25:25,245 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (1049) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:26:25,334 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 1m, 0s
2024-06-13 05:26:25,334 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81-MDtype23 crash on backend pytorch when predicting
2024-06-13 05:26:25,356 logger.py[line:35] INFO coverage_c=14245
2024-06-13 05:26:25,363 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81-MDtype23
2024-06-13 05:26:25,363 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:26:25,363 logger.py[line:35] INFO after_prediction
2024-06-13 05:26:25,537 logger.py[line:35] INFO INFO: Mutation progress 24/100
2024-06-13 05:26:25,538 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:26:25,538 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:26:25,538 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:26:25,538 logger.py[line:35] INFO Score for MDtype is: 0.8169014084507042
2024-06-13 05:26:25,538 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:26:25,538 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:26:25,538 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:26:25,538 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:26:25,538 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:26:25,538 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:26:25,538 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:26:25,538 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-NLAll54-NLAll124-MDtype127
2024-06-13 05:26:25,538 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:26:28,435 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:26:29,208 logger.py[line:35] INFO Generating model using NLAll
2024-06-13 05:26:29,211 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll')>}
2024-06-13 05:26:29,475 logger.py[line:35] INFO Insert 10 out of 34 Global New Layers
2024-06-13 05:26:29,475 logger.py[line:35] INFO insert GlobalAveragePooling1D after repeat_vector_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,475 logger.py[line:35] INFO insert Conv3DTranspose after gaussian_dropout_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,475 logger.py[line:35] INFO insert DepthwiseConv2D after up_sampling2d_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,475 logger.py[line:35] INFO insert TimeDistributed after separable_conv1d_insert_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,475 logger.py[line:35] INFO insert AlphaDropout after conv3d_transpose_insert_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,475 logger.py[line:35] INFO insert Conv1D after separable_conv1d_insert_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,475 logger.py[line:35] INFO insert GaussianDropout after softmax_insert_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,475 logger.py[line:35] INFO insert UpSampling1D after repeat_vector_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,475 logger.py[line:35] INFO insert GRU after repeat_vector_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,476 logger.py[line:35] INFO insert PReLU after up_sampling2d_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,476 logger.py[line:35] INFO Insert 4 out of 24 Local New Layers
2024-06-13 05:26:29,476 logger.py[line:35] INFO insert UpSampling3D after up_sampling3d_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,476 logger.py[line:35] INFO insert UpSampling2D after up_sampling2d_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,476 logger.py[line:35] INFO insert SeparableConv2D after up_sampling2d_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,476 logger.py[line:35] INFO insert Flatten after gaussian_dropout_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,476 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 3
2024-06-13 05:26:29,477 logger.py[line:35] INFO insert ReLU after custom_expand_layer_2_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,479 logger.py[line:35] INFO insert ActivityRegularization after global_max_pooling3d_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,479 logger.py[line:35] INFO insert GlobalAveragePooling3D after conv3d_transpose_insert_copy_MDtype_copy_NLAll
2024-06-13 05:26:29,482 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.core.activity_regularization.ActivityRegularization object at 0x7fc44c286890>
2024-06-13 05:26:29,588 logger.py[line:35] INFO Converting output shape (None, 1) to actual shape [None, 1]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ReLU object at 0x7fc474f96d10>
2024-06-13 05:26:29,600 logger.py[line:35] INFO Converting output shape (None, 1, 1, 1, 1) to actual shape [None, 1, 1, 1, 1]
[DEBUG] Inserting layer: <keras.layers.convolutional.UpSampling3D object at 0x7fc44c231b10>
2024-06-13 05:26:29,621 logger.py[line:35] INFO Converting output shape (None, 3, 27, 27, 225) to actual shape [None, 1, 9, 9, 225]
[DEBUG] Inserting layer: <keras.layers.core.flatten.Flatten object at 0x7fc44c235e90>
2024-06-13 05:26:29,629 logger.py[line:35] INFO Converting output shape (None, 18225) to actual shape [None, 1, 9, 9, 225]
[DEBUG] Inserting layer: <keras.layers.pooling.GlobalAveragePooling3D object at 0x7fc44c2670d0>
2024-06-13 05:26:29,665 logger.py[line:35] INFO Converting output shape (None, 1) to actual shape [None, 1, 9, 9, 225]
[DEBUG] Inserting layer: <keras.layers.convolutional.SeparableConv2D object at 0x7fc44c2b4a90>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/initializers/initializers_v2.py", line 674, in __call__
    'Identity matrix initializer can only be used for 2D matrices. '
ValueError: Identity matrix initializer can only be used for 2D matrices. Received: shape=(1, 1, 225, 225) of rank 4.
2024-06-13 05:26:30,147 logger.py[line:35] INFO INFO: Mutation progress 24/100
2024-06-13 05:26:30,147 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:26:30,147 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:26:30,147 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:26:30,147 logger.py[line:35] INFO Score for MDtype is: 0.8169014084507042
2024-06-13 05:26:30,147 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:26:30,147 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:26:30,147 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:26:30,147 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:26:30,147 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:26:30,147 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:26:30,148 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:26:30,148 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102
2024-06-13 05:26:30,148 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:26:37,531 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 05:26:42,326 logger.py[line:35] INFO Insert 10 out of 13 Global New Layers
2024-06-13 05:26:42,328 logger.py[line:35] INFO insert ELU after batch_normalization_182_copy_MParam_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:26:42,328 logger.py[line:35] INFO insert LeakyReLU after max_pooling2d_3_copy_MParam_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:26:42,329 logger.py[line:35] INFO insert TimeDistributed after conv2d_115_copy_MParam_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:26:42,330 logger.py[line:35] INFO insert Conv2DTranspose after conv2d_113_copy_MParam_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:26:42,330 logger.py[line:35] INFO insert AlphaDropout after batch_normalization_168_copy_MParam_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:26:42,331 logger.py[line:35] INFO insert LayerNormalization after conv2d_120_copy_MParam_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:26:42,332 logger.py[line:35] INFO insert ConvLSTM1D after conv2d_93_copy_MParam_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:26:42,332 logger.py[line:35] INFO insert GaussianDropout after conv2d_152_copy_MParam_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:26:42,333 logger.py[line:35] INFO insert DepthwiseConv2D after conv2d_35_copy_MParam_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:26:42,334 logger.py[line:35] INFO insert GaussianNoise after conv2d_55_copy_MParam_copy_MDtype_copy_MDtype_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.convolutional.DepthwiseConv2D object at 0x7f32d4736090>
2024-06-13 05:26:42,835 logger.py[line:35] INFO Converting output shape (None, 35, 27, 48) to actual shape [None, 35, 35, 48]
[DEBUG] Inserting layer: <keras.layers.noise.GaussianNoise object at 0x7f32d45c66d0>
2024-06-13 05:26:43,281 logger.py[line:35] INFO Converting output shape (None, 35, 35, 32) to actual shape [None, 35, 35, 32]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.LeakyReLU object at 0x7f32d44b31d0>
2024-06-13 05:26:43,574 logger.py[line:35] INFO Converting output shape (None, 17, 17, 320) to actual shape [None, 17, 17, 320]
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 62, in new_layer_addition
    layer_list = selected_layer(output_shape)
  File "/root/implementations/scripts/generation/layer_pools.py", line 463, in conv_lstm_1d
    inserted_layer = ConfigurationUtils.random_config(candidate_layer)
  File "/root/implementations/scripts/generation/layer_pools.py", line 57, in random_config
    new_layer = layer.from_config(layer_config)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 970, in from_config
    return cls(**config)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 1134, in __init__
    **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 842, in __init__
    **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 141, in __init__
    'Unrolling is not possible with convolutional RNNs. '
TypeError: Unrolling is not possible with convolutional RNNs. Received: unroll=True
2024-06-13 05:26:44,781 logger.py[line:35] INFO INFO: Mutation progress 24/100
2024-06-13 05:26:44,781 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:26:44,781 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:26:44,782 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:26:44,782 logger.py[line:35] INFO Score for MDtype is: 0.8169014084507042
2024-06-13 05:26:44,782 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:26:44,782 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:26:44,782 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:26:44,782 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:26:44,782 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:26:44,782 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:26:44,782 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:26:44,782 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MDtype4-NLAll12-NLAll32-NLAll93-NLAll-1
2024-06-13 05:26:44,782 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:26:49,413 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam')>}
2024-06-13 05:26:50,509 logger.py[line:35] INFO Changing 2/5 of layer conv5_block2_2_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam's configuration
2024-06-13 05:26:50,509 logger.py[line:35] INFO changing config momentum in layer conv5_block2_2_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from 0.99 to 0.41811084543577237
2024-06-13 05:26:50,509 logger.py[line:35] INFO changing config epsilon in layer conv5_block2_2_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from 1.001e-05 to 0.020588052904665144
2024-06-13 05:26:50,510 logger.py[line:35] INFO changing config scale in layer conv5_block2_2_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from True to False
2024-06-13 05:26:50,510 logger.py[line:35] INFO Changing 1/1 of layer softmax_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam's configuration
2024-06-13 05:26:50,510 logger.py[line:35] INFO changing config axis in layer softmax_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from -2 to -2
2024-06-13 05:26:50,510 logger.py[line:35] INFO Changing 1/16 of layer conv2d_transpose_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam's configuration
2024-06-13 05:26:50,510 logger.py[line:35] INFO changing config use_bias in layer conv2d_transpose_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from False to False
2024-06-13 05:26:50,510 logger.py[line:35] INFO changing config bias_initializer in layer conv2d_transpose_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from {'class_name': 'TruncatedNormal', 'config': {'mean': 0.0, 'stddev': 0.05, 'seed': None}} to Ones
2024-06-13 05:26:50,510 logger.py[line:35] INFO Changing 3/5 of layer conv4_block4_2_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam's configuration
2024-06-13 05:26:50,510 logger.py[line:35] INFO changing config momentum in layer conv4_block4_2_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from 0.99 to 0.2767620768451653
2024-06-13 05:26:50,510 logger.py[line:35] INFO changing config center in layer conv4_block4_2_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from True to True
2024-06-13 05:26:50,511 logger.py[line:35] INFO changing config epsilon in layer conv4_block4_2_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from 1.001e-05 to 0.6861230567478768
2024-06-13 05:26:50,511 logger.py[line:35] INFO changing config scale in layer conv4_block4_2_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from True to True
2024-06-13 05:26:50,511 logger.py[line:35] INFO Changing 1/15 of layer conv5_block2_2_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam's configuration
2024-06-13 05:26:50,511 logger.py[line:35] INFO changing config activity_regularizer in layer conv5_block2_2_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from None to l2
2024-06-13 05:26:50,511 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 05:26:50,511 logger.py[line:35] INFO changing config use_bias in layer conv5_block2_2_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from True to True
2024-06-13 05:26:50,511 logger.py[line:35] INFO Changing 1/1 of layer softmax_insert_copy_MParam's configuration
2024-06-13 05:26:50,511 logger.py[line:35] INFO changing config axis in layer softmax_insert_copy_MParam: from -1 to -2
2024-06-13 05:26:50,511 logger.py[line:35] INFO Changing 1/15 of layer conv3_block2_2_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam's configuration
2024-06-13 05:26:50,511 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 05:26:50,511 logger.py[line:35] INFO changing config activity_regularizer in layer conv3_block2_2_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from None to l2
2024-06-13 05:26:50,511 logger.py[line:35] INFO changing config strides in layer conv3_block2_2_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from (1, 1) to [4, 1]
2024-06-13 05:26:50,511 logger.py[line:35] INFO Changing 2/15 of layer conv5_block1_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam's configuration
2024-06-13 05:26:50,512 logger.py[line:35] INFO changing config use_bias in layer conv5_block1_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from True to False
2024-06-13 05:26:50,512 logger.py[line:35] INFO changing config bias_initializer in layer conv5_block1_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from {'class_name': 'Zeros', 'config': {}} to Zeros
2024-06-13 05:26:50,512 logger.py[line:35] INFO changing config kernel_constraint in layer conv5_block1_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MParam: from None to UnitNorm
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/merge.py", line 79, in _compute_elemwise_op_output_shape
    'Inputs have incompatible shapes. '
ValueError: Inputs have incompatible shapes. Received shapes (28, 28, 512) and (7, 28, 512)
2024-06-13 05:26:51,525 logger.py[line:35] INFO INFO: Mutation progress 24/100
2024-06-13 05:26:51,525 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:26:51,525 logger.py[line:35] INFO Score for NLAll is: 0.8802816901408451
2024-06-13 05:26:51,525 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:26:51,525 logger.py[line:35] INFO Score for MDtype is: 0.8169014084507042
2024-06-13 05:26:51,525 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:26:51,525 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:26:51,525 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:26:51,525 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:26:51,525 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:26:51,525 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:26:51,526 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:26:51,526 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-LMerg10-NLAll66
2024-06-13 05:26:51,526 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:26:55,643 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_LMerg_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll')>}
2024-06-13 05:26:56,891 logger.py[line:35] INFO Insert 9 out of 13 Global New Layers
2024-06-13 05:26:56,891 logger.py[line:35] INFO insert DepthwiseConv2D after conv2_block1_1_bn_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll
2024-06-13 05:26:56,891 logger.py[line:35] INFO insert GaussianNoise after conv2_block1_0_bn_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll
2024-06-13 05:26:56,892 logger.py[line:35] INFO insert TimeDistributed after conv3_block1_3_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll
2024-06-13 05:26:56,892 logger.py[line:35] INFO insert GaussianDropout after conv2_block1_1_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll
2024-06-13 05:26:56,892 logger.py[line:35] INFO insert SpatialDropout2D after conv5_block2_1_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll
2024-06-13 05:26:56,892 logger.py[line:35] INFO insert ConvLSTM1D after conv5_block2_3_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll
2024-06-13 05:26:56,893 logger.py[line:35] INFO insert AlphaDropout after conv3_block2_1_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll
2024-06-13 05:26:56,893 logger.py[line:35] INFO insert Conv2DTranspose after conv3_block2_3_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll
2024-06-13 05:26:56,893 logger.py[line:35] INFO insert LayerNormalization after conv2_block2_1_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.noise.GaussianDropout object at 0x7ff82072f910>
2024-06-13 05:26:56,927 logger.py[line:35] INFO Converting output shape (None, 56, 56, 64) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <keras.layers.convolutional.DepthwiseConv2D object at 0x7ff8206c2350>
2024-06-13 05:26:56,954 logger.py[line:35] INFO Converting output shape (None, 56, 50, 59) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <keras.layers.noise.GaussianNoise object at 0x7ff82063c250>
2024-06-13 05:26:57,037 logger.py[line:35] INFO Converting output shape (None, 56, 56, 256) to actual shape [None, 56, 56, 256]
[DEBUG] Inserting layer: <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x7ff820695910>
2024-06-13 05:26:57,076 logger.py[line:35] INFO Converting output shape (None, 56, 56, 64) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <keras.layers.wrappers.TimeDistributed object at 0x7ff8205c9e50>
2024-06-13 05:26:57,218 logger.py[line:35] INFO Converting output shape (None, 28, 28, 512) to actual shape [None, 28, 28, 512]
[DEBUG] Inserting layer: <keras.layers.noise.AlphaDropout object at 0x7ff820585110>
2024-06-13 05:26:57,246 logger.py[line:35] INFO Converting output shape (None, 28, 28, 128) to actual shape [None, 28, 28, 128]
[DEBUG] Inserting layer: <keras.layers.convolutional.Conv2DTranspose object at 0x7ff8205a5290>
2024-06-13 05:26:57,301 logger.py[line:35] INFO Converting output shape (None, 31, 36, 512) to actual shape [None, 28, 28, 512]
[DEBUG] Inserting layer: <keras.layers.core.spatial_dropout.SpatialDropout2D object at 0x7ff820601050>
2024-06-13 05:26:57,860 logger.py[line:35] INFO Converting output shape (None, 7, 7, 512) to actual shape [None, 7, 7, 512]
[DEBUG] Inserting layer: <keras.layers.convolutional_recurrent.ConvLSTM1D object at 0x7ff7c8613c50>
2024-06-13 05:29:30,548 logger.py[line:35] INFO Converting output shape (None, 7, 1, 2048) to actual shape [None, 7, 7, 2048]
model outputs {'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll')>}
2024-06-13 05:29:30,721 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 69/2170
The Configuration Coverage is: 246/2049
The NDims Coverage Is: 41/117
The DType Coverage Is: 51/354
The Shape Coverage Is: 74/295
The Input Coverage Is: 166/766
2024-06-13 05:32:05,795 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:32:06,244 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 58, in <module>
    transform_onnx(model_path)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 41, in transform_onnx
    model = keras.models.load_model(model_path, custom_objects=custom_objects())
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/save.py", line 201, in load_model
    compile)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/hdf5_format.py", line 181, in load_model_from_hdf5
    custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/model_config.py", line 52, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 678, in deserialize_keras_object
    list(custom_objects.items())))
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 663, in from_config
    config, custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1273, in reconstruct_from_config
    process_layer(layer_data)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1255, in process_layer
    layer = deserialize_layer(layer_data, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 681, in deserialize_keras_object
    deserialized_obj = cls.from_config(cls_config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 748, in from_config
    return cls(**config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/noise.py", line 107, in __init__
    super(GaussianDropout, self).__init__(**kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 323, in __init__
    generic_utils.validate_kwargs(kwargs, allowed_kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 1143, in validate_kwargs
    raise TypeError(error_message, kwarg)
TypeError: ('Keyword argument not understood:', 'seed')
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/resnet50-LMerg2-LMerg10-NLAll66-NLAll24/resnet50-LMerg2-LMerg10-NLAll66-NLAll24.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:32:11,668 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 5s
2024-06-13 05:32:11,668 logger.py[line:35] INFO resnet50-LMerg2-LMerg10-NLAll66-NLAll24 crash on backend pytorch when predicting
2024-06-13 05:32:11,691 logger.py[line:35] INFO coverage_c=14245
2024-06-13 05:32:11,790 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-LMerg10-NLAll66-NLAll24
2024-06-13 05:32:11,790 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:32:11,790 logger.py[line:35] INFO after_prediction
2024-06-13 05:32:11,955 logger.py[line:35] INFO INFO: Mutation progress 25/100
2024-06-13 05:32:11,955 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:32:11,955 logger.py[line:35] INFO Score for NLAll is: 0.875
2024-06-13 05:32:11,955 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:32:11,955 logger.py[line:35] INFO Score for MDtype is: 0.8169014084507042
2024-06-13 05:32:11,955 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:32:11,955 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:32:11,955 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:32:11,955 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:32:11,955 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:32:11,955 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:32:11,955 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:32:11,955 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MDtype39
2024-06-13 05:32:11,955 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:32:16,208 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 05:32:17,465 logger.py[line:35] INFO Insert 4 out of 4 Global New Layers
2024-06-13 05:32:17,466 logger.py[line:35] INFO insert LeakyReLU after conv4_block2_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:32:17,466 logger.py[line:35] INFO insert ActivityRegularization after conv4_block6_2_bn_copy_LMerg_merge1_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:32:17,466 logger.py[line:35] INFO insert ELU after conv2_block2_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:32:17,466 logger.py[line:35] INFO insert PReLU after conv1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:32:17,466 logger.py[line:35] INFO Insert 2 out of 19 Local New Layers
2024-06-13 05:32:17,467 logger.py[line:35] INFO insert AveragePooling2D after conv2_block2_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:32:17,467 logger.py[line:35] INFO insert SpatialDropout2D after conv4_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.advanced_activations.PReLU object at 0x7f5528510a10>
2024-06-13 05:32:17,493 logger.py[line:35] INFO Converting output shape (None, 112, 112, 64) to actual shape [None, 112, 112, 64]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ELU object at 0x7f55c417da90>
2024-06-13 05:32:17,593 logger.py[line:35] INFO Converting output shape (None, 56, 56, 64) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <keras.layers.pooling.AveragePooling2D object at 0x7f552849dfd0>
2024-06-13 05:32:17,611 logger.py[line:35] INFO Converting output shape (None, 56, 56, 256) to actual shape [None, 56, 56, 256]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.LeakyReLU object at 0x7f55283a2890>
2024-06-13 05:32:17,954 logger.py[line:35] INFO Converting output shape (None, 14, 14, 256) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.core.spatial_dropout.SpatialDropout2D object at 0x7f55283a7ad0>
2024-06-13 05:32:17,965 logger.py[line:35] INFO Converting output shape (None, 14, 14, 256) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.core.activity_regularization.ActivityRegularization object at 0x7f55282d8e50>
2024-06-13 05:32:18,182 logger.py[line:35] INFO Converting output shape (None, 14, 14, 256) to actual shape [None, 14, 14, 256]
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 05:32:18,471 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 76/2170
The Configuration Coverage is: 255/2049
The NDims Coverage Is: 45/117
The DType Coverage Is: 55/354
The Shape Coverage Is: 80/295
The Input Coverage Is: 180/766
2024-06-13 05:32:20,508 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:32:20,952 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (149) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
Automatic inference of operator: neg
2024-06-13 05:32:45,598 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 05:32:45,599 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-MDtype39-NLAll25 crash on backend pytorch when predicting
2024-06-13 05:32:45,620 logger.py[line:35] INFO coverage_c=14245
2024-06-13 05:32:45,726 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-MDtype39-NLAll25
2024-06-13 05:32:45,726 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:32:45,726 logger.py[line:35] INFO after_prediction
2024-06-13 05:32:45,862 logger.py[line:35] INFO INFO: Mutation progress 26/100
2024-06-13 05:32:45,862 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:32:45,862 logger.py[line:35] INFO Score for NLAll is: 0.8698630136986302
2024-06-13 05:32:45,862 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:32:45,862 logger.py[line:35] INFO Score for MDtype is: 0.8169014084507042
2024-06-13 05:32:45,862 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:32:45,862 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:32:45,862 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:32:45,862 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:32:45,862 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:32:45,862 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:32:45,862 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:32:45,862 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll93
2024-06-13 05:32:45,862 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:32:59,813 logger.py[line:35] INFO Generating model using MDims
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_MDims')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_MDims')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_MDims')>, 'leaky_re_lu_insert': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_MDims')>, 'custom_pad_layer_2': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'custom_pad_layer_2_copy_MDims')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_MDims')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_MDims')>, 'spatial_dropout2d_insert': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'spatial_dropout2d_insert_copy_MDims')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_MDims')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_MDims')>}
2024-06-13 05:33:09,987 logger.py[line:35] INFO Change 2 Layer's Dimension Out Of 3 Layer classes
2024-06-13 05:33:09,987 logger.py[line:35] INFO Global Layer Class: 3; Local Layer Class: 0; Total Layer Class: 3
2024-06-13 05:33:09,987 logger.py[line:35] INFO Changing 2 out of 3 Layer's NDims.
2024-06-13 05:33:09,989 logger.py[line:35] INFO Selecting a Global NDims 3 For Layer conv4_block1_0_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_MDims
2024-06-13 05:33:09,990 logger.py[line:35] INFO Selecting a Global NDims 5 For Layer leaky_re_lu_insert_copy_MDims
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 88, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dims(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 377, in mutate_dims
    new_model = InputMutationUtils.mdims(MDims_model, selected_layer_ndims_pair, revert_shape=True)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 349, in mdims
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 340, in mdims_layer_addition
    layer_input = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/normalization/batch_normalization.py", line 313, in build
    f'Invalid axis. Expected 0 <= axis < inputs.rank (with '
ValueError: Invalid axis. Expected 0 <= axis < inputs.rank (with inputs.rank=3). Received: layer.axis=ListWrapper([3])
2024-06-13 05:33:11,892 logger.py[line:35] INFO INFO: Mutation progress 26/100
2024-06-13 05:33:11,892 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:33:11,892 logger.py[line:35] INFO Score for NLAll is: 0.8698630136986302
2024-06-13 05:33:11,892 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:33:11,892 logger.py[line:35] INFO Score for MDtype is: 0.8169014084507042
2024-06-13 05:33:11,893 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:33:11,893 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:33:11,893 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:33:11,893 logger.py[line:35] INFO Score for MShape is: 0.7222222222222222
2024-06-13 05:33:11,893 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:33:11,893 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:33:11,893 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:33:11,893 logger.py[line:35] INFO Choose seed: densenet121-MDims75
2024-06-13 05:33:11,893 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:33:17,362 logger.py[line:35] INFO Generating model using MShape
model outputs {'predictions_copy_MDims': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MDims_copy_MShape')>}
2024-06-13 05:33:19,274 logger.py[line:35] INFO Change 3 Layer's Shape Out Of 6 Layer classes
2024-06-13 05:33:19,275 logger.py[line:35] INFO Changing 1 Layer's Shape.
2024-06-13 05:33:19,276 logger.py[line:35] INFO [Globally] Changing The Input Shape Of Layer: pool3_pool_copy_MDims_copy_MShape From [None, 28, 28, 256] To [None, 5, 9, 7]
2024-06-13 05:33:19,276 logger.py[line:35] INFO Changing 2 out of 5 Layer's Shape.
2024-06-13 05:33:19,277 logger.py[line:35] INFO [Locally] Changing The Input Shape Of Layer: conv4_block22_2_conv_copy_MDims_copy_MShape From [None, 14, 14, 128] To [None, 1, 6, 1]
2024-06-13 05:33:19,279 logger.py[line:35] INFO [Locally] Changing The Input Shape Of Layer: pool1_copy_MDims_copy_MShape From [None, 114, 114, 64] To [None, 7, 9, 9]
model outputs {'predictions_copy_MDims_copy_MShape': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MDims_copy_MShape')>}
2024-06-13 05:33:21,615 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 76/2170
The Configuration Coverage is: 258/2049
The NDims Coverage Is: 46/117
The DType Coverage Is: 55/354
The Shape Coverage Is: 82/295
The Input Coverage Is: 183/766
2024-06-13 05:33:24,972 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:33:25,416 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (386) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:33:47,459 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 22s
2024-06-13 05:33:47,459 logger.py[line:35] INFO densenet121-MDims75-MShape26 crash on backend pytorch when predicting
2024-06-13 05:33:47,481 logger.py[line:35] INFO coverage_c=14245
2024-06-13 05:33:47,586 logger.py[line:35] INFO Fail on backend: pytorch of model densenet121-MDims75-MShape26
2024-06-13 05:33:47,586 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:33:47,586 logger.py[line:35] INFO after_prediction
2024-06-13 05:33:47,741 logger.py[line:35] INFO INFO: Mutation progress 27/100
2024-06-13 05:33:47,741 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:33:47,741 logger.py[line:35] INFO Score for NLAll is: 0.8698630136986302
2024-06-13 05:33:47,741 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:33:47,741 logger.py[line:35] INFO Score for MDtype is: 0.8169014084507042
2024-06-13 05:33:47,741 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:33:47,741 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:33:47,741 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:33:47,741 logger.py[line:35] INFO Score for MShape is: 0.7
2024-06-13 05:33:47,741 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:33:47,742 logger.py[line:35] INFO The last used seed is: MShape
2024-06-13 05:33:47,742 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:33:47,742 logger.py[line:35] INFO Choose seed: densenet121-MDims75
2024-06-13 05:33:47,742 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:33:53,211 logger.py[line:35] INFO Generating model using MDims
model outputs {'predictions_copy_MDims': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MDims_copy_MDims')>}
2024-06-13 05:33:55,137 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 05:33:55,138 logger.py[line:35] INFO Global Layer Class: 1; Local Layer Class: 0; Total Layer Class: 1
2024-06-13 05:33:55,138 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 05:33:55,140 logger.py[line:35] INFO Selecting a Global NDims 3 For Layer conv3_block2_1_bn_copy_MDims_copy_MDims
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 88, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dims(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 377, in mutate_dims
    new_model = InputMutationUtils.mdims(MDims_model, selected_layer_ndims_pair, revert_shape=True)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 349, in mdims
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 340, in mdims_layer_addition
    layer_input = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/normalization/batch_normalization.py", line 313, in build
    f'Invalid axis. Expected 0 <= axis < inputs.rank (with '
ValueError: Invalid axis. Expected 0 <= axis < inputs.rank (with inputs.rank=3). Received: layer.axis=ListWrapper([3])
2024-06-13 05:33:56,124 logger.py[line:35] INFO INFO: Mutation progress 27/100
2024-06-13 05:33:56,124 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:33:56,124 logger.py[line:35] INFO Score for NLAll is: 0.8698630136986302
2024-06-13 05:33:56,124 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:33:56,124 logger.py[line:35] INFO Score for MDtype is: 0.8169014084507042
2024-06-13 05:33:56,124 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:33:56,124 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:33:56,124 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:33:56,124 logger.py[line:35] INFO Score for MShape is: 0.7
2024-06-13 05:33:56,124 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:33:56,124 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:33:56,125 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:33:56,125 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-LMerg10-NLAll66
2024-06-13 05:33:56,125 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:34:00,246 logger.py[line:35] INFO Generating model using MShape
model outputs {'predictions_copy_LMerg_copy_LMerg_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_MShape')>}
2024-06-13 05:34:01,285 logger.py[line:35] INFO Change 2 Layer's Shape Out Of 6 Layer classes
2024-06-13 05:34:01,285 logger.py[line:35] INFO Changing 1 Layer's Shape.
2024-06-13 05:34:01,286 logger.py[line:35] INFO [Globally] Changing The Input Shape Of Layer: thresholded_re_lu_insert_copy_MShape From [None, 2048] To [None, 8]
2024-06-13 05:34:01,286 logger.py[line:35] INFO Changing 1 out of 5 Layer's Shape.
2024-06-13 05:34:01,286 logger.py[line:35] INFO [Locally] Changing The Input Shape Of Layer: conv1_pad_copy_LMerg_copy_LMerg_copy_NLAll_copy_MShape From [None, 224, 224, 3] To [None, 4, 3, 9]
model outputs {'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_MShape': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_MShape')>}
2024-06-13 05:34:02,370 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 76/2170
The Configuration Coverage is: 258/2049
The NDims Coverage Is: 46/117
The DType Coverage Is: 55/354
The Shape Coverage Is: 83/295
The Input Coverage Is: 184/766
2024-06-13 05:34:04,355 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:34:04,806 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (138) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:34:29,402 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 05:34:29,403 logger.py[line:35] INFO resnet50-LMerg2-LMerg10-NLAll66-MShape27 crash on backend pytorch when predicting
2024-06-13 05:34:29,425 logger.py[line:35] INFO coverage_c=14245
2024-06-13 05:34:29,476 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-LMerg10-NLAll66-MShape27
2024-06-13 05:34:29,477 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:34:29,477 logger.py[line:35] INFO after_prediction
2024-06-13 05:34:29,612 logger.py[line:35] INFO INFO: Mutation progress 28/100
2024-06-13 05:34:29,612 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:34:29,612 logger.py[line:35] INFO Score for NLAll is: 0.8698630136986302
2024-06-13 05:34:29,612 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:34:29,612 logger.py[line:35] INFO Score for MDtype is: 0.8169014084507042
2024-06-13 05:34:29,612 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:34:29,612 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:34:29,612 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:34:29,612 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:34:29,612 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:34:29,612 logger.py[line:35] INFO The last used seed is: MShape
2024-06-13 05:34:29,613 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:34:29,613 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-NLAll99
2024-06-13 05:34:29,613 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:34:33,925 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll')>}
2024-06-13 05:34:35,213 logger.py[line:35] INFO Insert 8 out of 23 Local New Layers
2024-06-13 05:34:35,213 logger.py[line:35] INFO insert LayerNormalization after conv1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:34:35,213 logger.py[line:35] INFO insert SpatialDropout2D after conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:34:35,214 logger.py[line:35] INFO insert DepthwiseConv2D after conv4_block6_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:34:35,214 logger.py[line:35] INFO insert ActivityRegularization after conv5_block1_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:34:35,214 logger.py[line:35] INFO insert UpSampling2D after conv3_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:34:35,214 logger.py[line:35] INFO insert ELU after conv4_block3_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:34:35,214 logger.py[line:35] INFO insert Flatten after conv4_block5_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:34:35,214 logger.py[line:35] INFO insert Dropout after conv2_block1_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.core.spatial_dropout.SpatialDropout2D object at 0x7f3f700b0650>
2024-06-13 05:34:35,222 logger.py[line:35] INFO Converting output shape (None, 230, 230, 3) to actual shape [None, 230, 230, 3]
[DEBUG] Inserting layer: <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x7f3f700bfc90>
2024-06-13 05:34:35,249 logger.py[line:35] INFO Converting output shape (None, 112, 112, 64) to actual shape [None, 112, 112, 64]
[DEBUG] Inserting layer: <keras.layers.core.dropout.Dropout object at 0x7f3f70077190>
2024-06-13 05:34:35,315 logger.py[line:35] INFO Converting output shape (None, 56, 56, 256) to actual shape [None, 56, 56, 256]
[DEBUG] Inserting layer: <keras.layers.convolutional.UpSampling2D object at 0x7f3f2020df50>
2024-06-13 05:34:35,443 logger.py[line:35] INFO Converting output shape (None, 28, 28, 128) to actual shape [None, 28, 28, 128]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ELU object at 0x7f3f2015f750>
2024-06-13 05:34:35,794 logger.py[line:35] INFO Converting output shape (None, 14, 14, 256) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.core.flatten.Flatten object at 0x7f3f200ebb10>
2024-06-13 05:34:35,885 logger.py[line:35] INFO Converting output shape (None, 50176) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.convolutional.DepthwiseConv2D object at 0x7f3f200a4090>
2024-06-13 05:34:35,987 logger.py[line:35] INFO Converting output shape (None, 14, 14, 1024) to actual shape [None, 14, 14, 1024]
[DEBUG] Inserting layer: <keras.layers.core.activity_regularization.ActivityRegularization object at 0x7f3ef07d5750>
2024-06-13 05:34:36,026 logger.py[line:35] INFO Converting output shape (None, 7, 7, 512) to actual shape [None, 7, 7, 512]
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll')>}
2024-06-13 05:34:36,266 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 89/2170
The Configuration Coverage is: 272/2049
The NDims Coverage Is: 46/117
The DType Coverage Is: 55/354
The Shape Coverage Is: 89/295
The Input Coverage Is: 190/766
2024-06-13 05:34:38,463 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:34:38,916 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (169) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:35:03,663 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 05:35:03,663 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-NLAll99-NLAll28 crash on backend pytorch when predicting
2024-06-13 05:35:03,684 logger.py[line:35] INFO coverage_c=14245
2024-06-13 05:35:03,786 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-NLAll99-NLAll28
2024-06-13 05:35:03,786 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:35:03,786 logger.py[line:35] INFO after_prediction
2024-06-13 05:35:03,914 logger.py[line:35] INFO INFO: Mutation progress 29/100
2024-06-13 05:35:03,914 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:35:03,914 logger.py[line:35] INFO Score for NLAll is: 0.8648648648648649
2024-06-13 05:35:03,914 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:35:03,914 logger.py[line:35] INFO Score for MDtype is: 0.8169014084507042
2024-06-13 05:35:03,915 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:35:03,915 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:35:03,915 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:35:03,915 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:35:03,915 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:35:03,915 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:35:03,915 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:35:03,915 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-LMerg10-NLAll66
2024-06-13 05:35:03,915 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:35:08,084 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_LMerg_copy_LMerg_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_MDtype')>}
2024-06-13 05:35:09,057 logger.py[line:35] INFO Change 2 Layer's DType Out Of 6 Layer classes
2024-06-13 05:35:09,057 logger.py[line:35] INFO Changing 2 out of 6 Layer's DType.
2024-06-13 05:35:09,058 logger.py[line:35] INFO Selecting a Global DType float32 For Layer thresholded_re_lu_insert_copy_MDtype
2024-06-13 05:35:09,058 logger.py[line:35] INFO Selecting a Global DType float16 For Layer pool1_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_MDtype
model outputs {'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_MDtype')>}
2024-06-13 05:35:10,044 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 89/2170
The Configuration Coverage is: 272/2049
The NDims Coverage Is: 46/117
The DType Coverage Is: 55/354
The Shape Coverage Is: 89/295
The Input Coverage Is: 190/766
2024-06-13 05:35:12,068 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:35:12,519 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (133) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:35:36,564 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 05:35:36,564 logger.py[line:35] INFO resnet50-LMerg2-LMerg10-NLAll66-MDtype29 crash on backend pytorch when predicting
2024-06-13 05:35:36,586 logger.py[line:35] INFO coverage_c=14245
2024-06-13 05:35:36,690 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-LMerg10-NLAll66-MDtype29
2024-06-13 05:35:36,690 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:35:36,690 logger.py[line:35] INFO after_prediction
2024-06-13 05:35:36,690 logger.py[line:35] INFO No representative seed generated: resnet50-LMerg2-LMerg10-NLAll66-MDtype29, do not increase the reward
2024-06-13 05:35:36,825 logger.py[line:35] INFO INFO: Mutation progress 30/100
2024-06-13 05:35:36,825 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:35:36,825 logger.py[line:35] INFO Score for NLAll is: 0.8648648648648649
2024-06-13 05:35:36,825 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:35:36,825 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:35:36,825 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:35:36,825 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:35:36,825 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:35:36,825 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:35:36,825 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:35:36,825 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:35:36,825 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:35:36,825 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82
2024-06-13 05:35:36,825 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:35:41,218 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 05:35:42,616 logger.py[line:35] INFO Insert 3 out of 28 Local New Layers
2024-06-13 05:35:42,617 logger.py[line:35] INFO insert SeparableConv2D after conv5_block1_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:35:42,617 logger.py[line:35] INFO insert AlphaDropout after conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:35:42,617 logger.py[line:35] INFO insert ELU after avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.noise.AlphaDropout object at 0x7f810829e850>
2024-06-13 05:35:43,362 logger.py[line:35] INFO Converting output shape (None, 7, 7, 512) to actual shape [None, 7, 7, 512]
[DEBUG] Inserting layer: <keras.layers.convolutional.SeparableConv2D object at 0x7f81082bbb10>
2024-06-13 05:35:43,400 logger.py[line:35] INFO Converting output shape (None, 3, 2, 512) to actual shape [None, 7, 7, 512]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ELU object at 0x7f81081afd50>
2024-06-13 05:35:43,594 logger.py[line:35] INFO Converting output shape (None, 64) to actual shape [None, 64]
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float32 (created by layer 'elu_insert')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 05:35:43,795 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 92/2170
The Configuration Coverage is: 281/2049
The NDims Coverage Is: 47/117
The DType Coverage Is: 56/354
The Shape Coverage Is: 92/295
The Input Coverage Is: 195/766
2024-06-13 05:35:46,046 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:35:46,490 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:36:21,673 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:36:21,673 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/batchnorm.py", line 65, in forward
    return self.bnu.forward(X)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 179, in forward
    self.eps,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2283, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: Expected weight to have type Float but got Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:36:25,454 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 38s
2024-06-13 05:36:25,454 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll30 crash on backend pytorch when predicting
2024-06-13 05:36:25,476 logger.py[line:35] INFO coverage_c=14245
2024-06-13 05:36:25,582 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll30
2024-06-13 05:36:25,582 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:36:25,582 logger.py[line:35] INFO after_prediction
2024-06-13 05:36:25,719 logger.py[line:35] INFO INFO: Mutation progress 31/100
2024-06-13 05:36:25,719 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:36:25,719 logger.py[line:35] INFO Score for NLAll is: 0.86
2024-06-13 05:36:25,719 logger.py[line:35] INFO Score for Edge is: 0.8333333333333334
2024-06-13 05:36:25,719 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:36:25,719 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:36:25,719 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:36:25,719 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:36:25,719 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:36:25,719 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:36:25,720 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:36:25,720 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:36:25,720 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-NLAll95
2024-06-13 05:36:25,720 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:36:28,608 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:29,703 logger.py[line:35] INFO Generating model using Edge
2024-06-13 05:36:29,706 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge')>}
Choosing 3 To Insert
2024-06-13 05:36:30,263 logger.py[line:35] INFO Insert 3 Global New Edges
2024-06-13 05:36:30,263 logger.py[line:35] INFO Candidate Edge: ('Bidirectional', 'LSTM')
2024-06-13 05:36:30,273 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:30,988 logger.py[line:35] INFO Trying Adding Edge: ['Bidirectional', 'LSTM'] by Connecting bidirectional_insert_copy_Edge and lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 05:36:30,991 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:31,091 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:31,654 logger.py[line:35] INFO Successfully Add Edge: ['Bidirectional', 'LSTM'] by Connecting bidirectional_insert_copy_Edge and lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 05:36:31,654 logger.py[line:35] INFO Candidate Edge: ('LSTM', 'RepeatVector')
2024-06-13 05:36:31,665 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:31,686 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:32,300 logger.py[line:35] INFO Trying Adding Edge: ['LSTM', 'RepeatVector'] by Connecting lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge_1 and repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 05:36:32,303 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:32,865 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:32,969 logger.py[line:35] INFO Successfully Add Edge: ['LSTM', 'RepeatVector'] by Connecting lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge_1 and repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 05:36:32,969 logger.py[line:35] INFO Candidate Edge: ('UpSampling3D', 'Dropout')
2024-06-13 05:36:32,981 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:33,000 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:33,671 logger.py[line:35] INFO Trying Adding Edge: ['UpSampling3D', 'Dropout'] by Connecting up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 05:36:33,674 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:34,512 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:34,611 logger.py[line:35] INFO Successfully Add Edge: ['UpSampling3D', 'Dropout'] by Connecting up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 05:36:34,653 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:36:35,251 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:36:35,271 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 95/2170
The Configuration Coverage is: 281/2049
The NDims Coverage Is: 47/117
The DType Coverage Is: 56/354
The Shape Coverage Is: 94/295
The Input Coverage Is: 197/766
2024-06-13 05:36:35,911 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:36:36,360 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:36:47,515 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:36:47,515 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 208, in forward
    outputs = op((self,), activations, *in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/loop.py", line 95, in forward
    while i < M and cond:
RuntimeError: t == DeviceType::CUDAINTERNAL ASSERT FAILED at "/root/dl_libraries/pytorch/c10/cuda/impl/CUDAGuardImpl.h":24, please report a bug to PyTorch. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:36:49,792 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 13s
2024-06-13 05:36:49,792 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-NLAll95-Edge31 crash on backend pytorch when predicting
2024-06-13 05:36:49,814 logger.py[line:35] INFO coverage_c=14252
2024-06-13 05:36:49,920 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-NLAll95-Edge31
2024-06-13 05:36:49,920 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:36:49,920 logger.py[line:35] INFO after_prediction
2024-06-13 05:36:50,052 logger.py[line:35] INFO INFO: Mutation progress 32/100
2024-06-13 05:36:50,052 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:36:50,052 logger.py[line:35] INFO Score for NLAll is: 0.86
2024-06-13 05:36:50,052 logger.py[line:35] INFO Score for Edge is: 0.8275862068965517
2024-06-13 05:36:50,052 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:36:50,052 logger.py[line:35] INFO Score for MParam is: 0.8035714285714286
2024-06-13 05:36:50,052 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:36:50,052 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:36:50,052 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:36:50,052 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:36:50,052 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:36:50,052 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:36:50,052 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-NLAll99-MDtype111-MDims14-SpecialI56
2024-06-13 05:36:50,052 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:36:54,476 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_MParam')>}
2024-06-13 05:36:55,509 logger.py[line:35] INFO Changing 1/5 of layer conv3_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_MParam's configuration
2024-06-13 05:36:55,509 logger.py[line:35] INFO changing config center in layer conv3_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_MParam: from True to False
2024-06-13 05:36:55,509 logger.py[line:35] INFO changing config epsilon in layer conv3_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_MParam: from 1.001e-05 to 0.13976659086341559
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_MParam')>}
2024-06-13 05:36:56,519 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 95/2170
The Configuration Coverage is: 282/2049
The NDims Coverage Is: 47/117
The DType Coverage Is: 56/354
The Shape Coverage Is: 94/295
The Input Coverage Is: 197/766
2024-06-13 05:36:58,598 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:36:59,049 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (149) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:37:23,697 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 05:37:23,697 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-NLAll99-MDtype111-MDims14-SpecialI56-MParam32 crash on backend pytorch when predicting
2024-06-13 05:37:23,719 logger.py[line:35] INFO coverage_c=14252
2024-06-13 05:37:23,817 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-NLAll99-MDtype111-MDims14-SpecialI56-MParam32
2024-06-13 05:37:23,817 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:37:23,818 logger.py[line:35] INFO after_prediction
2024-06-13 05:37:23,945 logger.py[line:35] INFO INFO: Mutation progress 33/100
2024-06-13 05:37:23,945 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:37:23,945 logger.py[line:35] INFO Score for NLAll is: 0.86
2024-06-13 05:37:23,945 logger.py[line:35] INFO Score for Edge is: 0.8275862068965517
2024-06-13 05:37:23,945 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:37:23,945 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:37:23,945 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:37:23,945 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:37:23,945 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:37:23,945 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:37:23,945 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:37:23,945 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:37:23,945 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84
2024-06-13 05:37:23,945 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:37:26,881 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:37:27,612 logger.py[line:35] INFO Generating model using MDtype
2024-06-13 05:37:27,615 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_MDtype')>}
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 91, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dtype(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 403, in mutate_dtype
    mode=mutation_mode
  File "/root/implementations/scripts/tools/architecture_utils.py", line 990, in choose_layers_for_mdtype
    current_dtype_set = set(input_diversity[layer_class]["dtype"])
KeyError: 'GlobalAveragePooling3D'
2024-06-13 05:37:28,267 logger.py[line:35] INFO INFO: Mutation progress 33/100
2024-06-13 05:37:28,268 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:37:28,268 logger.py[line:35] INFO Score for NLAll is: 0.86
2024-06-13 05:37:28,268 logger.py[line:35] INFO Score for Edge is: 0.8275862068965517
2024-06-13 05:37:28,268 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:37:28,268 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:37:28,268 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:37:28,268 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:37:28,268 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:37:28,268 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:37:28,268 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:37:28,268 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:37:28,268 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65
2024-06-13 05:37:28,268 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:37:31,178 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:37:31,892 logger.py[line:35] INFO Generating model using Edge
2024-06-13 05:37:31,895 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge')>}
Choosing 2 To Insert
2024-06-13 05:37:32,073 logger.py[line:35] INFO Insert 2 Global New Edges
2024-06-13 05:37:32,073 logger.py[line:35] INFO Candidate Edge: ('RepeatVector', 'Dropout')
2024-06-13 05:37:32,082 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:37:32,258 logger.py[line:35] INFO Trying Adding Edge: ['RepeatVector', 'Dropout'] by Connecting repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 05:37:32,261 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:37:32,441 logger.py[line:35] INFO Successfully Add Edge: ['RepeatVector', 'Dropout'] by Connecting repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 05:37:32,441 logger.py[line:35] INFO Candidate Edge: ('UpSampling3D', 'UpSampling3D')
2024-06-13 05:37:32,450 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:37:32,633 logger.py[line:35] INFO Trying Adding Edge: ['UpSampling3D', 'UpSampling3D'] by Connecting up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge and up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 05:37:32,636 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:37:32,861 logger.py[line:35] INFO Successfully Add Edge: ['UpSampling3D', 'UpSampling3D'] by Connecting up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge and up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 05:37:32,899 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:37:33,741 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 98/2170
The Configuration Coverage is: 283/2049
The NDims Coverage Is: 49/117
The DType Coverage Is: 57/354
The Shape Coverage Is: 96/295
The Input Coverage Is: 202/766
2024-06-13 05:37:33,985 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:37:34,428 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:38:03,552 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:38:03,553 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 208, in forward
    outputs = op((self,), activations, *in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/loop.py", line 95, in forward
    while i < M and cond:
RuntimeError: t == DeviceType::CUDAINTERNAL ASSERT FAILED at "/root/dl_libraries/pytorch/c10/cuda/impl/CUDAGuardImpl.h":24, please report a bug to PyTorch. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:38:05,934 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 31s
2024-06-13 05:38:05,934 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65-Edge33 crash on backend pytorch when predicting
2024-06-13 05:38:05,956 logger.py[line:35] INFO coverage_c=14252
2024-06-13 05:38:06,013 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65-Edge33
2024-06-13 05:38:06,013 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:38:06,013 logger.py[line:35] INFO after_prediction
2024-06-13 05:38:06,128 logger.py[line:35] INFO INFO: Mutation progress 34/100
2024-06-13 05:38:06,128 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:38:06,128 logger.py[line:35] INFO Score for NLAll is: 0.86
2024-06-13 05:38:06,128 logger.py[line:35] INFO Score for Edge is: 0.8220338983050848
2024-06-13 05:38:06,128 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:38:06,128 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:38:06,128 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:38:06,128 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:38:06,129 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:38:06,129 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:38:06,129 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:38:06,129 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:38:06,129 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype87
2024-06-13 05:38:06,129 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:38:10,460 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge')>}
Choosing 6 To Insert
2024-06-13 05:38:11,444 logger.py[line:35] INFO Insert 6 Local New Edges
2024-06-13 05:38:11,444 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'Conv2D')
2024-06-13 05:38:12,421 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'Conv2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv2_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 05:38:13,325 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'Conv2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv2_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 05:38:13,325 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'ZeroPadding2D')
2024-06-13 05:38:14,498 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'ZeroPadding2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 05:38:15,429 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'ZeroPadding2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 05:38:15,430 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'Conv2D')
2024-06-13 05:38:16,455 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'Conv2D'] by Connecting pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv2_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 05:38:17,394 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'Conv2D'] by Connecting pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv2_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 05:38:17,394 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'MaxPooling2D')
2024-06-13 05:38:18,610 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'MaxPooling2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 05:38:19,546 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'MaxPooling2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 05:38:19,546 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'BatchNormalization')
2024-06-13 05:38:20,569 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting conv3_block4_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv4_block2_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 05:38:21,710 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting conv3_block4_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv4_block2_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 05:38:21,710 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'ZeroPadding2D')
2024-06-13 05:38:22,750 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'ZeroPadding2D'] by Connecting pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2
2024-06-13 05:38:23,701 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'ZeroPadding2D'] by Connecting pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2
2024-06-13 05:38:23,837 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 98/2170
The Configuration Coverage is: 283/2049
The NDims Coverage Is: 49/117
The DType Coverage Is: 58/354
The Shape Coverage Is: 96/295
The Input Coverage Is: 203/766
2024-06-13 05:38:25,947 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:38:26,390 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:38:56,639 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:38:56,639 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: expected scalar type Float but found Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:38:59,948 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 33s
2024-06-13 05:38:59,948 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype87-Edge34 crash on backend pytorch when predicting
2024-06-13 05:38:59,970 logger.py[line:35] INFO coverage_c=14252
2024-06-13 05:39:00,076 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype87-Edge34
2024-06-13 05:39:00,076 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:39:00,077 logger.py[line:35] INFO after_prediction
2024-06-13 05:39:00,214 logger.py[line:35] INFO INFO: Mutation progress 35/100
2024-06-13 05:39:00,214 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:39:00,214 logger.py[line:35] INFO Score for NLAll is: 0.86
2024-06-13 05:39:00,214 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:39:00,214 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:39:00,214 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:39:00,214 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:39:00,214 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:39:00,214 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:39:00,214 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:39:00,214 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:39:00,214 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:39:00,214 logger.py[line:35] INFO Choose seed: lenet-LMerg90-NLAll105-NLAll116-Edge130-LMerg32-LMerg63
2024-06-13 05:39:00,215 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:39:03,808 logger.py[line:35] INFO Generating model using NLAll
model outputs {'dense_15_copy_LMerg_copy_NLAll_copy_NLAll_copy_Edge_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_15_copy_LMerg_copy_NLAll_copy_NLAll_copy_Edge_copy_LMerg_copy_LMerg_copy_NLAll')>, 'dot_copy_ML_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 10, 10) dtype=float32 (created by layer 'dot_copy_ML_copy_LMerg_copy_NLAll')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_1_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 14, 14, 6) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_1_copy_LMerg_copy_LMerg_copy_NLAll')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_2_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 120) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_2_copy_LMerg_copy_LMerg_copy_NLAll')>, 'elu_insert_copy_Edge_1_2_1_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 120) dtype=float32 (created by layer 'elu_insert_copy_Edge_1_2_1_copy_LMerg_copy_LMerg_copy_NLAll')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_1_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 16) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_1_copy_LMerg_copy_LMerg_copy_NLAll')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_2_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 16) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_2_copy_LMerg_copy_LMerg_copy_NLAll')>, 'concatenate_copy_ML': <KerasTensor: shape=(None, 10, 4) dtype=float32 (created by layer 'concatenate_copy_ML_copy_NLAll')>}
2024-06-13 05:39:04,020 logger.py[line:35] INFO Insert 6 out of 13 Global New Layers
2024-06-13 05:39:04,020 logger.py[line:35] INFO insert LocallyConnected1D after repeat_vector_insert_copy_NLAll_copy_Edge_copy_LMerg_copy_LMerg_copy_NLAll
2024-06-13 05:39:04,020 logger.py[line:35] INFO insert SeparableConv1D after repeat_vector_insert_copy_NLAll_copy_Edge_copy_LMerg_copy_LMerg_copy_NLAll
2024-06-13 05:39:04,020 logger.py[line:35] INFO insert SimpleRNN after dropout_5_copy_LMerg_merge1_copy_NLAll_copy_NLAll_copy_Edge_2_copy_LMerg_copy_LMerg_copy_NLAll
2024-06-13 05:39:04,020 logger.py[line:35] INFO insert Cropping1D after cropping1d_1_copy_LMerg_copy_LMerg_merge1_copy_NLAll
2024-06-13 05:39:04,020 logger.py[line:35] INFO insert DepthwiseConv1D after permute_insert_copy_Edge_copy_LMerg_copy_LMerg_copy_NLAll
2024-06-13 05:39:04,020 logger.py[line:35] INFO insert SpatialDropout1D after dropout_5_copy_LMerg_merge1_copy_NLAll_copy_NLAll_copy_Edge_2_copy_LMerg_copy_LMerg_copy_NLAll
2024-06-13 05:39:04,020 logger.py[line:35] INFO Insert 2 out of 34 Local New Layers
2024-06-13 05:39:04,020 logger.py[line:35] INFO insert PReLU after dropout_5_copy_LMerg_merge1_copy_NLAll_copy_NLAll_copy_Edge_1_2_copy_LMerg_merge1_copy_LMerg_copy_NLAll
2024-06-13 05:39:04,020 logger.py[line:35] INFO insert Conv2D after softmax_insert_copy_NLAll_copy_Edge_2_copy_LMerg_copy_LMerg_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.convolutional.SeparableConv1D object at 0x7f093c04bdd0>
2024-06-13 05:39:04,109 logger.py[line:35] INFO Converting output shape (None, 2, 120) to actual shape [None, 2, 120]
[DEBUG] Inserting layer: <keras.layers.convolutional.DepthwiseConv1D object at 0x7f091c7ee850>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1939, in _create_c_op
    raise ValueError(e.message)
ValueError: Exception encountered when calling layer "depthwise_conv1d_insert" (type DepthwiseConv1D).

Negative dimension size caused by subtracting 8 from 2 for '{{node depthwise_conv1d_insert/depthwise}} = DepthwiseConv2dNative[T=DT_FLOAT, data_format="NCHW", dilations=[1, 1, 1, 1], explicit_paddings=[], padding="VALID", strides=[1, 1, 1, 1]](depthwise_conv1d_insert/ExpandDims, depthwise_conv1d_insert/ExpandDims_1)' with input shapes: [?,120,1,2], [1,8,120,1].

Call arguments received:
   inputs=tf.Tensor(shape=(None, 120, 2), dtype=float32)
2024-06-13 05:39:04,559 logger.py[line:35] INFO INFO: Mutation progress 35/100
2024-06-13 05:39:04,560 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:39:04,560 logger.py[line:35] INFO Score for NLAll is: 0.86
2024-06-13 05:39:04,560 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:39:04,560 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:39:04,560 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:39:04,560 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:39:04,560 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:39:04,560 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:39:04,560 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:39:04,560 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:39:04,560 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:39:04,561 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-NLAll54-NLAll124-MDtype127
2024-06-13 05:39:04,561 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:39:07,471 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:39:08,269 logger.py[line:35] INFO Generating model using NLAll
2024-06-13 05:39:08,272 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll')>}
2024-06-13 05:39:08,538 logger.py[line:35] INFO Insert 8 out of 20 Global New Layers
2024-06-13 05:39:08,539 logger.py[line:35] INFO insert SpatialDropout1D after separable_conv1d_insert_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,539 logger.py[line:35] INFO insert ZeroPadding3D after up_sampling3d_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,539 logger.py[line:35] INFO insert GlobalAveragePooling3D after gaussian_dropout_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,539 logger.py[line:35] INFO insert SeparableConv1D after repeat_vector_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,539 logger.py[line:35] INFO insert Conv3DTranspose after gaussian_dropout_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,539 logger.py[line:35] INFO insert GlobalAveragePooling1D after repeat_vector_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,539 logger.py[line:35] INFO insert ZeroPadding1D after separable_conv1d_insert_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,539 logger.py[line:35] INFO insert GRU after separable_conv1d_insert_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,539 logger.py[line:35] INFO Insert 4 out of 38 Local New Layers
2024-06-13 05:39:08,539 logger.py[line:35] INFO insert MaxPooling2D after up_sampling2d_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,539 logger.py[line:35] INFO insert RepeatVector after softmax_insert_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,539 logger.py[line:35] INFO insert ReLU after global_max_pooling3d_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,540 logger.py[line:35] INFO insert PReLU after up_sampling2d_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,540 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 1
2024-06-13 05:39:08,540 logger.py[line:35] INFO insert GlobalAveragePooling2D after custom_expand_layer_1_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:39:08,543 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.pooling.GlobalAveragePooling2D object at 0x7f1d2047ce50>
2024-06-13 05:39:08,642 logger.py[line:35] INFO Converting output shape (None, 25) to actual shape [None, 1, 1, 25]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ReLU object at 0x7f1d20413510>
2024-06-13 05:39:08,656 logger.py[line:35] INFO Converting output shape (None, 1) to actual shape [None, 1]
[DEBUG] Inserting layer: <keras.layers.convolutional.ZeroPadding3D object at 0x7f1d20465a50>
2024-06-13 05:39:08,682 logger.py[line:35] INFO Converting output shape (None, 1, 11, 17, 227) to actual shape [None, 1, 9, 9, 225]
[DEBUG] Inserting layer: <keras.layers.convolutional.Conv3DTranspose object at 0x7f1d20535fd0>
2024-06-13 05:39:10,994 logger.py[line:35] INFO Converting output shape (None, 7, 15, 15, 225) to actual shape [None, 1, 9, 9, 225]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.PReLU object at 0x7f1d20431b10>
2024-06-13 05:39:11,039 logger.py[line:35] INFO Converting output shape (None, 63, 63, 225) to actual shape [None, 63, 63, 225]
[DEBUG] Inserting layer: <keras.layers.core.repeat_vector.RepeatVector object at 0x7f1d203d5810>
2024-06-13 05:39:11,076 logger.py[line:35] INFO Converting output shape (None, 2, 25) to actual shape [None, 25]
[DEBUG] Inserting layer: <keras.layers.pooling.GlobalAveragePooling1D object at 0x7f1d203e1f90>
2024-06-13 05:39:11,088 logger.py[line:35] INFO Converting output shape (None, 2) to actual shape [None, 2, 25]
2024-06-13 05:39:11,267 recurrent_v2.py[line:399] WARNING Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.recurrent_v2.GRU object at 0x7f1d20609510>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 73, in new_layer_addition
    mylogger.info(f"Converting output shape {layer_input.shape} to actual shape {target_shape}")
AttributeError: 'list' object has no attribute 'shape'
2024-06-13 05:39:11,962 logger.py[line:35] INFO INFO: Mutation progress 35/100
2024-06-13 05:39:11,962 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:39:11,962 logger.py[line:35] INFO Score for NLAll is: 0.86
2024-06-13 05:39:11,963 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:39:11,963 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:39:11,963 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:39:11,963 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:39:11,963 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:39:11,963 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:39:11,963 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:39:11,963 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:39:11,963 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:39:11,963 logger.py[line:35] INFO Choose seed: mobilenet.v2-MParam43
2024-06-13 05:39:11,963 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:39:16,009 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_NLAll')>}
2024-06-13 05:39:17,094 logger.py[line:35] INFO Insert 9 out of 30 Local New Layers
2024-06-13 05:39:17,095 logger.py[line:35] INFO insert LocallyConnected2D after block_7_project_BN_copy_MParam_copy_NLAll
2024-06-13 05:39:17,095 logger.py[line:35] INFO insert SpatialDropout2D after out_relu_copy_MParam_copy_NLAll
2024-06-13 05:39:17,095 logger.py[line:35] INFO insert GaussianDropout after block_15_expand_relu_copy_MParam_copy_NLAll
2024-06-13 05:39:17,095 logger.py[line:35] INFO insert ConvLSTM1D after block_2_project_BN_copy_MParam_copy_NLAll
2024-06-13 05:39:17,095 logger.py[line:35] INFO insert GlobalMaxPooling2D after block_12_depthwise_copy_MParam_copy_NLAll
2024-06-13 05:39:17,096 logger.py[line:35] INFO insert PReLU after block_7_expand_relu_copy_MParam_copy_NLAll
2024-06-13 05:39:17,096 logger.py[line:35] INFO insert SeparableConv2D after block_15_depthwise_relu_copy_MParam_copy_NLAll
2024-06-13 05:39:17,096 logger.py[line:35] INFO insert LayerNormalization after Conv1_relu_copy_MParam_copy_NLAll
2024-06-13 05:39:17,096 logger.py[line:35] INFO insert AveragePooling2D after block_1_pad_copy_MParam_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x7f62501357d0>
2024-06-13 05:39:17,124 logger.py[line:35] INFO Converting output shape (None, 112, 112, 32) to actual shape [None, 112, 112, 32]
[DEBUG] Inserting layer: <keras.layers.pooling.AveragePooling2D object at 0x7f62a00d2c90>
2024-06-13 05:39:17,170 logger.py[line:35] INFO Converting output shape (None, 113, 113, 96) to actual shape [None, 113, 113, 96]
[DEBUG] Inserting layer: <keras.layers.convolutional_recurrent.ConvLSTM1D object at 0x7f625009af10>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 73, in new_layer_addition
    mylogger.info(f"Converting output shape {layer_input.shape} to actual shape {target_shape}")
AttributeError: 'list' object has no attribute 'shape'
2024-06-13 05:39:17,890 logger.py[line:35] INFO INFO: Mutation progress 35/100
2024-06-13 05:39:17,890 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:39:17,891 logger.py[line:35] INFO Score for NLAll is: 0.86
2024-06-13 05:39:17,891 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:39:17,891 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:39:17,891 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:39:17,891 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:39:17,891 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:39:17,891 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:39:17,891 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:39:17,891 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:39:17,891 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:39:17,891 logger.py[line:35] INFO Choose seed: alexnet
2024-06-13 05:39:17,891 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:39:21,222 logger.py[line:35] INFO Generating model using NLAll
model outputs {'dense_3': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_NLAll')>}
2024-06-13 05:39:21,336 logger.py[line:35] INFO Insert 1 out of 23 Local New Layers
2024-06-13 05:39:21,336 logger.py[line:35] INFO insert Softmax after flatten_1_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.advanced_activations.Softmax object at 0x7f3380090f10>
2024-06-13 05:39:21,416 logger.py[line:35] INFO Converting output shape (None, 256) to actual shape [None, 256]
model outputs {'dense_3_copy_NLAll': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_NLAll')>}
2024-06-13 05:39:21,457 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 99/2170
The Configuration Coverage is: 284/2049
The NDims Coverage Is: 50/117
The DType Coverage Is: 58/354
The Shape Coverage Is: 97/295
The Input Coverage Is: 205/766
2024-06-13 05:39:22,282 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:39:22,725 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (26) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:39:44,668 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 21s
2024-06-13 05:39:44,668 logger.py[line:35] INFO alexnet-NLAll35 crash on backend pytorch when predicting
2024-06-13 05:39:44,690 logger.py[line:35] INFO coverage_c=14252
2024-06-13 05:39:44,699 logger.py[line:35] INFO Fail on backend: pytorch of model alexnet-NLAll35
2024-06-13 05:39:44,699 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:39:44,699 logger.py[line:35] INFO after_prediction
2024-06-13 05:39:44,819 logger.py[line:35] INFO INFO: Mutation progress 36/100
2024-06-13 05:39:44,819 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:39:44,819 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:39:44,819 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:39:44,819 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:39:44,819 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:39:44,820 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:39:44,820 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:39:44,820 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:39:44,820 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:39:44,820 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:39:44,820 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:39:44,820 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99
2024-06-13 05:39:44,820 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:39:52,201 logger.py[line:35] INFO Generating model using LMerg
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 05:39:55,682 logger.py[line:35] INFO Insert 1 out of 4 Global New Layers
2024-06-13 05:39:55,688 logger.py[line:35] INFO Trying Merge Layers: mixed_7a_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_LMerg and block8_4_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_LMerg by Dot
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 72, in generate_model_by_model_mutation
    return InteractionMutationUtils.merge_layers(model=model, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 176, in merge_layers
    new_model = ArchitectureUtils.merge_two_layers(ML_model, selected_layer, layer1_name, layer2_name)
  File "/root/implementations/scripts/tools/architecture_utils.py", line 735, in merge_two_layers
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/merge.py", line 525, in build
    raise ValueError(err_msg)
ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 8, 8, 8, 192), (None, 8, 8, 8, 256)]
2024-06-13 05:39:59,611 logger.py[line:35] INFO INFO: Mutation progress 36/100
2024-06-13 05:39:59,612 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:39:59,612 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:39:59,612 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:39:59,612 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:39:59,612 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:39:59,612 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:39:59,612 logger.py[line:35] INFO Score for LMerg is: 0.7894736842105263
2024-06-13 05:39:59,612 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:39:59,612 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:39:59,612 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 05:39:59,612 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:39:59,612 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84
2024-06-13 05:39:59,612 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:40:02,510 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:40:03,196 logger.py[line:35] INFO Generating model using LMerg
2024-06-13 05:40:03,199 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 05:40:03,415 logger.py[line:35] INFO Insert 1 out of 4 Global New Layers
2024-06-13 05:40:03,416 logger.py[line:35] INFO Trying Merge Layers: custom_drop_dim_layer_2_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_LMerg and global_average_pooling3d_insert_copy_LMerg_copy_LMerg by Dot
2024-06-13 05:40:03,419 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:40:03,634 logger.py[line:35] INFO Success on Merge Layers: custom_drop_dim_layer_2_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_LMerg and global_average_pooling3d_insert_copy_LMerg_copy_LMerg by Dot
2024-06-13 05:40:03,653 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:40:04,279 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 101/2170
The Configuration Coverage is: 305/2049
The NDims Coverage Is: 53/117
The DType Coverage Is: 60/354
The Shape Coverage Is: 100/295
The Input Coverage Is: 213/766
2024-06-13 05:40:04,513 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:40:04,969 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 280, in convert_operations
    "Conversion not implemented for op_type={}.".format(node.op_type)
NotImplementedError: Conversion not implemented for op_type=ReduceSumSquare.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:40:13,195 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 8s
2024-06-13 05:40:13,196 logger.py[line:35] INFO lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84-LMerg36 crash on backend pytorch when predicting
2024-06-13 05:40:13,218 logger.py[line:35] INFO coverage_c=14258
2024-06-13 05:40:13,318 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84-LMerg36
2024-06-13 05:40:13,318 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:40:13,318 logger.py[line:35] INFO after_prediction
2024-06-13 05:40:13,435 logger.py[line:35] INFO INFO: Mutation progress 37/100
2024-06-13 05:40:13,435 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:40:13,435 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:40:13,435 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:40:13,435 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:40:13,435 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:40:13,435 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:40:13,435 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:40:13,436 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:40:13,436 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:40:13,436 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 05:40:13,436 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:40:13,436 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-LMerg70
2024-06-13 05:40:13,436 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:40:17,785 logger.py[line:35] INFO Generating model using MShape
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>}
2024-06-13 05:40:18,850 logger.py[line:35] INFO Change 1 Layer's Shape Out Of 6 Layer classes
2024-06-13 05:40:18,850 logger.py[line:35] INFO Changing 1 out of 6 Layer's Shape.
2024-06-13 05:40:18,851 logger.py[line:35] INFO [Locally] Changing The Input Shape Of Layer: cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape From [None, 58, 58, 64] To [None, 5, 7, 0]
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 94, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_shape(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 483, in mutate_shape
    new_model = InputMutationUtils.mshape(MShape_model, selected_layer_shape_pair, revert_shape=True)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 456, in mshape
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 447, in mshape_layer_mutation
    layer_input = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional.py", line 3554, in call
    raise ValueError('Argument `cropping` must be '
ValueError: Exception encountered when calling layer "cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape" (type Cropping2D).

Argument `cropping` must be greater than the input shape. Received: inputs.shape=(None, 5, 7, 0), and cropping=((24, 24), (24, 24))

Call arguments received:
   inputs=tf.Tensor(shape=(None, 5, 7, 0), dtype=float32)
2024-06-13 05:40:20,489 logger.py[line:35] INFO INFO: Mutation progress 37/100
2024-06-13 05:40:20,489 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:40:20,489 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:40:20,489 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:40:20,489 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:40:20,489 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:40:20,489 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:40:20,489 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:40:20,489 logger.py[line:35] INFO Score for MShape is: 0.6818181818181818
2024-06-13 05:40:20,489 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:40:20,489 logger.py[line:35] INFO The last used seed is: MShape
2024-06-13 05:40:20,490 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:40:20,490 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-LMerg70
2024-06-13 05:40:20,490 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:40:24,854 logger.py[line:35] INFO Generating model using MShape
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>}
2024-06-13 05:40:25,923 logger.py[line:35] INFO Change 3 Layer's Shape Out Of 6 Layer classes
2024-06-13 05:40:25,923 logger.py[line:35] INFO Changing 3 out of 6 Layer's Shape.
2024-06-13 05:40:25,923 logger.py[line:35] INFO [Locally] Changing The Input Shape Of Layer: avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape From [None, 114, 114, 64] To [None, 9, 6, 2]
2024-06-13 05:40:25,924 logger.py[line:35] INFO [Locally] Changing The Input Shape Of Layer: pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_1_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape From [None, 112, 112, 64] To [None, 2, 3, 2]
2024-06-13 05:40:25,925 logger.py[line:35] INFO [Locally] Changing The Input Shape Of Layer: pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape From [None, 114, 114, 64] To [None, 8, 5, 9]
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape': <KerasTensor: shape=(None, 64) dtype=float32 (created by layer 'custom_pad_layer_2')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MShape')>}
2024-06-13 05:40:27,091 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 101/2170
The Configuration Coverage is: 305/2049
The NDims Coverage Is: 53/117
The DType Coverage Is: 60/354
The Shape Coverage Is: 100/295
The Input Coverage Is: 213/766
2024-06-13 05:40:29,416 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:40:29,864 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:41:06,147 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:41:06,148 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (243x33 and 64x100)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:41:09,480 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 39s
2024-06-13 05:41:09,480 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-LMerg70-MShape37 crash on backend pytorch when predicting
2024-06-13 05:41:09,503 logger.py[line:35] INFO coverage_c=14277
2024-06-13 05:41:09,561 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-LMerg70-MShape37
2024-06-13 05:41:09,561 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:41:09,561 logger.py[line:35] INFO after_prediction
2024-06-13 05:41:09,561 logger.py[line:35] INFO No representative seed generated: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-LMerg70-MShape37, do not increase the reward
2024-06-13 05:41:09,699 logger.py[line:35] INFO INFO: Mutation progress 38/100
2024-06-13 05:41:09,699 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:41:09,699 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:41:09,699 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:41:09,699 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:41:09,699 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:41:09,699 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:41:09,699 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:41:09,700 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:41:09,700 logger.py[line:35] INFO Score for SpecialI is: 0.6052631578947368
2024-06-13 05:41:09,700 logger.py[line:35] INFO The last used seed is: MShape
2024-06-13 05:41:09,700 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:41:09,700 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84
2024-06-13 05:41:09,700 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:41:12,622 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:41:13,319 logger.py[line:35] INFO Generating model using SpecialI
2024-06-13 05:41:13,322 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_SpecialI')>}
2024-06-13 05:41:13,534 logger.py[line:35] INFO Change Input Of Layer: lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_SpecialI To: nan
2024-06-13 05:41:13,537 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_SpecialI will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_SpecialI': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_SpecialI')>}
2024-06-13 05:41:13,769 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:41:14,377 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_SpecialI will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 101/2170
The Configuration Coverage is: 305/2049
The NDims Coverage Is: 53/117
The DType Coverage Is: 60/354
The Shape Coverage Is: 100/295
The Input Coverage Is: 213/766
2024-06-13 05:41:14,609 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:41:15,055 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 280, in convert_operations
    "Conversion not implemented for op_type={}.".format(node.op_type)
NotImplementedError: Conversion not implemented for op_type=ReduceSumSquare.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:41:23,182 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 8s
2024-06-13 05:41:23,182 logger.py[line:35] INFO lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84-SpecialI38 crash on backend pytorch when predicting
2024-06-13 05:41:23,204 logger.py[line:35] INFO coverage_c=14277
2024-06-13 05:41:23,306 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84-SpecialI38
2024-06-13 05:41:23,306 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:41:23,307 logger.py[line:35] INFO after_prediction
2024-06-13 05:41:23,307 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84-SpecialI38, do not increase the reward
2024-06-13 05:41:23,424 logger.py[line:35] INFO INFO: Mutation progress 39/100
2024-06-13 05:41:23,425 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:41:23,425 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:41:23,425 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:41:23,425 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:41:23,425 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:41:23,425 logger.py[line:35] INFO Score for MDims is: 0.7926829268292683
2024-06-13 05:41:23,425 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:41:23,425 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:41:23,425 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:41:23,425 logger.py[line:35] INFO The last used seed is: SpecialI
2024-06-13 05:41:23,425 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:41:23,425 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65
2024-06-13 05:41:23,425 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:41:26,332 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:41:27,002 logger.py[line:35] INFO Generating model using MDims
2024-06-13 05:41:27,005 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDims')>}
2024-06-13 05:41:27,183 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 05:41:27,183 logger.py[line:35] INFO Global Layer Class: 0; Local Layer Class: 1; Total Layer Class: 1
2024-06-13 05:41:27,183 logger.py[line:35] INFO Changing 0 Layer's NDims.
2024-06-13 05:41:27,183 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 05:41:27,183 logger.py[line:35] INFO No Global NDims Can Be Found, Randomly Select NDims: 2 For Layer: dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDims
2024-06-13 05:41:27,186 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDims': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDims')>}
2024-06-13 05:41:27,405 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:41:28,027 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 101/2170
The Configuration Coverage is: 305/2049
The NDims Coverage Is: 53/117
The DType Coverage Is: 60/354
The Shape Coverage Is: 100/295
The Input Coverage Is: 213/766
2024-06-13 05:41:28,238 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:41:28,691 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (59) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:41:36,567 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 7s
2024-06-13 05:41:36,568 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65-MDims39 crash on backend pytorch when predicting
2024-06-13 05:41:36,590 logger.py[line:35] INFO coverage_c=14277
2024-06-13 05:41:36,642 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65-MDims39
2024-06-13 05:41:36,642 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:41:36,642 logger.py[line:35] INFO after_prediction
2024-06-13 05:41:36,642 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65-MDims39, do not increase the reward
2024-06-13 05:41:36,762 logger.py[line:35] INFO INFO: Mutation progress 40/100
2024-06-13 05:41:36,762 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:41:36,762 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:41:36,762 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:41:36,762 logger.py[line:35] INFO Score for MDtype is: 0.8055555555555556
2024-06-13 05:41:36,762 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:41:36,762 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:41:36,762 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:41:36,762 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:41:36,762 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:41:36,762 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:41:36,763 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:41:36,763 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81
2024-06-13 05:41:36,763 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:41:44,174 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype')>}
2024-06-13 05:41:47,858 logger.py[line:35] INFO Change 2 Layer's DType Out Of 5 Layer classes
2024-06-13 05:41:47,858 logger.py[line:35] INFO Changing 2 out of 5 Layer's DType.
2024-06-13 05:41:47,860 logger.py[line:35] INFO Selecting a Global DType float64 For Layer avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype
2024-06-13 05:41:47,862 logger.py[line:35] INFO Selecting a Global DType double For Layer conv2d_100_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype')>}
2024-06-13 05:41:51,677 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 101/2170
The Configuration Coverage is: 305/2049
The NDims Coverage Is: 53/117
The DType Coverage Is: 60/354
The Shape Coverage Is: 100/295
The Input Coverage Is: 213/766
2024-06-13 05:41:58,006 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:41:58,456 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (1046) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:42:57,543 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 59s
2024-06-13 05:42:57,543 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81-MDtype40 crash on backend pytorch when predicting
2024-06-13 05:42:57,565 logger.py[line:35] INFO coverage_c=14277
2024-06-13 05:42:57,669 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81-MDtype40
2024-06-13 05:42:57,669 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:42:57,670 logger.py[line:35] INFO after_prediction
2024-06-13 05:42:57,847 logger.py[line:35] INFO INFO: Mutation progress 41/100
2024-06-13 05:42:57,847 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:42:57,847 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:42:57,847 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:42:57,847 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:42:57,847 logger.py[line:35] INFO Score for MParam is: 0.7931034482758621
2024-06-13 05:42:57,847 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:42:57,847 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:42:57,847 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:42:57,847 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:42:57,847 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:42:57,847 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:42:57,847 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94
2024-06-13 05:42:57,847 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:43:02,136 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam')>}
2024-06-13 05:43:03,190 logger.py[line:35] INFO Changing 1/5 of layer conv2_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 05:43:03,190 logger.py[line:35] INFO changing config scale in layer conv2_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to False
2024-06-13 05:43:03,190 logger.py[line:35] INFO changing config axis in layer conv2_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 05:43:03,190 logger.py[line:35] INFO Changing 1/2 of layer conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 05:43:03,190 logger.py[line:35] INFO changing config padding in layer conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from ((3, 3), (3, 3)) to [1, 2]
2024-06-13 05:43:03,191 logger.py[line:35] INFO changing config data_format in layer conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from channels_last to channels_last
2024-06-13 05:43:03,191 logger.py[line:35] INFO Changing 1/5 of layer conv2_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 05:43:03,191 logger.py[line:35] INFO changing config momentum in layer conv2_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from 0.99 to 0.8007601293087833
2024-06-13 05:43:03,191 logger.py[line:35] INFO changing config epsilon in layer conv2_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from 1.001e-05 to 0.17430141909235808
2024-06-13 05:43:03,191 logger.py[line:35] INFO Changing 3/5 of layer conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 05:43:03,191 logger.py[line:35] INFO changing config momentum in layer conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from 0.99 to 0.6892648164733683
2024-06-13 05:43:03,191 logger.py[line:35] INFO changing config axis in layer conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 05:43:03,191 logger.py[line:35] INFO changing config center in layer conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to False
2024-06-13 05:43:03,191 logger.py[line:35] INFO changing config epsilon in layer conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from 1.001e-05 to 0.10536797791970898
2024-06-13 05:43:03,191 logger.py[line:35] INFO Changing 1/15 of layer conv2_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 05:43:03,191 logger.py[line:35] INFO changing config bias_constraint in layer conv2_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from None to NonNeg
2024-06-13 05:43:03,191 logger.py[line:35] INFO changing config bias_initializer in layer conv2_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from {'class_name': 'Zeros', 'config': {}} to Ones
2024-06-13 05:43:03,192 logger.py[line:35] INFO Changing 3/5 of layer conv4_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 05:43:03,192 logger.py[line:35] INFO changing config axis in layer conv4_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 05:43:03,192 logger.py[line:35] INFO changing config momentum in layer conv4_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from 0.99 to 0.3398724337352116
2024-06-13 05:43:03,192 logger.py[line:35] INFO changing config scale in layer conv4_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to False
2024-06-13 05:43:03,192 logger.py[line:35] INFO changing config center in layer conv4_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to True
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam')>}
2024-06-13 05:43:04,172 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 101/2170
The Configuration Coverage is: 310/2049
The NDims Coverage Is: 53/117
The DType Coverage Is: 60/354
The Shape Coverage Is: 100/295
The Input Coverage Is: 213/766
2024-06-13 05:43:06,264 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:43:06,716 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,1,64,64) (1,1,56,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,1,64,64) (1,1,56,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,1,64,64) (1,1,56,1) 
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (243) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:43:31,515 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 05:43:31,515 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-MParam94-MParam41 crash on backend pytorch when predicting
2024-06-13 05:43:31,537 logger.py[line:35] INFO coverage_c=14277
2024-06-13 05:43:31,591 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-MParam94-MParam41
2024-06-13 05:43:31,591 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:43:31,591 logger.py[line:35] INFO after_prediction
2024-06-13 05:43:31,727 logger.py[line:35] INFO INFO: Mutation progress 42/100
2024-06-13 05:43:31,727 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:43:31,727 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:43:31,727 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:43:31,728 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:43:31,728 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:43:31,728 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:43:31,728 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:43:31,728 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:43:31,728 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:43:31,728 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:43:31,728 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:43:31,728 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MDtype4-NLAll12-NLAll32-NLAll93-NLAll-1-Edge61-MParam98
2024-06-13 05:43:31,728 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:43:36,708 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam')>, 'elu_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 14, 13, 1017) dtype=float32 (created by layer 'elu_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam_copy_MParam')>, 'softmax_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 7, 7, 512) dtype=float32 (created by layer 'softmax_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam_copy_MParam')>, 'pool1_pool_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 3, 6, 2052) dtype=float16 (created by layer 'pool1_pool_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam_copy_MParam')>, 'cropping2d_copy_MParam': <KerasTensor: shape=(None, 10, 10, 258) dtype=float32 (created by layer 'cropping2d_copy_MParam_copy_MParam')>, 'conv4_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv4_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam_copy_MParam')>, 'global_max_pooling2d_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'global_max_pooling2d_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam_copy_MParam')>}
2024-06-13 05:43:37,846 logger.py[line:35] INFO Changing 2/5 of layer conv4_block5_1_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam's configuration
2024-06-13 05:43:37,847 logger.py[line:35] INFO changing config scale in layer conv4_block5_1_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam: from False to False
2024-06-13 05:43:37,847 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 05:43:37,847 logger.py[line:35] INFO changing config center in layer conv4_block5_1_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam: from False to False
2024-06-13 05:43:37,847 logger.py[line:35] INFO changing config axis in layer conv4_block5_1_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 05:43:37,847 logger.py[line:35] INFO Changing 1/15 of layer conv3_block4_3_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam's configuration
2024-06-13 05:43:37,847 logger.py[line:35] INFO changing config activation in layer conv3_block4_3_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam: from linear to tanh
2024-06-13 05:43:37,847 logger.py[line:35] INFO changing config data_format in layer conv3_block4_3_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam: from channels_last to channels_first
2024-06-13 05:43:37,847 logger.py[line:35] INFO Changing 1/1 of layer softmax_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam_copy_MParam's configuration
2024-06-13 05:43:37,848 logger.py[line:35] INFO changing config axis in layer softmax_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam_copy_MParam: from -2 to -1
2024-06-13 05:43:37,848 logger.py[line:35] INFO Changing 1/5 of layer conv4_block2_3_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam's configuration
2024-06-13 05:43:37,848 logger.py[line:35] INFO changing config center in layer conv4_block2_3_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam: from True to True
2024-06-13 05:43:37,848 logger.py[line:35] INFO changing config axis in layer conv4_block2_3_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 05:43:37,848 logger.py[line:35] INFO Changing 3/15 of layer conv3_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam's configuration
2024-06-13 05:43:37,848 logger.py[line:35] INFO changing config bias_initializer in layer conv3_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam: from {'class_name': 'Zeros', 'config': {}} to he_uniform
2024-06-13 05:43:37,848 logger.py[line:35] INFO changing config data_format in layer conv3_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam: from channels_last to channels_first
2024-06-13 05:43:37,848 logger.py[line:35] INFO changing config bias_constraint in layer conv3_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam: from None to UnitNorm
2024-06-13 05:43:37,848 logger.py[line:35] INFO changing config activation in layer conv3_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MParam: from linear to tanh
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/merge.py", line 79, in _compute_elemwise_op_output_shape
    'Inputs have incompatible shapes. '
ValueError: Inputs have incompatible shapes. Received shapes (28, 28, 512) and (128, 28, 512)
2024-06-13 05:43:38,713 logger.py[line:35] INFO INFO: Mutation progress 42/100
2024-06-13 05:43:38,713 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:43:38,713 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:43:38,713 logger.py[line:35] INFO Score for Edge is: 0.8166666666666667
2024-06-13 05:43:38,713 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:43:38,713 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:43:38,713 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:43:38,713 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:43:38,713 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:43:38,713 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:43:38,713 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:43:38,714 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:43:38,714 logger.py[line:35] INFO Choose seed: densenet121-MDims75
2024-06-13 05:43:38,714 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:43:44,446 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_MDims': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MDims_copy_Edge')>}
Choosing 6 To Insert
2024-06-13 05:43:46,378 logger.py[line:35] INFO Insert 6 Global New Edges
2024-06-13 05:43:46,379 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'MaxPooling2D')
2024-06-13 05:43:48,832 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'MaxPooling2D'] by Connecting pool3_pool_copy_MDims_copy_Edge and pool1_copy_MDims_copy_Edge
2024-06-13 05:43:50,884 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'MaxPooling2D'] by Connecting pool3_pool_copy_MDims_copy_Edge and pool1_copy_MDims_copy_Edge
2024-06-13 05:43:50,884 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'AveragePooling2D')
2024-06-13 05:43:53,102 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'AveragePooling2D'] by Connecting pool3_pool_copy_MDims_copy_Edge and pool3_pool_copy_MDims_copy_Edge
2024-06-13 05:43:55,204 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'AveragePooling2D'] by Connecting pool3_pool_copy_MDims_copy_Edge and pool3_pool_copy_MDims_copy_Edge
2024-06-13 05:43:55,204 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'GlobalAveragePooling2D')
2024-06-13 05:43:57,429 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'GlobalAveragePooling2D'] by Connecting pool2_pool_copy_MDims_copy_Edge and avg_pool_copy_MDims_copy_Edge
2024-06-13 05:43:59,542 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'GlobalAveragePooling2D'] by Connecting pool2_pool_copy_MDims_copy_Edge and avg_pool_copy_MDims_copy_Edge
2024-06-13 05:43:59,542 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'AveragePooling2D')
2024-06-13 05:44:01,762 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'AveragePooling2D'] by Connecting pool1_copy_MDims_copy_Edge_1 and pool3_pool_copy_MDims_copy_Edge_2
2024-06-13 05:44:03,862 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'AveragePooling2D'] by Connecting pool1_copy_MDims_copy_Edge_1 and pool3_pool_copy_MDims_copy_Edge_2
2024-06-13 05:44:03,862 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'AveragePooling2D')
2024-06-13 05:44:06,095 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'AveragePooling2D'] by Connecting zero_padding2d_2_copy_MDims_copy_Edge and pool3_pool_copy_MDims_copy_Edge_2_1
2024-06-13 05:44:07,990 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'AveragePooling2D'] by Connecting zero_padding2d_2_copy_MDims_copy_Edge and pool3_pool_copy_MDims_copy_Edge_2_1
2024-06-13 05:44:07,990 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'ZeroPadding2D')
2024-06-13 05:44:10,449 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'ZeroPadding2D'] by Connecting pool2_pool_copy_MDims_copy_Edge and zero_padding2d_2_copy_MDims_copy_Edge
2024-06-13 05:44:12,353 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'ZeroPadding2D'] by Connecting pool2_pool_copy_MDims_copy_Edge and zero_padding2d_2_copy_MDims_copy_Edge
2024-06-13 05:44:12,564 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 108/2170
The Configuration Coverage is: 310/2049
The NDims Coverage Is: 53/117
The DType Coverage Is: 60/354
The Shape Coverage Is: 100/295
The Input Coverage Is: 213/766
2024-06-13 05:44:16,304 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:44:16,750 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:44:41,424 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:44:41,425 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/reshape.py", line 31, in forward
    return torch.reshape(input, tuple(shape))
RuntimeError: shape '[-1, 12544]' is invalid for input of size 1096704

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:44:47,454 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 30s
2024-06-13 05:44:47,454 logger.py[line:35] INFO densenet121-MDims75-Edge42 crash on backend pytorch when predicting
2024-06-13 05:44:47,476 logger.py[line:35] INFO coverage_c=14302
2024-06-13 05:44:47,530 logger.py[line:35] INFO Fail on backend: pytorch of model densenet121-MDims75-Edge42
2024-06-13 05:44:47,530 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:44:47,530 logger.py[line:35] INFO after_prediction
2024-06-13 05:44:47,696 logger.py[line:35] INFO INFO: Mutation progress 43/100
2024-06-13 05:44:47,696 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:44:47,696 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:44:47,696 logger.py[line:35] INFO Score for Edge is: 0.8114754098360656
2024-06-13 05:44:47,696 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:44:47,696 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:44:47,696 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:44:47,696 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:44:47,696 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:44:47,696 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:44:47,696 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:44:47,696 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:44:47,696 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7
2024-06-13 05:44:47,696 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:44:52,051 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_Edge')>, 'cropping2d': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_Edge')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_Edge')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_Edge')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2_copy_Edge')>, 'cropping2d_1': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_1_copy_Edge')>, 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 20, 20, 256) dtype=float32 (created by layer 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_Edge')>, 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_Edge')>, 'cropping2d_2': <KerasTensor: shape=(None, 11, 11, 64) dtype=float32 (created by layer 'cropping2d_2_copy_Edge')>}
Choosing 9 To Insert
2024-06-13 05:44:53,081 logger.py[line:35] INFO Insert 4 Global New Edges
2024-06-13 05:44:53,081 logger.py[line:35] INFO Insert 5 Local New Edges
2024-06-13 05:44:53,081 logger.py[line:35] INFO Candidate Edge: ('Cropping2D', 'Conv2D')
2024-06-13 05:44:54,118 logger.py[line:35] INFO Trying Adding Edge: ['Cropping2D', 'Conv2D'] by Connecting cropping2d_2_copy_Edge and conv4_block4_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_Edge
2024-06-13 05:44:55,054 logger.py[line:35] INFO Successfully Add Edge: ['Cropping2D', 'Conv2D'] by Connecting cropping2d_2_copy_Edge and conv4_block4_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_Edge
2024-06-13 05:44:55,054 logger.py[line:35] INFO Candidate Edge: ('Cropping2D', 'GlobalAveragePooling2D')
2024-06-13 05:44:56,218 logger.py[line:35] INFO Trying Adding Edge: ['Cropping2D', 'GlobalAveragePooling2D'] by Connecting cropping2d_1_copy_Edge and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_Edge
2024-06-13 05:44:57,161 logger.py[line:35] INFO Successfully Add Edge: ['Cropping2D', 'GlobalAveragePooling2D'] by Connecting cropping2d_1_copy_Edge and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_Edge
2024-06-13 05:44:57,162 logger.py[line:35] INFO Candidate Edge: ('Cropping2D', 'BatchNormalization')
2024-06-13 05:44:58,213 logger.py[line:35] INFO Trying Adding Edge: ['Cropping2D', 'BatchNormalization'] by Connecting cropping2d_1_copy_Edge and conv4_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_Edge
2024-06-13 05:44:59,323 logger.py[line:35] INFO Successfully Add Edge: ['Cropping2D', 'BatchNormalization'] by Connecting cropping2d_1_copy_Edge and conv4_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_Edge
2024-06-13 05:44:59,323 logger.py[line:35] INFO Candidate Edge: ('Cropping2D', 'Cropping2D')
2024-06-13 05:45:00,370 logger.py[line:35] INFO Trying Adding Edge: ['Cropping2D', 'Cropping2D'] by Connecting cropping2d_copy_Edge and cropping2d_1_copy_Edge
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 75, in generate_model_by_model_mutation
    return InteractionMutationUtils.connect_layers(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 209, in connect_layers
    Edge_model = ArchitectureUtils.connect_two_layers(Edge_model, layer1_name, layer2_name)
  File "/root/implementations/scripts/tools/architecture_utils.py", line 635, in connect_two_layers
    edge_output = right_cloned_layer(left_output)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional.py", line 3554, in call
    raise ValueError('Argument `cropping` must be '
ValueError: Exception encountered when calling layer "cropping2d_1_copy_Edge_2" (type Cropping2D).

Argument `cropping` must be greater than the input shape. Received: inputs.shape=(None, 10, 10, 64), and cropping=((110, 110), (110, 110))

Call arguments received:
   inputs=tf.Tensor(shape=(None, 10, 10, 64), dtype=float32)
2024-06-13 05:45:01,926 logger.py[line:35] INFO INFO: Mutation progress 43/100
2024-06-13 05:45:01,926 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:45:01,926 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:45:01,927 logger.py[line:35] INFO Score for Edge is: 0.8114754098360656
2024-06-13 05:45:01,927 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:45:01,927 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:45:01,927 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:45:01,927 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:45:01,927 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:45:01,927 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:45:01,927 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:45:01,927 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:45:01,927 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84
2024-06-13 05:45:01,927 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:45:04,841 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:45:05,548 logger.py[line:35] INFO Generating model using Edge
2024-06-13 05:45:05,551 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge')>}
Choosing 4 To Insert
2024-06-13 05:45:05,768 logger.py[line:35] INFO Insert 4 Global New Edges
2024-06-13 05:45:05,768 logger.py[line:35] INFO Candidate Edge: ('Conv3DTranspose', 'LayerNormalization')
2024-06-13 05:45:05,778 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:45:05,990 logger.py[line:35] INFO Trying Adding Edge: ['Conv3DTranspose', 'LayerNormalization'] by Connecting conv3d_transpose_insert_copy_LMerg_copy_Edge and layer_normalization_insert_copy_LMerg_copy_Edge
2024-06-13 05:45:05,993 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:45:06,224 logger.py[line:35] INFO Successfully Add Edge: ['Conv3DTranspose', 'LayerNormalization'] by Connecting conv3d_transpose_insert_copy_LMerg_copy_Edge and layer_normalization_insert_copy_LMerg_copy_Edge
2024-06-13 05:45:06,224 logger.py[line:35] INFO Candidate Edge: ('LSTM', 'Dropout')
2024-06-13 05:45:06,235 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:45:06,462 logger.py[line:35] INFO Trying Adding Edge: ['LSTM', 'Dropout'] by Connecting lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge and dropout_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge
2024-06-13 05:45:06,465 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:45:06,692 logger.py[line:35] INFO Successfully Add Edge: ['LSTM', 'Dropout'] by Connecting lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge and dropout_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge
2024-06-13 05:45:06,692 logger.py[line:35] INFO Candidate Edge: ('LayerNormalization', 'LayerNormalization')
2024-06-13 05:45:06,706 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:45:07,091 logger.py[line:35] INFO Trying Adding Edge: ['LayerNormalization', 'LayerNormalization'] by Connecting layer_normalization_insert_copy_LMerg_copy_Edge_2 and layer_normalization_insert_copy_LMerg_copy_Edge_1
2024-06-13 05:45:07,094 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:45:07,345 logger.py[line:35] INFO Successfully Add Edge: ['LayerNormalization', 'LayerNormalization'] by Connecting layer_normalization_insert_copy_LMerg_copy_Edge_2 and layer_normalization_insert_copy_LMerg_copy_Edge_1
2024-06-13 05:45:07,345 logger.py[line:35] INFO Candidate Edge: ('Conv3DTranspose', 'GlobalAveragePooling3D')
2024-06-13 05:45:07,357 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:45:07,607 logger.py[line:35] INFO Trying Adding Edge: ['Conv3DTranspose', 'GlobalAveragePooling3D'] by Connecting conv3d_transpose_insert_copy_LMerg_copy_Edge and global_average_pooling3d_insert_copy_LMerg_copy_Edge
2024-06-13 05:45:07,610 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:45:07,858 logger.py[line:35] INFO Successfully Add Edge: ['Conv3DTranspose', 'GlobalAveragePooling3D'] by Connecting conv3d_transpose_insert_copy_LMerg_copy_Edge and global_average_pooling3d_insert_copy_LMerg_copy_Edge
2024-06-13 05:45:07,908 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:45:08,551 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 113/2170
The Configuration Coverage is: 311/2049
The NDims Coverage Is: 54/117
The DType Coverage Is: 60/354
The Shape Coverage Is: 103/295
The Input Coverage Is: 217/766
2024-06-13 05:45:08,817 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:45:09,263 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 280, in convert_operations
    "Conversion not implemented for op_type={}.".format(node.op_type)
NotImplementedError: Conversion not implemented for op_type=ReduceSumSquare.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
Automatic inference of operator: neg
Automatic inference of operator: neg
2024-06-13 05:45:20,344 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 11s
2024-06-13 05:45:20,344 logger.py[line:35] INFO lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84-Edge43 crash on backend pytorch when predicting
2024-06-13 05:45:20,366 logger.py[line:35] INFO coverage_c=14302
2024-06-13 05:45:20,419 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84-Edge43
2024-06-13 05:45:20,419 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:45:20,419 logger.py[line:35] INFO after_prediction
2024-06-13 05:45:20,542 logger.py[line:35] INFO INFO: Mutation progress 44/100
2024-06-13 05:45:20,542 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:45:20,542 logger.py[line:35] INFO Score for NLAll is: 0.8552631578947368
2024-06-13 05:45:20,542 logger.py[line:35] INFO Score for Edge is: 0.8064516129032258
2024-06-13 05:45:20,542 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:45:20,542 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:45:20,542 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:45:20,542 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:45:20,542 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:45:20,542 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:45:20,542 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:45:20,542 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:45:20,542 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype132-SpecialI1-MShape20
2024-06-13 05:45:20,543 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:45:24,859 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll')>, 'custom_cast_layer_5_copy_SpecialI_copy_MShape': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'custom_cast_layer_5_copy_SpecialI_copy_MShape_copy_NLAll')>, 'custom_pad_layer_1': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'custom_pad_layer_1_copy_NLAll')>}
2024-06-13 05:45:26,128 logger.py[line:35] INFO Insert 1 out of 28 Local New Layers
2024-06-13 05:45:26,128 logger.py[line:35] INFO insert ELU after pool1_pad_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ELU object at 0x7f0788049910>
2024-06-13 05:45:26,159 logger.py[line:35] INFO Converting output shape (None, 114, 114, 64) to actual shape [None, 114, 114, 64]
model outputs {'predictions_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll')>, 'custom_cast_layer_5_copy_SpecialI_copy_MShape_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'custom_cast_layer_5_copy_SpecialI_copy_MShape_copy_NLAll')>, 'custom_pad_layer_1_copy_NLAll': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'custom_pad_layer_1_copy_NLAll')>}
2024-06-13 05:45:27,135 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 115/2170
The Configuration Coverage is: 311/2049
The NDims Coverage Is: 54/117
The DType Coverage Is: 60/354
The Shape Coverage Is: 104/295
The Input Coverage Is: 218/766
2024-06-13 05:45:29,238 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:45:29,684 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:45:56,680 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:45:56,681 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[215, 115, 118, 115] to have 3 channels, but got 115 channels instead

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:45:59,036 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 29s
2024-06-13 05:45:59,036 logger.py[line:35] INFO resnet50-Edge65-MDtype132-SpecialI1-MShape20-NLAll44 crash on backend pytorch when predicting
2024-06-13 05:45:59,058 logger.py[line:35] INFO coverage_c=14348
2024-06-13 05:45:59,163 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-Edge65-MDtype132-SpecialI1-MShape20-NLAll44
2024-06-13 05:45:59,163 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:45:59,163 logger.py[line:35] INFO after_prediction
2024-06-13 05:45:59,304 logger.py[line:35] INFO INFO: Mutation progress 45/100
2024-06-13 05:45:59,304 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:45:59,304 logger.py[line:35] INFO Score for NLAll is: 0.8506493506493507
2024-06-13 05:45:59,304 logger.py[line:35] INFO Score for Edge is: 0.8064516129032258
2024-06-13 05:45:59,304 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:45:59,304 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:45:59,304 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:45:59,304 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:45:59,304 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:45:59,304 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:45:59,304 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:45:59,305 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:45:59,305 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype60-MDims77-MDtype88
2024-06-13 05:45:59,305 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:46:02,801 logger.py[line:35] INFO Generating model using MParam
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam')>}
2024-06-13 05:46:02,941 logger.py[line:35] INFO Changing 2/5 of layer batch_normalization_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam's configuration
2024-06-13 05:46:02,941 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 05:46:02,941 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 05:46:02,941 logger.py[line:35] INFO changing config center in layer batch_normalization_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from True to True
2024-06-13 05:46:02,941 logger.py[line:35] INFO changing config axis in layer batch_normalization_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 05:46:02,942 logger.py[line:35] INFO changing config scale in layer batch_normalization_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from True to False
2024-06-13 05:46:02,942 logger.py[line:35] INFO Changing 3/5 of layer batch_normalization_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam's configuration
2024-06-13 05:46:02,942 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 05:46:02,942 logger.py[line:35] INFO changing config axis in layer batch_normalization_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 05:46:02,942 logger.py[line:35] INFO changing config center in layer batch_normalization_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from True to True
2024-06-13 05:46:02,942 logger.py[line:35] INFO changing config scale in layer batch_normalization_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from True to False
2024-06-13 05:46:02,942 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 05:46:02,942 logger.py[line:35] INFO Changing 2/15 of layer conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam's configuration
2024-06-13 05:46:02,942 logger.py[line:35] INFO changing config bias_initializer in layer conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from {'class_name': 'Zeros', 'config': {}} to Constant
2024-06-13 05:46:02,943 logger.py[line:35] INFO changing config padding in layer conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from same to same
2024-06-13 05:46:02,943 logger.py[line:35] INFO changing config bias_constraint in layer conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from None to MaxNorm
2024-06-13 05:46:02,943 logger.py[line:35] INFO Changing 3/15 of layer conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam's configuration
2024-06-13 05:46:02,943 logger.py[line:35] INFO changing config padding in layer conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from same to valid
2024-06-13 05:46:02,943 logger.py[line:35] INFO changing config data_format in layer conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from channels_last to channels_first
2024-06-13 05:46:02,943 logger.py[line:35] INFO changing config kernel_constraint in layer conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from None to MinMaxNorm
2024-06-13 05:46:02,943 logger.py[line:35] INFO changing config bias_constraint in layer conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from None to MinMaxNorm
2024-06-13 05:46:02,943 logger.py[line:35] INFO Changing 3/15 of layer conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam's configuration
2024-06-13 05:46:02,943 logger.py[line:35] INFO changing config kernel_constraint in layer conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from None to MaxNorm
2024-06-13 05:46:02,943 logger.py[line:35] INFO changing config kernel_initializer in layer conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}} to RandomUniform
2024-06-13 05:46:02,943 logger.py[line:35] INFO changing config bias_regularizer in layer conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from None to l1
2024-06-13 05:46:02,943 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 05:46:02,943 logger.py[line:35] INFO changing config bias_initializer in layer conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam: from {'class_name': 'Zeros', 'config': {}} to Ones
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1939, in _create_c_op
    raise ValueError(e.message)
ValueError: Exception encountered when calling layer "max_pooling2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam" (type MaxPooling2D).

Negative dimension size caused by subtracting 3 from 1 for '{{node max_pooling2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDims_copy_MDtype_copy_MParam/MaxPool}} = MaxPool[T=DT_FLOAT, data_format="NHWC", explicit_paddings=[], ksize=[1, 3, 3, 1], padding="VALID", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,127,1,256].

Call arguments received:
   inputs=tf.Tensor(shape=(None, 127, 1, 256), dtype=float32)
2024-06-13 05:46:03,443 logger.py[line:35] INFO INFO: Mutation progress 45/100
2024-06-13 05:46:03,443 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:46:03,443 logger.py[line:35] INFO Score for NLAll is: 0.8506493506493507
2024-06-13 05:46:03,443 logger.py[line:35] INFO Score for Edge is: 0.8064516129032258
2024-06-13 05:46:03,443 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:46:03,443 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:46:03,443 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:46:03,443 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:46:03,443 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:46:03,443 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:46:03,443 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:46:03,444 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:46:03,444 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MDtype39
2024-06-13 05:46:03,444 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:46:07,716 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 05:46:08,956 logger.py[line:35] INFO Insert 3 out of 22 Local New Layers
2024-06-13 05:46:08,956 logger.py[line:35] INFO insert Flatten after conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:46:08,956 logger.py[line:35] INFO insert Conv2DTranspose after conv2_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 05:46:08,957 logger.py[line:35] INFO insert ReLU after conv3_block4_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.core.flatten.Flatten object at 0x7feff8515d50>
2024-06-13 05:46:08,962 logger.py[line:35] INFO Converting output shape (None, 158700) to actual shape [None, 230, 230, 3]
[DEBUG] Inserting layer: <keras.layers.convolutional.Conv2DTranspose object at 0x7feff84424d0>
2024-06-13 05:46:09,157 logger.py[line:35] INFO Converting output shape (None, 64, 56, 64) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ReLU object at 0x7feff8323550>
2024-06-13 05:46:09,406 logger.py[line:35] INFO Converting output shape (None, 28, 28, 512) to actual shape [None, 28, 28, 512]
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 05:46:09,983 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 119/2170
The Configuration Coverage is: 321/2049
The NDims Coverage Is: 54/117
The DType Coverage Is: 60/354
The Shape Coverage Is: 105/295
The Input Coverage Is: 219/766
2024-06-13 05:46:12,121 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:46:12,575 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (151) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:46:37,121 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 05:46:37,122 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-MDtype39-NLAll45 crash on backend pytorch when predicting
2024-06-13 05:46:37,144 logger.py[line:35] INFO coverage_c=14348
2024-06-13 05:46:37,246 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-MDtype39-NLAll45
2024-06-13 05:46:37,246 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:46:37,246 logger.py[line:35] INFO after_prediction
2024-06-13 05:46:37,377 logger.py[line:35] INFO INFO: Mutation progress 46/100
2024-06-13 05:46:37,377 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:46:37,377 logger.py[line:35] INFO Score for NLAll is: 0.8461538461538461
2024-06-13 05:46:37,377 logger.py[line:35] INFO Score for Edge is: 0.8064516129032258
2024-06-13 05:46:37,377 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:46:37,377 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:46:37,377 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:46:37,377 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:46:37,377 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:46:37,377 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:46:37,378 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:46:37,378 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:46:37,378 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-NLAll58
2024-06-13 05:46:37,378 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:46:40,303 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:40,977 logger.py[line:35] INFO Generating model using NLAll
2024-06-13 05:46:40,980 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_NLAll')>}
2024-06-13 05:46:41,155 logger.py[line:35] INFO Insert 10 out of 18 Global New Layers
2024-06-13 05:46:41,155 logger.py[line:35] INFO insert ZeroPadding3D after spatial_dropout3d_insert_copy_NLAll
2024-06-13 05:46:41,155 logger.py[line:35] INFO insert DepthwiseConv1D after repeat_vector_insert_copy_NLAll_copy_NLAll
2024-06-13 05:46:41,155 logger.py[line:35] INFO insert SpatialDropout1D after permute_insert_copy_NLAll
2024-06-13 05:46:41,155 logger.py[line:35] INFO insert SimpleRNN after repeat_vector_insert_copy_NLAll_copy_NLAll
2024-06-13 05:46:41,155 logger.py[line:35] INFO insert Conv1D after permute_insert_copy_NLAll
2024-06-13 05:46:41,155 logger.py[line:35] INFO insert LocallyConnected1D after repeat_vector_insert_copy_NLAll_copy_NLAll
2024-06-13 05:46:41,155 logger.py[line:35] INFO insert MaxPooling3D after up_sampling3d_insert_copy_NLAll_copy_NLAll
2024-06-13 05:46:41,155 logger.py[line:35] INFO insert AveragePooling1D after repeat_vector_insert_copy_NLAll_copy_NLAll
2024-06-13 05:46:41,155 logger.py[line:35] INFO insert Cropping1D after repeat_vector_insert_copy_NLAll_copy_NLAll
2024-06-13 05:46:41,155 logger.py[line:35] INFO insert ZeroPadding1D after permute_insert_copy_NLAll
2024-06-13 05:46:41,155 logger.py[line:35] INFO Insert 6 out of 24 Local New Layers
2024-06-13 05:46:41,156 logger.py[line:35] INFO insert Dropout after spatial_dropout3d_insert_copy_NLAll
2024-06-13 05:46:41,156 logger.py[line:35] INFO insert GaussianNoise after lstm_1_copy_NLAll_copy_NLAll_copy_NLAll
2024-06-13 05:46:41,156 logger.py[line:35] INFO insert ActivityRegularization after up_sampling3d_insert_copy_NLAll_copy_NLAll
2024-06-13 05:46:41,156 logger.py[line:35] INFO insert SpatialDropout3D after spatial_dropout3d_insert_copy_NLAll
2024-06-13 05:46:41,156 logger.py[line:35] INFO insert ReLU after lstm_1_copy_NLAll_copy_NLAll_copy_NLAll
2024-06-13 05:46:41,156 logger.py[line:35] INFO insert Conv3DTranspose after spatial_dropout3d_insert_copy_NLAll
2024-06-13 05:46:41,156 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 5
2024-06-13 05:46:41,157 logger.py[line:35] INFO insert Softmax after custom_crop_layer_copy_NLAll_copy_NLAll
2024-06-13 05:46:41,157 logger.py[line:35] INFO Fail to find suitable insertion point for dimension: [6]
2024-06-13 05:46:41,157 logger.py[line:35] INFO insert ConvLSTM3D after up_sampling3d_insert_copy_NLAll_copy_NLAll
2024-06-13 05:46:41,158 logger.py[line:35] INFO insert SpatialDropout3D after spatial_dropout3d_insert_copy_NLAll
2024-06-13 05:46:41,158 logger.py[line:35] INFO insert LocallyConnected1D after custom_crop_layer_copy_NLAll
2024-06-13 05:46:41,159 logger.py[line:35] INFO insert UpSampling3D after spatial_dropout3d_insert_copy_NLAll
2024-06-13 05:46:41,162 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ReLU object at 0x7f138002ba10>
2024-06-13 05:46:41,257 logger.py[line:35] INFO Converting output shape (None, 25) to actual shape [None, 25]
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 62, in new_layer_addition
    layer_list = selected_layer(output_shape)
  File "/root/implementations/scripts/generation/layer_pools.py", line 489, in conv_lstm_3d
    inserted_layer = ConfigurationUtils.random_config(candidate_layer)
  File "/root/implementations/scripts/generation/layer_pools.py", line 57, in random_config
    new_layer = layer.from_config(layer_config)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 970, in from_config
    return cls(**config)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 1466, in __init__
    **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 842, in __init__
    **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 141, in __init__
    'Unrolling is not possible with convolutional RNNs. '
TypeError: Unrolling is not possible with convolutional RNNs. Received: unroll=True
2024-06-13 05:46:41,729 logger.py[line:35] INFO INFO: Mutation progress 46/100
2024-06-13 05:46:41,729 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:46:41,729 logger.py[line:35] INFO Score for NLAll is: 0.8461538461538461
2024-06-13 05:46:41,730 logger.py[line:35] INFO Score for Edge is: 0.8064516129032258
2024-06-13 05:46:41,730 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:46:41,730 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:46:41,730 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:46:41,730 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:46:41,730 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:46:41,730 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:46:41,730 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:46:41,730 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:46:41,730 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97
2024-06-13 05:46:41,730 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:46:44,655 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:44,668 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:45,486 logger.py[line:35] INFO Generating model using Edge
2024-06-13 05:46:45,489 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:45,713 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_copy_Edge')>, 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge')>, 'cropping3d': <KerasTensor: shape=(None, 1, 11, 11, 2025) dtype=float32 (created by layer 'cropping3d_copy_Edge')>, 'lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge')>, 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 2, 25) dtype=float32 (created by layer 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_Edge')>}
Choosing 6 To Insert
2024-06-13 05:46:45,811 logger.py[line:35] INFO Insert 5 Global New Edges
2024-06-13 05:46:45,811 logger.py[line:35] INFO Insert 1 Local New Edges
2024-06-13 05:46:45,812 logger.py[line:35] INFO Candidate Edge: ('Cropping3D', 'UpSampling3D')
2024-06-13 05:46:45,822 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:45,837 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:46,149 logger.py[line:35] INFO Trying Adding Edge: ['Cropping3D', 'UpSampling3D'] by Connecting cropping3d_copy_Edge and up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge
2024-06-13 05:46:46,152 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:46,374 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:46,817 logger.py[line:35] INFO Successfully Add Edge: ['Cropping3D', 'UpSampling3D'] by Connecting cropping3d_copy_Edge and up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge
2024-06-13 05:46:46,817 logger.py[line:35] INFO Candidate Edge: ('Cropping3D', 'Cropping3D')
2024-06-13 05:46:46,828 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:46,840 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:47,585 logger.py[line:35] INFO Trying Adding Edge: ['Cropping3D', 'Cropping3D'] by Connecting cropping3d_copy_Edge and cropping3d_copy_Edge
2024-06-13 05:46:47,588 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:48,174 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:48,291 logger.py[line:35] INFO Successfully Add Edge: ['Cropping3D', 'Cropping3D'] by Connecting cropping3d_copy_Edge and cropping3d_copy_Edge
2024-06-13 05:46:48,292 logger.py[line:35] INFO Candidate Edge: ('Cropping3D', 'Dropout')
2024-06-13 05:46:48,303 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:48,316 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:48,975 logger.py[line:35] INFO Trying Adding Edge: ['Cropping3D', 'Dropout'] by Connecting cropping3d_copy_Edge_1 and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge
2024-06-13 05:46:48,979 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:49,550 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:49,665 logger.py[line:35] INFO Successfully Add Edge: ['Cropping3D', 'Dropout'] by Connecting cropping3d_copy_Edge_1 and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge
2024-06-13 05:46:49,665 logger.py[line:35] INFO Candidate Edge: ('Dropout', 'LSTM')
2024-06-13 05:46:49,678 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:49,691 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:50,369 logger.py[line:35] INFO Trying Adding Edge: ['Dropout', 'LSTM'] by Connecting dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge_1 and lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge
2024-06-13 05:46:50,373 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:50,467 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:50,960 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:51,168 logger.py[line:35] INFO Successfully Add Edge: ['Dropout', 'LSTM'] by Connecting dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge_1 and lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge
2024-06-13 05:46:51,168 logger.py[line:35] INFO Candidate Edge: ('Dropout', 'Dropout')
2024-06-13 05:46:51,180 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:51,196 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:51,200 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:51,968 logger.py[line:35] INFO Trying Adding Edge: ['Dropout', 'Dropout'] by Connecting dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_1_copy_Edge and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge_1
2024-06-13 05:46:51,972 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:52,549 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:52,660 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:52,755 logger.py[line:35] INFO Successfully Add Edge: ['Dropout', 'Dropout'] by Connecting dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_1_copy_Edge and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge_1
2024-06-13 05:46:52,755 logger.py[line:35] INFO Candidate Edge: ('UpSampling3D', 'Cropping3D')
2024-06-13 05:46:52,768 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:52,780 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:52,786 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:53,725 logger.py[line:35] INFO Trying Adding Edge: ['UpSampling3D', 'Cropping3D'] by Connecting up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge_2 and cropping3d
2024-06-13 05:46:53,728 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:54,300 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:54,413 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:54,511 logger.py[line:35] INFO Successfully Add Edge: ['UpSampling3D', 'Cropping3D'] by Connecting up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge_2 and cropping3d
2024-06-13 05:46:54,599 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:46:59,182 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:59,195 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:46:59,199 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 123/2170
The Configuration Coverage is: 322/2049
The NDims Coverage Is: 54/117
The DType Coverage Is: 61/354
The Shape Coverage Is: 109/295
The Input Coverage Is: 224/766
2024-06-13 05:46:59,966 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:47:00,412 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97-Edge46/lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97-Edge46.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:52:03,013 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 5m, 2s
2024-06-13 05:52:03,014 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97-Edge46 crash on backend pytorch when predicting
2024-06-13 05:52:03,038 logger.py[line:35] INFO coverage_c=14348
2024-06-13 05:52:03,049 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97-Edge46
2024-06-13 05:52:03,049 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:52:03,050 logger.py[line:35] INFO after_prediction
2024-06-13 05:52:03,185 logger.py[line:35] INFO INFO: Mutation progress 47/100
2024-06-13 05:52:03,186 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:52:03,186 logger.py[line:35] INFO Score for NLAll is: 0.8461538461538461
2024-06-13 05:52:03,186 logger.py[line:35] INFO Score for Edge is: 0.8015873015873016
2024-06-13 05:52:03,186 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:52:03,186 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:52:03,186 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:52:03,186 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:52:03,186 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:52:03,186 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:52:03,186 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:52:03,186 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:52:03,186 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype132-SpecialI1-MShape20-Edge90
2024-06-13 05:52:03,186 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:52:07,500 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_MParam')>, 'custom_cast_layer_5_copy_SpecialI_copy_MShape_copy_Edge': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'custom_cast_layer_5_copy_SpecialI_copy_MShape_copy_Edge_copy_MParam')>, 'custom_pad_layer_1_copy_Edge': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'custom_pad_layer_1_copy_Edge_copy_MParam')>, 'conv4_block1_0_bn_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'conv4_block1_0_bn_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2_copy_MParam')>, 'conv3_block3_2_conv_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'conv3_block3_2_conv_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2_copy_MParam')>, 'avg_pool_copy_Edge_1_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2': <KerasTensor: shape=(None, 512) dtype=float32 (created by layer 'avg_pool_copy_Edge_1_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_2_copy_MParam')>}
2024-06-13 05:52:08,528 logger.py[line:35] INFO Changing 3/5 of layer conv4_block1_3_bn_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_MParam's configuration
2024-06-13 05:52:08,528 logger.py[line:35] INFO changing config axis in layer conv4_block1_3_bn_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 05:52:08,528 logger.py[line:35] INFO changing config scale in layer conv4_block1_3_bn_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_MParam: from True to False
2024-06-13 05:52:08,528 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 05:52:08,529 logger.py[line:35] INFO changing config center in layer conv4_block1_3_bn_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_MParam: from True to False
2024-06-13 05:52:08,529 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 05:52:08,529 logger.py[line:35] INFO Changing 1/15 of layer conv3_block2_2_conv_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_MParam's configuration
2024-06-13 05:52:08,529 logger.py[line:35] INFO changing config bias_constraint in layer conv3_block2_2_conv_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_MParam: from None to Constraint
2024-06-13 05:52:08,529 logger.py[line:35] INFO changing config data_format in layer conv3_block2_2_conv_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_Edge_copy_MParam: from channels_last to channels_first
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/merge.py", line 79, in _compute_elemwise_op_output_shape
    'Inputs have incompatible shapes. '
ValueError: Inputs have incompatible shapes. Received shapes (28, 28, 512) and (128, 28, 512)
2024-06-13 05:52:09,298 logger.py[line:35] INFO INFO: Mutation progress 47/100
2024-06-13 05:52:09,298 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:52:09,298 logger.py[line:35] INFO Score for NLAll is: 0.8461538461538461
2024-06-13 05:52:09,298 logger.py[line:35] INFO Score for Edge is: 0.8015873015873016
2024-06-13 05:52:09,298 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:52:09,298 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:52:09,298 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:52:09,298 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:52:09,298 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:52:09,298 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:52:09,298 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:52:09,298 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:52:09,299 logger.py[line:35] INFO Choose seed: lenet-LMerg90-NLAll105-NLAll116-Edge130-LMerg32-LMerg63
2024-06-13 05:52:09,299 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:52:12,822 logger.py[line:35] INFO Generating model using MDtype
model outputs {'dense_15_copy_LMerg_copy_NLAll_copy_NLAll_copy_Edge_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_15_copy_LMerg_copy_NLAll_copy_NLAll_copy_Edge_copy_LMerg_copy_LMerg_copy_MDtype')>, 'dot_copy_ML_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 10, 10) dtype=float32 (created by layer 'dot_copy_ML_copy_LMerg_copy_MDtype')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_1_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 14, 14, 6) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_1_copy_LMerg_copy_LMerg_copy_MDtype')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_2_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 120) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_2_copy_LMerg_copy_LMerg_copy_MDtype')>, 'elu_insert_copy_Edge_1_2_1_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 120) dtype=float32 (created by layer 'elu_insert_copy_Edge_1_2_1_copy_LMerg_copy_LMerg_copy_MDtype')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_1_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 16) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_1_copy_LMerg_copy_LMerg_copy_MDtype')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_2_copy_LMerg_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 16) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_2_copy_LMerg_copy_LMerg_copy_MDtype')>, 'concatenate_copy_ML': <KerasTensor: shape=(None, 10, 4) dtype=float32 (created by layer 'concatenate_copy_ML_copy_MDtype')>}
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 91, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dtype(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 403, in mutate_dtype
    mode=mutation_mode
  File "/root/implementations/scripts/tools/architecture_utils.py", line 990, in choose_layers_for_mdtype
    current_dtype_set = set(input_diversity[layer_class]["dtype"])
KeyError: 'Cropping1D'
2024-06-13 05:52:13,403 logger.py[line:35] INFO INFO: Mutation progress 47/100
2024-06-13 05:52:13,403 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:52:13,403 logger.py[line:35] INFO Score for NLAll is: 0.8461538461538461
2024-06-13 05:52:13,403 logger.py[line:35] INFO Score for Edge is: 0.8015873015873016
2024-06-13 05:52:13,403 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:52:13,403 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:52:13,403 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:52:13,403 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:52:13,403 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:52:13,403 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:52:13,403 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:52:13,403 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:52:13,404 logger.py[line:35] INFO Choose seed: densenet121-MDims75
2024-06-13 05:52:13,404 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:52:18,854 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_MDims': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MDims_copy_Edge')>}
Choosing 8 To Insert
2024-06-13 05:52:20,745 logger.py[line:35] INFO Insert 8 Local New Edges
2024-06-13 05:52:20,745 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'ZeroPadding2D')
2024-06-13 05:52:23,048 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'ZeroPadding2D'] by Connecting conv2_block6_0_bn_copy_MDims_copy_Edge and zero_padding2d_1_copy_MDims_copy_Edge
2024-06-13 05:52:25,061 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'ZeroPadding2D'] by Connecting conv2_block6_0_bn_copy_MDims_copy_Edge and zero_padding2d_1_copy_MDims_copy_Edge
2024-06-13 05:52:25,061 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'BatchNormalization')
2024-06-13 05:52:27,272 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting conv4_block3_1_bn_copy_MDims_copy_Edge and conv4_block17_1_bn_copy_MDims_copy_Edge
2024-06-13 05:52:29,360 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting conv4_block3_1_bn_copy_MDims_copy_Edge and conv4_block17_1_bn_copy_MDims_copy_Edge
2024-06-13 05:52:29,360 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'GlobalAveragePooling2D')
2024-06-13 05:52:31,583 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'GlobalAveragePooling2D'] by Connecting conv5_block7_2_conv_copy_MDims_copy_Edge and avg_pool_copy_MDims_copy_Edge
2024-06-13 05:52:33,476 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'GlobalAveragePooling2D'] by Connecting conv5_block7_2_conv_copy_MDims_copy_Edge and avg_pool_copy_MDims_copy_Edge
2024-06-13 05:52:33,476 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'ZeroPadding2D')
2024-06-13 05:52:35,911 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'ZeroPadding2D'] by Connecting pool2_pool_copy_MDims_copy_Edge and zero_padding2d_2_copy_MDims_copy_Edge
2024-06-13 05:52:37,800 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'ZeroPadding2D'] by Connecting pool2_pool_copy_MDims_copy_Edge and zero_padding2d_2_copy_MDims_copy_Edge
2024-06-13 05:52:37,800 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'MaxPooling2D')
2024-06-13 05:52:40,293 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'MaxPooling2D'] by Connecting conv4_block2_0_bn_copy_MDims_copy_Edge and pool1_copy_MDims_copy_Edge
2024-06-13 05:52:42,180 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'MaxPooling2D'] by Connecting conv4_block2_0_bn_copy_MDims_copy_Edge and pool1_copy_MDims_copy_Edge
2024-06-13 05:52:42,180 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'GlobalAveragePooling2D')
2024-06-13 05:52:44,582 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'GlobalAveragePooling2D'] by Connecting conv5_block11_0_bn_copy_MDims_copy_Edge and avg_pool_copy_MDims_copy_Edge_2
2024-06-13 05:52:46,592 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'GlobalAveragePooling2D'] by Connecting conv5_block11_0_bn_copy_MDims_copy_Edge and avg_pool_copy_MDims_copy_Edge_2
2024-06-13 05:52:46,592 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'Conv2D')
2024-06-13 05:52:48,831 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'Conv2D'] by Connecting conv4_block17_1_bn_copy_MDims_copy_Edge_2 and conv3_block1_2_conv_copy_MDims_copy_Edge
2024-06-13 05:52:50,728 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'Conv2D'] by Connecting conv4_block17_1_bn_copy_MDims_copy_Edge_2 and conv3_block1_2_conv_copy_MDims_copy_Edge
2024-06-13 05:52:50,728 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'BatchNormalization')
2024-06-13 05:52:53,190 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'BatchNormalization'] by Connecting pool1_copy_MDims_copy_Edge_1 and conv5_block5_1_bn_copy_MDims_copy_Edge
2024-06-13 05:52:55,101 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'BatchNormalization'] by Connecting pool1_copy_MDims_copy_Edge_1 and conv5_block5_1_bn_copy_MDims_copy_Edge
2024-06-13 05:52:55,531 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 123/2170
The Configuration Coverage is: 322/2049
The NDims Coverage Is: 54/117
The DType Coverage Is: 61/354
The Shape Coverage Is: 109/295
The Input Coverage Is: 224/766
2024-06-13 05:52:59,003 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:52:59,454 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:53:25,047 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:53:25,047 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/reshape.py", line 31, in forward
    return torch.reshape(input, tuple(shape))
RuntimeError: shape '[-1, 6272]' is invalid for input of size 594048

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:53:30,408 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 30s
2024-06-13 05:53:30,409 logger.py[line:35] INFO densenet121-MDims75-Edge47 crash on backend pytorch when predicting
2024-06-13 05:53:30,431 logger.py[line:35] INFO coverage_c=14393
2024-06-13 05:53:30,534 logger.py[line:35] INFO Fail on backend: pytorch of model densenet121-MDims75-Edge47
2024-06-13 05:53:30,534 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:53:30,534 logger.py[line:35] INFO after_prediction
2024-06-13 05:53:30,534 logger.py[line:35] INFO No representative seed generated: densenet121-MDims75-Edge47, do not increase the reward
2024-06-13 05:53:30,689 logger.py[line:35] INFO INFO: Mutation progress 48/100
2024-06-13 05:53:30,689 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:53:30,689 logger.py[line:35] INFO Score for NLAll is: 0.8461538461538461
2024-06-13 05:53:30,689 logger.py[line:35] INFO Score for MDtype is: 0.8013698630136986
2024-06-13 05:53:30,689 logger.py[line:35] INFO Score for Edge is: 0.7890625
2024-06-13 05:53:30,689 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:53:30,689 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:53:30,689 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:53:30,689 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:53:30,689 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:53:30,690 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:53:30,690 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:53:30,690 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype60
2024-06-13 05:53:30,690 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:53:34,024 logger.py[line:35] INFO Generating model using MDtype
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype')>}
2024-06-13 05:53:34,130 logger.py[line:35] INFO Change 2 Layer's DType Out Of 5 Layer classes
2024-06-13 05:53:34,130 logger.py[line:35] INFO Changing 2 out of 5 Layer's DType.
2024-06-13 05:53:34,130 logger.py[line:35] INFO Selecting a Global DType double For Layer max_pooling2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype
2024-06-13 05:53:34,131 logger.py[line:35] INFO Selecting a Global DType half For Layer conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype')>}
2024-06-13 05:53:34,261 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 123/2170
The Configuration Coverage is: 322/2049
The NDims Coverage Is: 54/117
The DType Coverage Is: 61/354
The Shape Coverage Is: 109/295
The Input Coverage Is: 224/766
2024-06-13 05:53:34,992 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:53:35,445 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (34) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:53:55,036 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 19s
2024-06-13 05:53:55,036 logger.py[line:35] INFO alexnet-SpecialI120-MDims44-MDtype60-MDtype48 crash on backend pytorch when predicting
2024-06-13 05:53:55,059 logger.py[line:35] INFO coverage_c=14393
2024-06-13 05:53:55,106 logger.py[line:35] INFO Fail on backend: pytorch of model alexnet-SpecialI120-MDims44-MDtype60-MDtype48
2024-06-13 05:53:55,106 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:53:55,106 logger.py[line:35] INFO after_prediction
2024-06-13 05:53:55,106 logger.py[line:35] INFO No representative seed generated: alexnet-SpecialI120-MDims44-MDtype60-MDtype48, do not increase the reward
2024-06-13 05:53:55,215 logger.py[line:35] INFO INFO: Mutation progress 49/100
2024-06-13 05:53:55,216 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:53:55,216 logger.py[line:35] INFO Score for NLAll is: 0.8461538461538461
2024-06-13 05:53:55,216 logger.py[line:35] INFO Score for MDtype is: 0.7905405405405406
2024-06-13 05:53:55,216 logger.py[line:35] INFO Score for Edge is: 0.7890625
2024-06-13 05:53:55,216 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:53:55,216 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:53:55,216 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:53:55,216 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:53:55,216 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:53:55,216 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:53:55,216 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:53:55,216 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-NLAll99
2024-06-13 05:53:55,216 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:53:59,548 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll')>}
2024-06-13 05:54:00,807 logger.py[line:35] INFO Insert 5 out of 22 Local New Layers
2024-06-13 05:54:00,807 logger.py[line:35] INFO insert TimeDistributed after conv4_block1_0_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:54:00,807 logger.py[line:35] INFO insert ReLU after global_max_pooling2d_insert_copy_NLAll
2024-06-13 05:54:00,807 logger.py[line:35] INFO insert ActivityRegularization after pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:54:00,807 logger.py[line:35] INFO insert Softmax after avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 05:54:00,807 logger.py[line:35] INFO insert Conv2DTranspose after pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.convolutional.Conv2DTranspose object at 0x7f67901c9050>
2024-06-13 05:54:00,850 logger.py[line:35] INFO Converting output shape (None, 64, 119, 71) to actual shape [None, 114, 114, 64]
[DEBUG] Inserting layer: <keras.layers.core.activity_regularization.ActivityRegularization object at 0x7f6790183d10>
2024-06-13 05:54:00,864 logger.py[line:35] INFO Converting output shape (None, 56, 56, 64) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ReLU object at 0x7f679010fe10>
2024-06-13 05:54:00,978 logger.py[line:35] INFO Converting output shape (None, 56) to actual shape [None, 56]
[DEBUG] Inserting layer: <keras.layers.wrappers.TimeDistributed object at 0x7f67587cfa50>
2024-06-13 05:54:01,324 logger.py[line:35] INFO Converting output shape (None, 14, 14, 1024) to actual shape [None, 14, 14, 1024]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.Softmax object at 0x7f67586647d0>
2024-06-13 05:54:01,765 logger.py[line:35] INFO Converting output shape (None, 2048) to actual shape [None, 2048]
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_NLAll')>}
2024-06-13 05:54:01,861 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 129/2170
The Configuration Coverage is: 328/2049
The NDims Coverage Is: 55/117
The DType Coverage Is: 62/354
The Shape Coverage Is: 114/295
The Input Coverage Is: 231/766
2024-06-13 05:54:03,791 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:54:04,279 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (155) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:54:28,876 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 05:54:28,876 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-NLAll99-NLAll49 crash on backend pytorch when predicting
2024-06-13 05:54:28,897 logger.py[line:35] INFO coverage_c=14393
2024-06-13 05:54:28,959 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-NLAll99-NLAll49
2024-06-13 05:54:28,959 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:54:28,959 logger.py[line:35] INFO after_prediction
2024-06-13 05:54:29,150 logger.py[line:35] INFO INFO: Mutation progress 50/100
2024-06-13 05:54:29,150 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:54:29,150 logger.py[line:35] INFO Score for NLAll is: 0.8417721518987342
2024-06-13 05:54:29,150 logger.py[line:35] INFO Score for MDtype is: 0.7905405405405406
2024-06-13 05:54:29,150 logger.py[line:35] INFO Score for Edge is: 0.7890625
2024-06-13 05:54:29,150 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:54:29,150 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:54:29,150 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:54:29,150 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:54:29,150 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:54:29,151 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:54:29,151 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:54:29,151 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype64
2024-06-13 05:54:29,151 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:54:32,535 logger.py[line:35] INFO Generating model using MDtype
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype')>}
2024-06-13 05:54:32,639 logger.py[line:35] INFO Change 2 Layer's DType Out Of 5 Layer classes
2024-06-13 05:54:32,639 logger.py[line:35] INFO Changing 2 out of 5 Layer's DType.
2024-06-13 05:54:32,639 logger.py[line:35] INFO Selecting a Global DType float64 For Layer flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype
2024-06-13 05:54:32,639 logger.py[line:35] INFO Selecting a Global DType float16 For Layer dropout_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype')>}
2024-06-13 05:54:32,767 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 129/2170
The Configuration Coverage is: 328/2049
The NDims Coverage Is: 55/117
The DType Coverage Is: 63/354
The Shape Coverage Is: 114/295
The Input Coverage Is: 232/766
2024-06-13 05:54:33,509 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:54:33,977 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (35) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:54:54,268 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 20s
2024-06-13 05:54:54,268 logger.py[line:35] INFO alexnet-SpecialI120-MDims44-MDtype64-MDtype50 crash on backend pytorch when predicting
2024-06-13 05:54:54,289 logger.py[line:35] INFO coverage_c=14393
2024-06-13 05:54:54,347 logger.py[line:35] INFO Fail on backend: pytorch of model alexnet-SpecialI120-MDims44-MDtype64-MDtype50
2024-06-13 05:54:54,348 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:54:54,348 logger.py[line:35] INFO after_prediction
2024-06-13 05:54:54,500 logger.py[line:35] INFO INFO: Mutation progress 51/100
2024-06-13 05:54:54,500 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:54:54,500 logger.py[line:35] INFO Score for NLAll is: 0.8417721518987342
2024-06-13 05:54:54,500 logger.py[line:35] INFO Score for Edge is: 0.7890625
2024-06-13 05:54:54,500 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:54:54,500 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:54:54,501 logger.py[line:35] INFO Score for LMerg is: 0.775
2024-06-13 05:54:54,501 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:54:54,501 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:54:54,501 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:54:54,501 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:54:54,501 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:54:54,501 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42
2024-06-13 05:54:54,501 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:54:58,797 logger.py[line:35] INFO Generating model using LMerg
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 05:54:59,877 logger.py[line:35] INFO Insert 1 out of 2 Global New Layers
2024-06-13 05:54:59,879 logger.py[line:35] INFO Trying Merge Layers: conv2_block2_2_relu_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg by Maximum
2024-06-13 05:55:00,869 logger.py[line:35] INFO Success on Merge Layers: conv2_block2_2_relu_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_LMerg by Maximum
2024-06-13 05:55:01,026 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 129/2170
The Configuration Coverage is: 333/2049
The NDims Coverage Is: 55/117
The DType Coverage Is: 63/354
The Shape Coverage Is: 117/295
The Input Coverage Is: 235/766
2024-06-13 05:55:03,178 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:55:03,647 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:55:38,387 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:55:38,388 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: expected scalar type Float but found Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:55:42,562 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 38s
2024-06-13 05:55:42,562 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42-LMerg51 crash on backend pytorch when predicting
2024-06-13 05:55:42,584 logger.py[line:35] INFO coverage_c=14446
2024-06-13 05:55:42,647 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42-LMerg51
2024-06-13 05:55:42,647 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:55:42,647 logger.py[line:35] INFO after_prediction
2024-06-13 05:55:42,837 logger.py[line:35] INFO INFO: Mutation progress 52/100
2024-06-13 05:55:42,837 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:55:42,843 logger.py[line:35] INFO Score for NLAll is: 0.8417721518987342
2024-06-13 05:55:42,843 logger.py[line:35] INFO Score for Edge is: 0.7890625
2024-06-13 05:55:42,843 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:55:42,843 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:55:42,843 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:55:42,843 logger.py[line:35] INFO Score for LMerg is: 0.7619047619047619
2024-06-13 05:55:42,843 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:55:42,843 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:55:42,843 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 05:55:42,843 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:55:42,843 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-NLAll99-MParam30-MParam53
2024-06-13 05:55:42,843 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:55:47,184 logger.py[line:35] INFO Generating model using MDims
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MParam_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MParam_copy_MParam_copy_MDims')>}
2024-06-13 05:55:48,191 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 05:55:48,192 logger.py[line:35] INFO Global Layer Class: 1; Local Layer Class: 0; Total Layer Class: 1
2024-06-13 05:55:48,192 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 05:55:48,193 logger.py[line:35] INFO Selecting a Global NDims 3 For Layer conv5_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MParam_copy_MParam_copy_MDims
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 88, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dims(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 377, in mutate_dims
    new_model = InputMutationUtils.mdims(MDims_model, selected_layer_ndims_pair, revert_shape=True)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 349, in mdims
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 340, in mdims_layer_addition
    layer_input = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/normalization/batch_normalization.py", line 313, in build
    f'Invalid axis. Expected 0 <= axis < inputs.rank (with '
ValueError: Invalid axis. Expected 0 <= axis < inputs.rank (with inputs.rank=3). Received: layer.axis=ListWrapper([3])
2024-06-13 05:55:49,563 logger.py[line:35] INFO INFO: Mutation progress 52/100
2024-06-13 05:55:49,563 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:55:49,563 logger.py[line:35] INFO Score for NLAll is: 0.8417721518987342
2024-06-13 05:55:49,563 logger.py[line:35] INFO Score for Edge is: 0.7890625
2024-06-13 05:55:49,563 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:55:49,563 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:55:49,563 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:55:49,563 logger.py[line:35] INFO Score for LMerg is: 0.7619047619047619
2024-06-13 05:55:49,563 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:55:49,563 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:55:49,564 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:55:49,564 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:55:49,564 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94
2024-06-13 05:55:49,564 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:55:53,875 logger.py[line:35] INFO Generating model using LMerg
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 05:55:54,852 logger.py[line:35] INFO Insert 1 out of 1 Global New Layers
2024-06-13 05:55:54,854 logger.py[line:35] INFO Trying Merge Layers: conv3_block3_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_LMerg and custom_crop_layer_copy_MDtype_copy_MParam_copy_LMerg by Multiply
2024-06-13 05:55:55,746 logger.py[line:35] INFO Success on Merge Layers: conv3_block3_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_LMerg and custom_crop_layer_copy_MDtype_copy_MParam_copy_LMerg by Multiply
2024-06-13 05:55:55,823 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 129/2170
The Configuration Coverage is: 333/2049
The NDims Coverage Is: 55/117
The DType Coverage Is: 63/354
The Shape Coverage Is: 117/295
The Input Coverage Is: 235/766
2024-06-13 05:55:57,733 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:55:58,198 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (136) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:56:22,394 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 05:56:22,395 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-MParam94-LMerg52 crash on backend pytorch when predicting
2024-06-13 05:56:22,416 logger.py[line:35] INFO coverage_c=14446
2024-06-13 05:56:22,477 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-MParam94-LMerg52
2024-06-13 05:56:22,477 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:56:22,478 logger.py[line:35] INFO after_prediction
2024-06-13 05:56:22,739 logger.py[line:35] INFO INFO: Mutation progress 53/100
2024-06-13 05:56:22,739 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:56:22,739 logger.py[line:35] INFO Score for NLAll is: 0.8417721518987342
2024-06-13 05:56:22,739 logger.py[line:35] INFO Score for Edge is: 0.7890625
2024-06-13 05:56:22,739 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:56:22,739 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:56:22,739 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:56:22,739 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 05:56:22,739 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:56:22,739 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:56:22,739 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 05:56:22,740 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:56:22,740 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-LMerg70
2024-06-13 05:56:22,740 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:56:27,153 logger.py[line:35] INFO Generating model using MDims
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MDims')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MDims')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MDims')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MDims')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MDims')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MDims')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MDims')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MDims')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MDims')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MDims')>}
2024-06-13 05:56:28,212 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 05:56:28,212 logger.py[line:35] INFO Global Layer Class: 1; Local Layer Class: 0; Total Layer Class: 1
2024-06-13 05:56:28,212 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 05:56:28,213 logger.py[line:35] INFO Selecting a Global NDims 3 For Layer conv2_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_MDims
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 88, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dims(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 377, in mutate_dims
    new_model = InputMutationUtils.mdims(MDims_model, selected_layer_ndims_pair, revert_shape=True)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 349, in mdims
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 340, in mdims_layer_addition
    layer_input = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/normalization/batch_normalization.py", line 313, in build
    f'Invalid axis. Expected 0 <= axis < inputs.rank (with '
ValueError: Invalid axis. Expected 0 <= axis < inputs.rank (with inputs.rank=3). Received: layer.axis=ListWrapper([3])
2024-06-13 05:56:28,909 logger.py[line:35] INFO INFO: Mutation progress 53/100
2024-06-13 05:56:28,909 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:56:28,909 logger.py[line:35] INFO Score for NLAll is: 0.8417721518987342
2024-06-13 05:56:28,909 logger.py[line:35] INFO Score for Edge is: 0.7890625
2024-06-13 05:56:28,909 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:56:28,909 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:56:28,909 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:56:28,909 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 05:56:28,909 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:56:28,910 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:56:28,910 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:56:28,910 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:56:28,910 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-LMerg10-NLAll66
2024-06-13 05:56:28,910 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:56:33,077 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_LMerg_copy_LMerg_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge')>}
Choosing 10 To Insert
2024-06-13 05:56:34,052 logger.py[line:35] INFO Insert 4 Global New Edges
2024-06-13 05:56:34,052 logger.py[line:35] INFO Insert 6 Local New Edges
2024-06-13 05:56:34,052 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'ThresholdedReLU')
2024-06-13 05:56:35,013 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'ThresholdedReLU'] by Connecting pool1_pad_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and thresholded_re_lu_insert_copy_Edge
2024-06-13 05:56:35,903 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'ThresholdedReLU'] by Connecting pool1_pad_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and thresholded_re_lu_insert_copy_Edge
2024-06-13 05:56:35,903 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'ThresholdedReLU')
2024-06-13 05:56:37,042 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'ThresholdedReLU'] by Connecting pool1_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and thresholded_re_lu_insert_copy_Edge_1
2024-06-13 05:56:37,938 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'ThresholdedReLU'] by Connecting pool1_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and thresholded_re_lu_insert_copy_Edge_1
2024-06-13 05:56:37,939 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'ThresholdedReLU')
2024-06-13 05:56:38,919 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'ThresholdedReLU'] by Connecting conv3_block2_2_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and thresholded_re_lu_insert_copy_Edge_1_1
2024-06-13 05:56:39,815 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'ThresholdedReLU'] by Connecting conv3_block2_2_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and thresholded_re_lu_insert_copy_Edge_1_1
2024-06-13 05:56:39,815 logger.py[line:35] INFO Candidate Edge: ('ThresholdedReLU', 'ThresholdedReLU')
2024-06-13 05:56:41,003 logger.py[line:35] INFO Trying Adding Edge: ['ThresholdedReLU', 'ThresholdedReLU'] by Connecting thresholded_re_lu_insert_copy_Edge_2 and thresholded_re_lu_insert_copy_Edge_1_1_1
2024-06-13 05:56:41,916 logger.py[line:35] INFO Successfully Add Edge: ['ThresholdedReLU', 'ThresholdedReLU'] by Connecting thresholded_re_lu_insert_copy_Edge_2 and thresholded_re_lu_insert_copy_Edge_1_1_1
2024-06-13 05:56:41,917 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'GlobalAveragePooling2D')
2024-06-13 05:56:42,906 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'GlobalAveragePooling2D'] by Connecting conv4_block3_2_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and avg_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge
2024-06-13 05:56:43,999 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'GlobalAveragePooling2D'] by Connecting conv4_block3_2_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and avg_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge
2024-06-13 05:56:43,999 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'BatchNormalization')
2024-06-13 05:56:44,991 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'BatchNormalization'] by Connecting conv3_block4_1_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and conv2_block1_3_bn_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge
2024-06-13 05:56:45,901 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'BatchNormalization'] by Connecting conv3_block4_1_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and conv2_block1_3_bn_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge
2024-06-13 05:56:45,901 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'GlobalAveragePooling2D')
2024-06-13 05:56:46,905 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'GlobalAveragePooling2D'] by Connecting pool1_pad_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and avg_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge_2
2024-06-13 05:56:48,006 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'GlobalAveragePooling2D'] by Connecting pool1_pad_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and avg_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge_2
2024-06-13 05:56:48,006 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'MaxPooling2D')
2024-06-13 05:56:49,018 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'MaxPooling2D'] by Connecting conv1_pad_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and pool1_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge
2024-06-13 05:56:49,937 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'MaxPooling2D'] by Connecting conv1_pad_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and pool1_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge
2024-06-13 05:56:49,937 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'Conv2D')
2024-06-13 05:56:50,945 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'Conv2D'] by Connecting conv1_pad_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and conv3_block3_1_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge
2024-06-13 05:56:52,073 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'Conv2D'] by Connecting conv1_pad_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and conv3_block3_1_conv_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge
2024-06-13 05:56:52,073 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'MaxPooling2D')
2024-06-13 05:56:53,094 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'MaxPooling2D'] by Connecting conv3_block2_1_bn_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and pool1_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge_2
2024-06-13 05:56:54,022 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'MaxPooling2D'] by Connecting conv3_block2_1_bn_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge and pool1_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_Edge_2
2024-06-13 05:56:54,178 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 134/2170
The Configuration Coverage is: 333/2049
The NDims Coverage Is: 55/117
The DType Coverage Is: 63/354
The Shape Coverage Is: 119/295
The Input Coverage Is: 237/766
2024-06-13 05:56:56,241 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:56:56,707 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
rewriter <function rewrite_cond at 0x7f7526655840>: exception make_sure failure: Cannot find node with output 'resnet50-LMerg2-LMerg10-NLAll66-Edge53/thresholded_re_lu_insert_copy_Edge_2/mul:0' in graph 'tf2onnx__3'
Failed topological_sort
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 74, in optimize_graph
    graph.topological_sort(graph.get_nodes())
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/graph.py", line 1055, in topological_sort
    utils.make_sure(j is not None, "Cannot find node with output %r in graph %r", inp, self.graph_name)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/utils.py", line 264, in make_sure
    raise ValueError("make_sure failure: " + error_msg % args)
ValueError: make_sure failure: Cannot find node with output 'resnet50-LMerg2-LMerg10-NLAll66-Edge53/thresholded_re_lu_insert_copy_Edge_2/mul:0' in graph 'tf2onnx__3'
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 58, in <module>
    transform_onnx(model_path)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 48, in transform_onnx
    opset=15, output_path=onnx_path)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/convert.py", line 517, in from_keras
    output_path=output_path)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/convert.py", line 176, in _convert_common
    external_tensor_storage=external_tensor_storage)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/graph.py", line 1189, in make_model
    graph = self.make_graph(graph_doc, graph_name, external_tensor_storage)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/graph.py", line 1095, in make_graph
    self.topological_sort(self.get_nodes())
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/graph.py", line 1055, in topological_sort
    utils.make_sure(j is not None, "Cannot find node with output %r in graph %r", inp, self.graph_name)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/utils.py", line 264, in make_sure
    raise ValueError("make_sure failure: " + error_msg % args)
ValueError: make_sure failure: Cannot find node with output 'resnet50-LMerg2-LMerg10-NLAll66-Edge53/thresholded_re_lu_insert_copy_Edge_2/mul:0' in graph 'tf2onnx__3'
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/resnet50-LMerg2-LMerg10-NLAll66-Edge53/resnet50-LMerg2-LMerg10-NLAll66-Edge53.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:57:26,109 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 29s
2024-06-13 05:57:26,109 logger.py[line:35] INFO resnet50-LMerg2-LMerg10-NLAll66-Edge53 crash on backend pytorch when predicting
2024-06-13 05:57:26,131 logger.py[line:35] INFO coverage_c=14446
2024-06-13 05:57:26,191 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-LMerg10-NLAll66-Edge53
2024-06-13 05:57:26,191 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:57:26,191 logger.py[line:35] INFO after_prediction
2024-06-13 05:57:26,375 logger.py[line:35] INFO INFO: Mutation progress 54/100
2024-06-13 05:57:26,375 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:57:26,375 logger.py[line:35] INFO Score for NLAll is: 0.8417721518987342
2024-06-13 05:57:26,375 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:57:26,375 logger.py[line:35] INFO Score for Edge is: 0.7846153846153846
2024-06-13 05:57:26,375 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:57:26,375 logger.py[line:35] INFO Score for MDims is: 0.7738095238095238
2024-06-13 05:57:26,375 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 05:57:26,375 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:57:26,375 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:57:26,375 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:57:26,375 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:57:26,375 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55
2024-06-13 05:57:26,376 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:57:29,324 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:57:30,008 logger.py[line:35] INFO Generating model using MDims
2024-06-13 05:57:30,011 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDims')>}
2024-06-13 05:57:30,183 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 05:57:30,183 logger.py[line:35] INFO Global Layer Class: 0; Local Layer Class: 1; Total Layer Class: 1
2024-06-13 05:57:30,183 logger.py[line:35] INFO Changing 0 Layer's NDims.
2024-06-13 05:57:30,183 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 05:57:30,184 logger.py[line:35] INFO No Global NDims Can Be Found, Randomly Select NDims: 2 For Layer: dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDims
2024-06-13 05:57:30,186 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDims': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDims')>}
2024-06-13 05:57:30,396 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:57:30,846 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 134/2170
The Configuration Coverage is: 333/2049
The NDims Coverage Is: 55/117
The DType Coverage Is: 63/354
The Shape Coverage Is: 119/295
The Input Coverage Is: 237/766
2024-06-13 05:57:31,064 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:57:31,525 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (55) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:57:39,551 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 8s
2024-06-13 05:57:39,551 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDims54 crash on backend pytorch when predicting
2024-06-13 05:57:39,572 logger.py[line:35] INFO coverage_c=14446
2024-06-13 05:57:39,583 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDims54
2024-06-13 05:57:39,583 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:57:39,583 logger.py[line:35] INFO after_prediction
2024-06-13 05:57:39,584 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDims54, do not increase the reward
2024-06-13 05:57:39,729 logger.py[line:35] INFO INFO: Mutation progress 55/100
2024-06-13 05:57:39,729 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:57:39,729 logger.py[line:35] INFO Score for NLAll is: 0.8417721518987342
2024-06-13 05:57:39,729 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:57:39,729 logger.py[line:35] INFO Score for Edge is: 0.7846153846153846
2024-06-13 05:57:39,729 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:57:39,730 logger.py[line:35] INFO Score for MDims is: 0.7558139534883721
2024-06-13 05:57:39,730 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 05:57:39,730 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:57:39,730 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:57:39,730 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:57:39,730 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:57:39,730 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55
2024-06-13 05:57:39,730 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:57:42,648 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:57:43,329 logger.py[line:35] INFO Generating model using MDims
2024-06-13 05:57:43,332 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDims')>}
2024-06-13 05:57:43,503 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 05:57:43,504 logger.py[line:35] INFO Global Layer Class: 0; Local Layer Class: 1; Total Layer Class: 1
2024-06-13 05:57:43,504 logger.py[line:35] INFO Changing 0 Layer's NDims.
2024-06-13 05:57:43,504 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 05:57:43,504 logger.py[line:35] INFO No Global NDims Can Be Found, Randomly Select NDims: 5 For Layer: dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDims
2024-06-13 05:57:43,507 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDims': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDims')>}
2024-06-13 05:57:43,699 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:57:44,127 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 134/2170
The Configuration Coverage is: 333/2049
The NDims Coverage Is: 55/117
The DType Coverage Is: 63/354
The Shape Coverage Is: 119/295
The Input Coverage Is: 237/766
2024-06-13 05:57:44,318 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:57:44,781 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (46) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:57:52,564 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 7s
2024-06-13 05:57:52,564 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDims55 crash on backend pytorch when predicting
2024-06-13 05:57:52,586 logger.py[line:35] INFO coverage_c=14446
2024-06-13 05:57:52,638 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDims55
2024-06-13 05:57:52,638 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:57:52,638 logger.py[line:35] INFO after_prediction
2024-06-13 05:57:52,638 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDims55, do not increase the reward
2024-06-13 05:57:52,767 logger.py[line:35] INFO INFO: Mutation progress 56/100
2024-06-13 05:57:52,767 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:57:52,767 logger.py[line:35] INFO Score for NLAll is: 0.8417721518987342
2024-06-13 05:57:52,767 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:57:52,767 logger.py[line:35] INFO Score for Edge is: 0.7846153846153846
2024-06-13 05:57:52,767 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:57:52,767 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 05:57:52,767 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 05:57:52,767 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:57:52,767 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:57:52,767 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 05:57:52,768 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:57:52,768 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MDtype4-NLAll12-NLAll32-NLAll93-NLAll-1-Edge61
2024-06-13 05:57:52,768 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:57:57,471 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MDtype')>, 'elu_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2': <KerasTensor: shape=(None, 14, 13, 1017) dtype=float32 (created by layer 'elu_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MDtype')>, 'softmax_insert_copy_NLAll_copy_NLAll_copy_Edge_2': <KerasTensor: shape=(None, 7, 7, 512) dtype=float32 (created by layer 'softmax_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MDtype')>, 'pool1_pool_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2': <KerasTensor: shape=(None, 3, 6, 2052) dtype=float16 (created by layer 'pool1_pool_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MDtype')>, 'cropping2d': <KerasTensor: shape=(None, 10, 10, 258) dtype=float32 (created by layer 'cropping2d_copy_MDtype')>, 'conv4_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv4_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MDtype')>, 'global_max_pooling2d_insert_copy_NLAll_copy_NLAll_copy_Edge_2': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'global_max_pooling2d_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MDtype')>}
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 91, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dtype(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 403, in mutate_dtype
    mode=mutation_mode
  File "/root/implementations/scripts/tools/architecture_utils.py", line 990, in choose_layers_for_mdtype
    current_dtype_set = set(input_diversity[layer_class]["dtype"])
KeyError: 'SeparableConv1D'
2024-06-13 05:57:59,092 logger.py[line:35] INFO INFO: Mutation progress 56/100
2024-06-13 05:57:59,092 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:57:59,092 logger.py[line:35] INFO Score for NLAll is: 0.8417721518987342
2024-06-13 05:57:59,092 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:57:59,093 logger.py[line:35] INFO Score for Edge is: 0.7846153846153846
2024-06-13 05:57:59,093 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:57:59,093 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 05:57:59,093 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 05:57:59,093 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:57:59,093 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:57:59,093 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:57:59,093 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:57:59,093 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-NLAll54-NLAll124-MDtype127
2024-06-13 05:57:59,093 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:58:02,020 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:58:02,801 logger.py[line:35] INFO Generating model using NLAll
2024-06-13 05:58:02,804 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll')>}
2024-06-13 05:58:03,069 logger.py[line:35] INFO Insert 8 out of 18 Global New Layers
2024-06-13 05:58:03,069 logger.py[line:35] INFO insert SeparableConv1D after separable_conv1d_insert_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,069 logger.py[line:35] INFO insert AveragePooling1D after separable_conv1d_insert_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,069 logger.py[line:35] INFO insert Conv1D after repeat_vector_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,069 logger.py[line:35] INFO insert UpSampling1D after repeat_vector_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,069 logger.py[line:35] INFO insert ZeroPadding3D after gaussian_dropout_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,069 logger.py[line:35] INFO insert GlobalMaxPooling3D after up_sampling3d_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,069 logger.py[line:35] INFO insert Conv3D after conv3d_transpose_insert_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,070 logger.py[line:35] INFO insert SpatialDropout1D after repeat_vector_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,070 logger.py[line:35] INFO Insert 3 out of 40 Local New Layers
2024-06-13 05:58:03,070 logger.py[line:35] INFO insert Cropping3D after conv3d_transpose_insert_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,070 logger.py[line:35] INFO insert Conv2D after up_sampling2d_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,070 logger.py[line:35] INFO insert Cropping2D after up_sampling2d_insert_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,070 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 2
2024-06-13 05:58:03,071 logger.py[line:35] INFO insert ZeroPadding2D after custom_expand_layer_1_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,072 logger.py[line:35] INFO insert BatchNormalization after custom_expand_layer_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll
2024-06-13 05:58:03,075 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7ff19833bd10>
2024-06-13 05:58:03,183 logger.py[line:35] INFO Converting output shape (None, 1, 25) to actual shape [None, 1, 25]
[DEBUG] Inserting layer: <keras.layers.convolutional.ZeroPadding2D object at 0x7ff19832f790>
2024-06-13 05:58:03,200 logger.py[line:35] INFO Converting output shape (None, 1, 9, 7) to actual shape [None, 1, 1, 1]
[DEBUG] Inserting layer: <keras.layers.pooling.GlobalMaxPooling3D object at 0x7ff198367050>
2024-06-13 05:58:03,222 logger.py[line:35] INFO Converting output shape (None, 225) to actual shape [None, 1, 9, 9, 225]
[DEBUG] Inserting layer: <keras.layers.convolutional.ZeroPadding3D object at 0x7ff198378610>
2024-06-13 05:58:03,237 logger.py[line:35] INFO Converting output shape (None, 9, 15, 13, 225) to actual shape [None, 1, 9, 9, 225]
[DEBUG] Inserting layer: <keras.layers.convolutional.Cropping3D object at 0x7ff19846cd10>
2024-06-13 05:58:03,263 logger.py[line:35] INFO Converting output shape (None, 0, 7, 9, 225) to actual shape [None, 1, 9, 9, 225]
[DEBUG] Inserting layer: <keras.layers.convolutional.Cropping2D object at 0x7ff19842af90>
2024-06-13 05:58:03,277 logger.py[line:35] INFO Converting output shape (None, 63, 61, 223) to actual shape [None, 63, 63, 225]
[DEBUG] Inserting layer: <keras.layers.core.spatial_dropout.SpatialDropout1D object at 0x7ff198358410>
2024-06-13 05:58:03,319 logger.py[line:35] INFO Converting output shape (None, 2, 25) to actual shape [None, 2, 25]
[DEBUG] Inserting layer: <keras.layers.pooling.AveragePooling1D object at 0x7ff198389990>
2024-06-13 05:58:03,344 logger.py[line:35] INFO Converting output shape (None, 2, 25) to actual shape [None, 2, 25]
model outputs {'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll')>}
2024-06-13 05:58:03,483 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:58:04,049 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 141/2170
The Configuration Coverage is: 372/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 69/354
The Shape Coverage Is: 130/295
The Input Coverage Is: 261/766
2024-06-13 05:58:04,359 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:58:04,821 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 58, in <module>
    transform_onnx(model_path)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 41, in transform_onnx
    model = keras.models.load_model(model_path, custom_objects=custom_objects())
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/save.py", line 201, in load_model
    compile)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/hdf5_format.py", line 181, in load_model_from_hdf5
    custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/model_config.py", line 52, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 678, in deserialize_keras_object
    list(custom_objects.items())))
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 663, in from_config
    config, custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1273, in reconstruct_from_config
    process_layer(layer_data)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1255, in process_layer
    layer = deserialize_layer(layer_data, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 681, in deserialize_keras_object
    deserialized_obj = cls.from_config(cls_config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 748, in from_config
    return cls(**config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/noise.py", line 107, in __init__
    super(GaussianDropout, self).__init__(**kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 323, in __init__
    generic_utils.validate_kwargs(kwargs, allowed_kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 1143, in validate_kwargs
    raise TypeError(error_message, kwarg)
TypeError: ('Keyword argument not understood:', 'seed')
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/lstm2-NLAll38-NLAll54-NLAll124-MDtype127-NLAll56/lstm2-NLAll38-NLAll54-NLAll124-MDtype127-NLAll56.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:58:10,044 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 5s
2024-06-13 05:58:10,044 logger.py[line:35] INFO lstm2-NLAll38-NLAll54-NLAll124-MDtype127-NLAll56 crash on backend pytorch when predicting
2024-06-13 05:58:10,066 logger.py[line:35] INFO coverage_c=14446
2024-06-13 05:58:10,076 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-NLAll54-NLAll124-MDtype127-NLAll56
2024-06-13 05:58:10,076 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:58:10,076 logger.py[line:35] INFO after_prediction
2024-06-13 05:58:10,215 logger.py[line:35] INFO INFO: Mutation progress 57/100
2024-06-13 05:58:10,215 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:58:10,215 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 05:58:10,215 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:58:10,215 logger.py[line:35] INFO Score for Edge is: 0.7846153846153846
2024-06-13 05:58:10,215 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:58:10,215 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 05:58:10,215 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 05:58:10,215 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:58:10,215 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:58:10,215 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 05:58:10,215 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:58:10,215 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55
2024-06-13 05:58:10,215 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:58:13,158 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:58:13,845 logger.py[line:35] INFO Generating model using Edge
2024-06-13 05:58:13,848 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge')>}
Choosing 3 To Insert
2024-06-13 05:58:14,022 logger.py[line:35] INFO Insert 3 Local New Edges
2024-06-13 05:58:14,022 logger.py[line:35] INFO Candidate Edge: ('Dropout', 'Dropout')
2024-06-13 05:58:14,031 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:58:14,199 logger.py[line:35] INFO Trying Adding Edge: ['Dropout', 'Dropout'] by Connecting dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge
2024-06-13 05:58:14,202 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:58:14,373 logger.py[line:35] INFO Successfully Add Edge: ['Dropout', 'Dropout'] by Connecting dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge
2024-06-13 05:58:14,373 logger.py[line:35] INFO Candidate Edge: ('LSTM', 'Dropout')
2024-06-13 05:58:14,381 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:58:14,556 logger.py[line:35] INFO Trying Adding Edge: ['LSTM', 'Dropout'] by Connecting lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge_1
2024-06-13 05:58:14,559 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:58:14,734 logger.py[line:35] INFO Successfully Add Edge: ['LSTM', 'Dropout'] by Connecting lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge_1
2024-06-13 05:58:14,734 logger.py[line:35] INFO Candidate Edge: ('UpSampling3D', 'Dropout')
2024-06-13 05:58:14,743 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:58:14,915 logger.py[line:35] INFO Trying Adding Edge: ['UpSampling3D', 'Dropout'] by Connecting up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_Edge and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge_1_2
2024-06-13 05:58:14,918 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:58:15,241 logger.py[line:35] INFO Successfully Add Edge: ['UpSampling3D', 'Dropout'] by Connecting up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_Edge and dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge_1_2
2024-06-13 05:58:15,281 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:58:15,760 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 141/2170
The Configuration Coverage is: 372/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 69/354
The Shape Coverage Is: 130/295
The Input Coverage Is: 261/766
2024-06-13 05:58:15,950 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:58:16,413 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 05:58:24,683 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 05:58:24,683 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 208, in forward
    outputs = op((self,), activations, *in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/loop.py", line 95, in forward
    while i < M and cond:
RuntimeError: t == DeviceType::CUDAINTERNAL ASSERT FAILED at "/root/dl_libraries/pytorch/c10/cuda/impl/CUDAGuardImpl.h":24, please report a bug to PyTorch. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:58:26,942 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 10s
2024-06-13 05:58:26,942 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-Edge57 crash on backend pytorch when predicting
2024-06-13 05:58:26,964 logger.py[line:35] INFO coverage_c=14446
2024-06-13 05:58:26,973 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-Edge57
2024-06-13 05:58:26,973 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:58:26,973 logger.py[line:35] INFO after_prediction
2024-06-13 05:58:26,973 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-MDtype45-MDims17-MDims55-Edge57, do not increase the reward
2024-06-13 05:58:27,106 logger.py[line:35] INFO INFO: Mutation progress 58/100
2024-06-13 05:58:27,107 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:58:27,107 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 05:58:27,107 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:58:27,107 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:58:27,107 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 05:58:27,107 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 05:58:27,107 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 05:58:27,107 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:58:27,107 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:58:27,107 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 05:58:27,107 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:58:27,107 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MDtype4-NLAll12-NLAll32-NLAll93-NLAll-1-Edge61
2024-06-13 05:58:27,107 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:58:31,837 logger.py[line:35] INFO Generating model using LMerg
model outputs {'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_LMerg')>, 'elu_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2': <KerasTensor: shape=(None, 14, 13, 1017) dtype=float32 (created by layer 'elu_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_LMerg')>, 'softmax_insert_copy_NLAll_copy_NLAll_copy_Edge_2': <KerasTensor: shape=(None, 7, 7, 512) dtype=float32 (created by layer 'softmax_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_LMerg')>, 'pool1_pool_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2': <KerasTensor: shape=(None, 3, 6, 2052) dtype=float16 (created by layer 'pool1_pool_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_LMerg')>, 'cropping2d': <KerasTensor: shape=(None, 10, 10, 258) dtype=float32 (created by layer 'cropping2d_copy_LMerg')>, 'conv4_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv4_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_LMerg')>, 'global_max_pooling2d_insert_copy_NLAll_copy_NLAll_copy_Edge_2': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'global_max_pooling2d_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 05:58:32,953 logger.py[line:35] INFO Insert 2 out of 8 Local New Layer
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 72, in generate_model_by_model_mutation
    return InteractionMutationUtils.merge_layers(model=model, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 165, in merge_layers
    assert len(selected_layer_name_list) == 1
AssertionError
2024-06-13 05:58:33,439 logger.py[line:35] INFO INFO: Mutation progress 58/100
2024-06-13 05:58:33,440 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:58:33,440 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 05:58:33,440 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:58:33,440 logger.py[line:35] INFO Score for MParam is: 0.7833333333333333
2024-06-13 05:58:33,440 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 05:58:33,440 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 05:58:33,440 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 05:58:33,440 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:58:33,440 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:58:33,440 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 05:58:33,440 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:58:33,440 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MDtype113-MDtype54-SpecialI59
2024-06-13 05:58:33,440 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:58:36,377 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 05:58:37,046 logger.py[line:35] INFO Generating model using MParam
2024-06-13 05:58:37,051 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_MParam')>}
2024-06-13 05:58:37,204 logger.py[line:35] INFO Changing 1/1 of layer up_sampling3d_insert_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_MParam's configuration
2024-06-13 05:58:37,205 logger.py[line:35] INFO changing config data_format in layer up_sampling3d_insert_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_MParam: from channels_first to channels_last
2024-06-13 05:58:37,209 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_MParam': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_MParam')>}
2024-06-13 05:58:37,375 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 05:58:37,825 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 141/2170
The Configuration Coverage is: 372/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 69/354
The Shape Coverage Is: 130/295
The Input Coverage Is: 261/766
2024-06-13 05:58:37,996 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:58:38,460 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (35) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 05:58:45,935 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 7s
2024-06-13 05:58:45,936 logger.py[line:35] INFO lstm2-NLAll38-SpecialI47-MDtype113-MDtype54-SpecialI59-MParam58 crash on backend pytorch when predicting
2024-06-13 05:58:45,957 logger.py[line:35] INFO coverage_c=14446
2024-06-13 05:58:46,018 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-SpecialI47-MDtype113-MDtype54-SpecialI59-MParam58
2024-06-13 05:58:46,018 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 05:58:46,018 logger.py[line:35] INFO after_prediction
2024-06-13 05:58:46,140 logger.py[line:35] INFO INFO: Mutation progress 59/100
2024-06-13 05:58:46,141 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:58:46,141 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 05:58:46,141 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:58:46,141 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 05:58:46,141 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 05:58:46,141 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 05:58:46,141 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 05:58:46,141 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:58:46,141 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:58:46,141 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 05:58:46,141 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:58:46,141 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MDtype4-NLAll12-NLAll32-NLAll93-NLAll-1
2024-06-13 05:58:46,141 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:58:50,814 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype')>}
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 91, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dtype(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 403, in mutate_dtype
    mode=mutation_mode
  File "/root/implementations/scripts/tools/architecture_utils.py", line 990, in choose_layers_for_mdtype
    current_dtype_set = set(input_diversity[layer_class]["dtype"])
KeyError: 'SimpleRNN'
2024-06-13 05:58:52,408 logger.py[line:35] INFO INFO: Mutation progress 59/100
2024-06-13 05:58:52,408 logger.py[line:35] INFO Logging for Seeds
2024-06-13 05:58:52,408 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 05:58:52,408 logger.py[line:35] INFO Score for MDtype is: 0.7866666666666666
2024-06-13 05:58:52,408 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 05:58:52,409 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 05:58:52,409 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 05:58:52,409 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 05:58:52,409 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 05:58:52,409 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 05:58:52,409 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 05:58:52,409 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 05:58:52,409 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99
2024-06-13 05:58:52,409 logger.py[line:35] INFO start mutating the generated model
2024-06-13 05:58:59,826 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MDtype')>}
2024-06-13 05:59:03,423 logger.py[line:35] INFO Change 1 Layer's DType Out Of 5 Layer classes
2024-06-13 05:59:03,424 logger.py[line:35] INFO Changing 1 out of 5 Layer's DType.
2024-06-13 05:59:03,426 logger.py[line:35] INFO Selecting a Global DType float64 For Layer max_pooling2d_4_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MDtype
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MDtype')>}
2024-06-13 05:59:07,359 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 141/2170
The Configuration Coverage is: 372/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 69/354
The Shape Coverage Is: 130/295
The Input Coverage Is: 261/766
2024-06-13 05:59:13,916 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 05:59:14,378 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (1043) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:00:14,079 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 59s
2024-06-13 06:00:14,080 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99-MDtype59 crash on backend pytorch when predicting
2024-06-13 06:00:14,101 logger.py[line:35] INFO coverage_c=14446
2024-06-13 06:00:14,107 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99-MDtype59
2024-06-13 06:00:14,107 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:00:14,107 logger.py[line:35] INFO after_prediction
2024-06-13 06:00:14,107 logger.py[line:35] INFO No representative seed generated: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99-MDtype59, do not increase the reward
2024-06-13 06:00:14,317 logger.py[line:35] INFO INFO: Mutation progress 60/100
2024-06-13 06:00:14,317 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:00:14,317 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:00:14,317 logger.py[line:35] INFO Score for MDtype is: 0.7763157894736842
2024-06-13 06:00:14,317 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:00:14,317 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:00:14,317 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:00:14,317 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:00:14,317 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 06:00:14,317 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:00:14,317 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 06:00:14,317 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:00:14,317 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97
2024-06-13 06:00:14,318 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:00:17,261 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:00:17,274 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:00:18,097 logger.py[line:35] INFO Generating model using NLAll
2024-06-13 06:00:18,100 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:00:18,328 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_copy_NLAll')>, 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_NLAll')>, 'cropping3d': <KerasTensor: shape=(None, 1, 11, 11, 2025) dtype=float32 (created by layer 'cropping3d_copy_NLAll')>, 'lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_NLAll')>, 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 2, 25) dtype=float32 (created by layer 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_NLAll')>}
2024-06-13 06:00:18,474 logger.py[line:35] INFO Insert 2 out of 14 Global New Layers
2024-06-13 06:00:18,474 logger.py[line:35] INFO insert Conv3D after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_NLAll
2024-06-13 06:00:18,474 logger.py[line:35] INFO insert ConvLSTM2D after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_NLAll
2024-06-13 06:00:18,477 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.convolutional_recurrent.ConvLSTM2D object at 0x7f3c40450e50>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 73, in new_layer_addition
    mylogger.info(f"Converting output shape {layer_input.shape} to actual shape {target_shape}")
AttributeError: 'list' object has no attribute 'shape'
2024-06-13 06:00:19,142 logger.py[line:35] INFO INFO: Mutation progress 60/100
2024-06-13 06:00:19,143 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:00:19,143 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:00:19,143 logger.py[line:35] INFO Score for MDtype is: 0.7763157894736842
2024-06-13 06:00:19,143 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:00:19,143 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:00:19,143 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:00:19,143 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:00:19,143 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 06:00:19,143 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:00:19,143 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:00:19,143 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:00:19,143 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25
2024-06-13 06:00:19,143 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:00:22,083 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:00:22,779 logger.py[line:35] INFO Generating model using MParam
2024-06-13 06:00:22,782 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MParam')>}
2024-06-13 06:00:22,989 logger.py[line:35] INFO Changing 3/16 of layer conv3d_transpose_insert_copy_MParam's configuration
2024-06-13 06:00:22,989 logger.py[line:35] INFO changing config output_padding in layer conv3d_transpose_insert_copy_MParam: from None to 1
2024-06-13 06:00:22,989 logger.py[line:35] INFO changing config bias_initializer in layer conv3d_transpose_insert_copy_MParam: from {'class_name': 'Ones', 'config': {}} to TruncatedNormal
2024-06-13 06:00:22,989 logger.py[line:35] INFO changing config strides in layer conv3d_transpose_insert_copy_MParam: from (1, 1, 1) to [4, 4, 3]
2024-06-13 06:00:22,989 logger.py[line:35] INFO changing config bias_regularizer in layer conv3d_transpose_insert_copy_MParam: from {'class_name': 'L1', 'config': {'l1': 0.009999999776482582}} to l1
2024-06-13 06:00:22,989 logger.py[line:35] INFO Changing 2/2 of layer global_average_pooling3d_insert_copy_MParam's configuration
2024-06-13 06:00:22,989 logger.py[line:35] INFO changing config data_format in layer global_average_pooling3d_insert_copy_MParam: from channels_last to channels_first
2024-06-13 06:00:22,990 logger.py[line:35] INFO changing config keepdims in layer global_average_pooling3d_insert_copy_MParam: from False to True
2024-06-13 06:00:22,990 logger.py[line:35] INFO Changing 1/21 of layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MParam's configuration
2024-06-13 06:00:22,990 logger.py[line:35] INFO changing config units in layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MParam: from 25 to 7
2024-06-13 06:00:22,990 logger.py[line:35] INFO changing config bias_initializer in layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MParam: from {'class_name': 'Zeros', 'config': {}} to he_uniform
2024-06-13 06:00:22,993 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:00:22,996 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 276, in change_layer_config
    x = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional.py", line 1566, in build
    raise ValueError('Inputs should have rank 5. '
ValueError: Inputs should have rank 5. Received input_shape=(None, 9, 9, 9, 1, 1, 1, 1).
2024-06-13 06:00:23,545 logger.py[line:35] INFO INFO: Mutation progress 60/100
2024-06-13 06:00:23,546 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:00:23,546 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:00:23,546 logger.py[line:35] INFO Score for MDtype is: 0.7763157894736842
2024-06-13 06:00:23,546 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:00:23,546 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:00:23,546 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:00:23,546 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:00:23,546 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 06:00:23,546 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:00:23,546 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:00:23,546 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:00:23,546 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-NLAll95
2024-06-13 06:00:23,546 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:00:26,480 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:00:27,566 logger.py[line:35] INFO Generating model using NLAll
2024-06-13 06:00:27,569 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll')>}
2024-06-13 06:00:28,255 logger.py[line:35] INFO Insert 10 out of 14 Global New Layers
2024-06-13 06:00:28,255 logger.py[line:35] INFO insert SimpleRNN after bidirectional_insert_copy_NLAll
2024-06-13 06:00:28,255 logger.py[line:35] INFO insert Conv1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,255 logger.py[line:35] INFO insert UpSampling1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,255 logger.py[line:35] INFO insert GlobalAveragePooling1D after bidirectional_insert_copy_NLAll
2024-06-13 06:00:28,255 logger.py[line:35] INFO insert MaxPooling3D after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO insert DepthwiseConv1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO insert LocallyConnected1D after bidirectional_insert_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO insert MaxPooling1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO insert Cropping1D after bidirectional_insert_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO insert ZeroPadding1D after bidirectional_insert_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO Insert 7 out of 24 Local New Layers
2024-06-13 06:00:28,256 logger.py[line:35] INFO insert GaussianDropout after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO insert SpatialDropout1D after bidirectional_insert_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO insert BatchNormalization after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO insert ThresholdedReLU after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO insert AlphaDropout after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO insert LayerNormalization after dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO insert ReLU after lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,256 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 5
2024-06-13 06:00:28,257 logger.py[line:35] INFO insert Cropping3D after custom_expand_layer_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,258 logger.py[line:35] INFO insert ActivityRegularization after custom_drop_dim_layer_3_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,259 logger.py[line:35] INFO insert LocallyConnected2D after custom_expand_layer_1_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,260 logger.py[line:35] INFO insert SeparableConv1D after custom_expand_layer_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,260 logger.py[line:35] INFO insert MaxPooling2D after custom_drop_dim_layer_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll
2024-06-13 06:00:28,263 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ReLU object at 0x7f53a04a9dd0>
2024-06-13 06:00:28,358 logger.py[line:35] INFO Converting output shape (None, 25) to actual shape [None, 25]
[DEBUG] Inserting layer: <keras.layers.pooling.MaxPooling3D object at 0x7f53a01e1710>
2024-06-13 06:00:28,382 logger.py[line:35] INFO Converting output shape (None, 1, 9, 9, 225) to actual shape [None, 1, 9, 9, 225]
[DEBUG] Inserting layer: <keras.layers.pooling.MaxPooling2D object at 0x7f53a01be2d0>
2024-06-13 06:00:28,390 logger.py[line:35] INFO Converting output shape (None, 9, 9, 225) to actual shape [None, 9, 9, 225]
[DEBUG] Inserting layer: <keras.layers.convolutional.SeparableConv1D object at 0x7f53a01c7090>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1939, in _create_c_op
    raise ValueError(e.message)
ValueError: Exception encountered when calling layer "separable_conv1d_insert" (type SeparableConv1D).

Negative dimension size caused by subtracting 7 from 1 for '{{node separable_conv1d_insert/separable_conv2d/depthwise}} = DepthwiseConv2dNative[T=DT_FLOAT, data_format="NHWC", dilations=[1, 1, 1, 1], explicit_paddings=[], padding="VALID", strides=[1, 1, 1, 1]](separable_conv1d_insert/ExpandDims, separable_conv1d_insert/ExpandDims_1)' with input shapes: [?,1,1,25], [1,7,25,1].

Call arguments received:
   inputs=tf.Tensor(shape=(None, 1, 25), dtype=float32)
2024-06-13 06:00:28,884 logger.py[line:35] INFO INFO: Mutation progress 60/100
2024-06-13 06:00:28,884 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:00:28,884 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:00:28,884 logger.py[line:35] INFO Score for MDtype is: 0.7763157894736842
2024-06-13 06:00:28,884 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:00:28,884 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:00:28,884 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:00:28,884 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:00:28,884 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 06:00:28,884 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:00:28,884 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:00:28,885 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:00:28,885 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65
2024-06-13 06:00:28,885 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:00:31,838 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:00:32,524 logger.py[line:35] INFO Generating model using NLAll
2024-06-13 06:00:32,527 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll')>}
2024-06-13 06:00:32,742 logger.py[line:35] INFO Insert 8 out of 14 Global New Layers
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert MaxPooling3D after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert ZeroPadding1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert Conv3D after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert Conv1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert SimpleRNN after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert DepthwiseConv1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert Cropping1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert MaxPooling1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,743 logger.py[line:35] INFO Insert 6 out of 19 Local New Layers
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert ThresholdedReLU after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert GaussianNoise after lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert PReLU after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert GaussianDropout after dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,743 logger.py[line:35] INFO insert ELU after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,744 logger.py[line:35] INFO insert LeakyReLU after dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,744 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 4
2024-06-13 06:00:32,745 logger.py[line:35] INFO insert Flatten after custom_expand_layer_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,746 logger.py[line:35] INFO insert MaxPooling3D after custom_expand_layer_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,747 logger.py[line:35] INFO insert AveragePooling1D after custom_expand_layer_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,747 logger.py[line:35] INFO insert MaxPooling2D after custom_drop_dim_layer_1_copy_MDtype_copy_NLAll
2024-06-13 06:00:32,750 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.noise.GaussianNoise object at 0x7f6f980ad690>
2024-06-13 06:00:32,842 logger.py[line:35] INFO Converting output shape (None, 25) to actual shape [None, 25]
[DEBUG] Inserting layer: <keras.layers.pooling.AveragePooling1D object at 0x7f6f98045650>
2024-06-13 06:00:32,849 logger.py[line:35] INFO Converting output shape (None, 1, 25) to actual shape [None, 1, 25]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ELU object at 0x7f6f907d3590>
2024-06-13 06:00:32,869 logger.py[line:35] INFO Converting output shape (None, 1, 9, 9, 225) to actual shape [None, 1, 9, 9, 225]
[DEBUG] Inserting layer: <keras.layers.pooling.MaxPooling3D object at 0x7f6f9806fb90>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1939, in _create_c_op
    raise ValueError(e.message)
ValueError: Exception encountered when calling layer "max_pooling3d_insert" (type MaxPooling3D).

Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling3d_insert/MaxPool3D}} = MaxPool3D[T=DT_FLOAT, data_format="NDHWC", ksize=[1, 2, 5, 5, 1], padding="VALID", strides=[1, 1, 1, 1, 1]](Placeholder)' with input shapes: [?,1,1,1,25].

Call arguments received:
   inputs=tf.Tensor(shape=(None, 1, 1, 1, 25), dtype=float32)
2024-06-13 06:00:33,327 logger.py[line:35] INFO INFO: Mutation progress 60/100
2024-06-13 06:00:33,328 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:00:33,328 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:00:33,328 logger.py[line:35] INFO Score for MDtype is: 0.7763157894736842
2024-06-13 06:00:33,328 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:00:33,328 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:00:33,328 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:00:33,328 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:00:33,328 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 06:00:33,328 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:00:33,328 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:00:33,328 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:00:33,328 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102
2024-06-13 06:00:33,328 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:00:40,742 logger.py[line:35] INFO Generating model using LMerg
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 06:00:44,416 logger.py[line:35] INFO Insert 2 out of 8 Local New Layer
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 72, in generate_model_by_model_mutation
    return InteractionMutationUtils.merge_layers(model=model, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 165, in merge_layers
    assert len(selected_layer_name_list) == 1
AssertionError
2024-06-13 06:00:45,156 logger.py[line:35] INFO INFO: Mutation progress 60/100
2024-06-13 06:00:45,156 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:00:45,156 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:00:45,156 logger.py[line:35] INFO Score for MDtype is: 0.7763157894736842
2024-06-13 06:00:45,156 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:00:45,156 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:00:45,156 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:00:45,156 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:00:45,156 logger.py[line:35] INFO Score for MShape is: 0.625
2024-06-13 06:00:45,156 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:00:45,156 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 06:00:45,157 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:00:45,157 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MDtype39
2024-06-13 06:00:45,157 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:00:49,469 logger.py[line:35] INFO Generating model using MShape
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_MShape')>}
2024-06-13 06:00:50,476 logger.py[line:35] INFO Change 3 Layer's Shape Out Of 5 Layer classes
2024-06-13 06:00:50,476 logger.py[line:35] INFO Changing 3 out of 5 Layer's Shape.
2024-06-13 06:00:50,477 logger.py[line:35] INFO [Locally] Changing The Input Shape Of Layer: conv4_block4_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_MShape From [None, 14, 14, 256] To [None, 5, 2, 2]
2024-06-13 06:00:50,477 logger.py[line:35] INFO [Locally] Changing The Input Shape Of Layer: avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_MShape From [None, 7, 7, 2048] To [None, 0, 7, 0]
2024-06-13 06:00:50,478 logger.py[line:35] INFO [Locally] Changing The Input Shape Of Layer: pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_MShape From [None, 114, 114, 64] To [None, 5, 4, 9]
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_MShape': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_MShape')>}
2024-06-13 06:00:51,487 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 141/2170
The Configuration Coverage is: 372/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 69/354
The Shape Coverage Is: 130/295
The Input Coverage Is: 261/766
2024-06-13 06:00:53,438 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:00:53,901 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (143) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:01:18,001 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 06:01:18,001 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-MDtype39-MShape60 crash on backend pytorch when predicting
2024-06-13 06:01:18,022 logger.py[line:35] INFO coverage_c=14446
2024-06-13 06:01:18,080 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-MDtype39-MShape60
2024-06-13 06:01:18,080 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:01:18,080 logger.py[line:35] INFO after_prediction
2024-06-13 06:01:18,081 logger.py[line:35] INFO No representative seed generated: resnet50-LMerg2-MShape5-MDtype6-MDtype39-MShape60, do not increase the reward
2024-06-13 06:01:18,246 logger.py[line:35] INFO INFO: Mutation progress 61/100
2024-06-13 06:01:18,246 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:01:18,246 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:01:18,246 logger.py[line:35] INFO Score for MDtype is: 0.7763157894736842
2024-06-13 06:01:18,246 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:01:18,246 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:01:18,246 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:01:18,246 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:01:18,247 logger.py[line:35] INFO Score for MShape is: 0.5769230769230769
2024-06-13 06:01:18,247 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:01:18,247 logger.py[line:35] INFO The last used seed is: MShape
2024-06-13 06:01:18,247 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:01:18,247 logger.py[line:35] INFO Choose seed: alexnet-Edge76
2024-06-13 06:01:18,247 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:01:21,582 logger.py[line:35] INFO Generating model using MDtype
model outputs {'dense_3_copy_Edge': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_Edge_copy_MDtype')>, 'dropout_2_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'dropout_2_copy_Edge_2_copy_MDtype')>}
2024-06-13 06:01:21,674 logger.py[line:35] INFO Change 1 Layer's DType Out Of 5 Layer classes
2024-06-13 06:01:21,674 logger.py[line:35] INFO Changing 1 out of 5 Layer's DType.
2024-06-13 06:01:21,674 logger.py[line:35] INFO Selecting a Global DType half For Layer dropout_2_copy_Edge_2_copy_MDtype
model outputs {'dense_3_copy_Edge_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_Edge_copy_MDtype')>, 'dropout_2_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'custom_cast_layer_1')>}
2024-06-13 06:01:21,819 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 141/2170
The Configuration Coverage is: 372/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 69/354
The Shape Coverage Is: 130/295
The Input Coverage Is: 261/766
2024-06-13 06:01:22,539 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:01:23,001 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:01:43,035 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:01:43,035 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: expected scalar type Float but found Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:01:46,346 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 23s
2024-06-13 06:01:46,346 logger.py[line:35] INFO alexnet-Edge76-MDtype61 crash on backend pytorch when predicting
2024-06-13 06:01:46,367 logger.py[line:35] INFO coverage_c=14446
2024-06-13 06:01:46,379 logger.py[line:35] INFO Fail on backend: pytorch of model alexnet-Edge76-MDtype61
2024-06-13 06:01:46,379 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:01:46,379 logger.py[line:35] INFO after_prediction
2024-06-13 06:01:46,379 logger.py[line:35] INFO No representative seed generated: alexnet-Edge76-MDtype61, do not increase the reward
2024-06-13 06:01:46,499 logger.py[line:35] INFO INFO: Mutation progress 62/100
2024-06-13 06:01:46,499 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:01:46,499 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:01:46,500 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:01:46,500 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:01:46,500 logger.py[line:35] INFO Score for MDtype is: 0.7662337662337663
2024-06-13 06:01:46,500 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:01:46,500 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:01:46,500 logger.py[line:35] INFO Score for MShape is: 0.5769230769230769
2024-06-13 06:01:46,500 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:01:46,500 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 06:01:46,500 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:01:46,500 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25
2024-06-13 06:01:46,500 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:01:49,439 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:01:50,139 logger.py[line:35] INFO Generating model using MParam
2024-06-13 06:01:50,142 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MParam')>}
2024-06-13 06:01:50,351 logger.py[line:35] INFO Changing 1/16 of layer conv3d_transpose_insert_copy_MParam's configuration
2024-06-13 06:01:50,352 logger.py[line:35] INFO changing config kernel_constraint in layer conv3d_transpose_insert_copy_MParam: from {'class_name': 'MinMaxNorm', 'config': {'min_value': 0.0, 'max_value': 1.0, 'rate': 1.0, 'axis': 0}} to MaxNorm
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 261, in mutate_param
    numeric_param_size=PARAMETER_SPACE
  File "/root/implementations/scripts/tools/architecture_utils.py", line 836, in choose_layers_for_mparam
    origin_param = layer_config[selected_config]
KeyError: 'dilation_rate'
2024-06-13 06:01:50,775 logger.py[line:35] INFO INFO: Mutation progress 62/100
2024-06-13 06:01:50,775 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:01:50,775 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:01:50,775 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:01:50,775 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:01:50,775 logger.py[line:35] INFO Score for MDtype is: 0.7662337662337663
2024-06-13 06:01:50,775 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:01:50,775 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:01:50,775 logger.py[line:35] INFO Score for MShape is: 0.5769230769230769
2024-06-13 06:01:50,775 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:01:50,775 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:01:50,776 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:01:50,776 logger.py[line:35] INFO Choose seed: alexnet
2024-06-13 06:01:50,776 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:01:54,138 logger.py[line:35] INFO Generating model using MParam
model outputs {'dense_3': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_MParam')>}
2024-06-13 06:01:54,231 logger.py[line:35] INFO Changing 1/15 of layer conv2d_4_copy_MParam's configuration
2024-06-13 06:01:54,231 logger.py[line:35] INFO changing config strides in layer conv2d_4_copy_MParam: from (1, 1) to [3, 4]
2024-06-13 06:01:54,231 logger.py[line:35] INFO changing config use_bias in layer conv2d_4_copy_MParam: from True to True
2024-06-13 06:01:54,232 logger.py[line:35] INFO Changing 1/15 of layer conv2d_3_copy_MParam's configuration
2024-06-13 06:01:54,232 logger.py[line:35] INFO changing config activity_regularizer in layer conv2d_3_copy_MParam: from None to l1
2024-06-13 06:01:54,232 logger.py[line:35] INFO changing config bias_regularizer in layer conv2d_3_copy_MParam: from None to l2
2024-06-13 06:01:54,232 logger.py[line:35] INFO Changing 3/5 of layer batch_normalization_3_copy_MParam's configuration
2024-06-13 06:01:54,232 logger.py[line:35] INFO changing config scale in layer batch_normalization_3_copy_MParam: from True to False
2024-06-13 06:01:54,232 logger.py[line:35] INFO changing config axis in layer batch_normalization_3_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:01:54,232 logger.py[line:35] INFO changing config center in layer batch_normalization_3_copy_MParam: from True to True
2024-06-13 06:01:54,232 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:01:54,232 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:01:54,232 logger.py[line:35] INFO Changing 2/5 of layer batch_normalization_1_copy_MParam's configuration
2024-06-13 06:01:54,232 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:01:54,233 logger.py[line:35] INFO changing config scale in layer batch_normalization_1_copy_MParam: from True to True
2024-06-13 06:01:54,233 logger.py[line:35] INFO changing config axis in layer batch_normalization_1_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:01:54,233 logger.py[line:35] INFO changing config center in layer batch_normalization_1_copy_MParam: from True to True
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1939, in _create_c_op
    raise ValueError(e.message)
ValueError: Exception encountered when calling layer "max_pooling2d_3_copy_MParam" (type MaxPooling2D).

Negative dimension size caused by subtracting 3 from 1 for '{{node max_pooling2d_3_copy_MParam/MaxPool}} = MaxPool[T=DT_FLOAT, data_format="NHWC", explicit_paddings=[], ksize=[1, 3, 3, 1], padding="VALID", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].

Call arguments received:
   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)
2024-06-13 06:01:54,715 logger.py[line:35] INFO INFO: Mutation progress 62/100
2024-06-13 06:01:54,716 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:01:54,716 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:01:54,716 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:01:54,716 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:01:54,716 logger.py[line:35] INFO Score for MDtype is: 0.7662337662337663
2024-06-13 06:01:54,716 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:01:54,716 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:01:54,716 logger.py[line:35] INFO Score for MShape is: 0.5769230769230769
2024-06-13 06:01:54,716 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:01:54,716 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:01:54,716 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:01:54,716 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype64-Edge69
2024-06-13 06:01:54,716 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:01:58,150 logger.py[line:35] INFO Generating model using MParam
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1': <KerasTensor: shape=(None, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MParam')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2': <KerasTensor: shape=(None, 8, 8, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_copy_MParam')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1': <KerasTensor: shape=(None, 16384) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_MParam')>, 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 1, 1, 256) dtype=float32 (created by layer 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 8, 8, 96) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_MParam')>, 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1_copy_MParam')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2_copy_MParam')>, 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 256) dtype=float64 (created by layer 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>}
2024-06-13 06:01:58,296 logger.py[line:35] INFO Changing 1/15 of layer conv2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 06:01:58,296 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:01:58,296 logger.py[line:35] INFO changing config activation in layer conv2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from relu to tanh
2024-06-13 06:01:58,297 logger.py[line:35] INFO changing config use_bias in layer conv2d_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from True to True
2024-06-13 06:01:58,297 logger.py[line:35] INFO Changing 1/1 of layer flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1_copy_MParam's configuration
2024-06-13 06:01:58,297 logger.py[line:35] INFO changing config data_format in layer flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1_copy_MParam: from channels_last to channels_last
2024-06-13 06:01:58,297 logger.py[line:35] INFO Changing 3/15 of layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam's configuration
2024-06-13 06:01:58,297 logger.py[line:35] INFO changing config padding in layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from same to valid
2024-06-13 06:01:58,297 logger.py[line:35] INFO changing config bias_constraint in layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from None to Constraint
2024-06-13 06:01:58,297 logger.py[line:35] INFO changing config dilation_rate in layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from (1, 1) to [4, 2]
2024-06-13 06:01:58,297 logger.py[line:35] INFO changing config bias_regularizer in layer conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from None to l2
2024-06-13 06:01:58,297 logger.py[line:35] INFO Changing 1/5 of layer batch_normalization_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 06:01:58,298 logger.py[line:35] INFO changing config scale in layer batch_normalization_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from True to False
2024-06-13 06:01:58,298 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:01:58,298 logger.py[line:35] INFO changing config axis in layer batch_normalization_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_MParam: from ListWrapper([3]) to -2
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 276, in change_layer_config
    x = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional.py", line 303, in compute_output_shape
    f'One of the dimensions in the output is <= 0 '
ValueError: One of the dimensions in the output is <= 0 due to downsampling in conv2d_4_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam. Consider increasing the input size. Received input shape [None, 3, 3, 256] which would produce output shape with a zero or negative value in a dimension.
2024-06-13 06:01:58,837 logger.py[line:35] INFO INFO: Mutation progress 62/100
2024-06-13 06:01:58,837 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:01:58,837 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:01:58,837 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:01:58,837 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:01:58,837 logger.py[line:35] INFO Score for MDtype is: 0.7662337662337663
2024-06-13 06:01:58,837 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:01:58,837 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:01:58,837 logger.py[line:35] INFO Score for MShape is: 0.5769230769230769
2024-06-13 06:01:58,837 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:01:58,837 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:01:58,838 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:01:58,838 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42
2024-06-13 06:01:58,838 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:02:03,328 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam')>}
2024-06-13 06:02:04,347 logger.py[line:35] INFO Changing 2/15 of layer conv4_block6_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam's configuration
2024-06-13 06:02:04,347 logger.py[line:35] INFO changing config bias_constraint in layer conv4_block6_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from None to NonNeg
2024-06-13 06:02:04,347 logger.py[line:35] INFO changing config kernel_initializer in layer conv4_block6_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}} to RandomUniform
2024-06-13 06:02:04,347 logger.py[line:35] INFO changing config strides in layer conv4_block6_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from (1, 1) to [2, 3]
2024-06-13 06:02:04,347 logger.py[line:35] INFO Changing 2/15 of layer conv3_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam's configuration
2024-06-13 06:02:04,347 logger.py[line:35] INFO changing config kernel_constraint in layer conv3_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from None to UnitNorm
2024-06-13 06:02:04,347 logger.py[line:35] INFO changing config kernel_initializer in layer conv3_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}} to lecun_normal
2024-06-13 06:02:04,347 logger.py[line:35] INFO changing config filters in layer conv3_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from 512 to 2
2024-06-13 06:02:04,347 logger.py[line:35] INFO Changing 3/15 of layer conv3_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam's configuration
2024-06-13 06:02:04,348 logger.py[line:35] INFO changing config use_bias in layer conv3_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from True to True
2024-06-13 06:02:04,348 logger.py[line:35] INFO changing config kernel_constraint in layer conv3_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from None to MinMaxNorm
2024-06-13 06:02:04,348 logger.py[line:35] INFO changing config bias_constraint in layer conv3_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from None to MinMaxNorm
2024-06-13 06:02:04,348 logger.py[line:35] INFO changing config activity_regularizer in layer conv3_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from None to l1
2024-06-13 06:02:04,348 logger.py[line:35] INFO Changing 1/5 of layer conv4_block4_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam's configuration
2024-06-13 06:02:04,348 logger.py[line:35] INFO changing config axis in layer conv4_block4_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:02:04,348 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:02:04,348 logger.py[line:35] INFO changing config center in layer conv4_block4_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from True to False
2024-06-13 06:02:04,348 logger.py[line:35] INFO Changing 1/15 of layer conv4_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam's configuration
2024-06-13 06:02:04,348 logger.py[line:35] INFO changing config activity_regularizer in layer conv4_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from None to l1
2024-06-13 06:02:04,348 logger.py[line:35] INFO changing config bias_constraint in layer conv4_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from None to NonNeg
2024-06-13 06:02:04,348 logger.py[line:35] INFO Changing 3/5 of layer conv3_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam's configuration
2024-06-13 06:02:04,348 logger.py[line:35] INFO changing config axis in layer conv3_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:02:04,349 logger.py[line:35] INFO changing config center in layer conv3_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from True to False
2024-06-13 06:02:04,349 logger.py[line:35] INFO changing config scale in layer conv3_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from True to True
2024-06-13 06:02:04,349 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:02:04,349 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:02:04,349 logger.py[line:35] INFO Changing 2/15 of layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam's configuration
2024-06-13 06:02:04,349 logger.py[line:35] INFO changing config kernel_regularizer in layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from None to l2
2024-06-13 06:02:04,349 logger.py[line:35] INFO changing config padding in layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from valid to valid
2024-06-13 06:02:04,349 logger.py[line:35] INFO changing config activation in layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from linear to hard_sigmoid
2024-06-13 06:02:04,349 logger.py[line:35] INFO Changing 1/15 of layer conv4_block2_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam's configuration
2024-06-13 06:02:04,349 logger.py[line:35] INFO changing config filters in layer conv4_block2_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from 1024 to 5
2024-06-13 06:02:04,349 logger.py[line:35] INFO changing config bias_regularizer in layer conv4_block2_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from None to l1
2024-06-13 06:02:04,350 logger.py[line:35] INFO Changing 2/5 of layer conv5_block2_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam's configuration
2024-06-13 06:02:04,350 logger.py[line:35] INFO changing config axis in layer conv5_block2_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:02:04,350 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:02:04,350 logger.py[line:35] INFO changing config center in layer conv5_block2_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from True to False
2024-06-13 06:02:04,350 logger.py[line:35] INFO changing config scale in layer conv5_block2_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from True to True
2024-06-13 06:02:04,350 logger.py[line:35] INFO Changing 3/15 of layer conv2_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam's configuration
2024-06-13 06:02:04,350 logger.py[line:35] INFO changing config padding in layer conv2_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from same to same
2024-06-13 06:02:04,350 logger.py[line:35] INFO changing config strides in layer conv2_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from (1, 1) to [4, 2]
2024-06-13 06:02:04,350 logger.py[line:35] INFO changing config bias_initializer in layer conv2_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from {'class_name': 'Zeros', 'config': {}} to Constant
2024-06-13 06:02:04,351 logger.py[line:35] INFO changing config data_format in layer conv2_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MParam: from channels_last to channels_first
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/merge.py", line 79, in _compute_elemwise_op_output_shape
    'Inputs have incompatible shapes. '
ValueError: Inputs have incompatible shapes. Received shapes (56, 56, 256) and (64, 14, 256)
2024-06-13 06:02:05,140 logger.py[line:35] INFO INFO: Mutation progress 62/100
2024-06-13 06:02:05,140 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:02:05,141 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:02:05,141 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:02:05,141 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:02:05,141 logger.py[line:35] INFO Score for MDtype is: 0.7662337662337663
2024-06-13 06:02:05,141 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:02:05,141 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:02:05,141 logger.py[line:35] INFO Score for MShape is: 0.5769230769230769
2024-06-13 06:02:05,141 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:02:05,141 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:02:05,141 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:02:05,141 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MDtype4-NLAll12-NLAll32-NLAll93-NLAll-1-Edge61-MParam98
2024-06-13 06:02:05,141 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:02:09,882 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_copy_MParam_copy_MDtype')>, 'elu_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 14, 13, 1017) dtype=float32 (created by layer 'elu_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam_copy_MDtype')>, 'softmax_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 7, 7, 512) dtype=float32 (created by layer 'softmax_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam_copy_MDtype')>, 'pool1_pool_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 3, 6, 2052) dtype=float16 (created by layer 'pool1_pool_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam_copy_MDtype')>, 'cropping2d_copy_MParam': <KerasTensor: shape=(None, 10, 10, 258) dtype=float32 (created by layer 'cropping2d_copy_MParam_copy_MDtype')>, 'conv4_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv4_block2_1_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam_copy_MDtype')>, 'global_max_pooling2d_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'global_max_pooling2d_insert_copy_NLAll_copy_NLAll_copy_Edge_2_copy_MParam_copy_MDtype')>}
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 91, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dtype(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 403, in mutate_dtype
    mode=mutation_mode
  File "/root/implementations/scripts/tools/architecture_utils.py", line 990, in choose_layers_for_mdtype
    current_dtype_set = set(input_diversity[layer_class]["dtype"])
KeyError: 'SimpleRNN'
2024-06-13 06:02:11,713 logger.py[line:35] INFO INFO: Mutation progress 62/100
2024-06-13 06:02:11,713 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:02:11,713 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:02:11,713 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:02:11,713 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:02:11,713 logger.py[line:35] INFO Score for MDtype is: 0.7662337662337663
2024-06-13 06:02:11,713 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:02:11,713 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:02:11,713 logger.py[line:35] INFO Score for MShape is: 0.5769230769230769
2024-06-13 06:02:11,713 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:02:11,713 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 06:02:11,713 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:02:11,713 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91
2024-06-13 06:02:11,714 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:02:14,672 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:02:15,358 logger.py[line:35] INFO Generating model using MShape
2024-06-13 06:02:15,361 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MShape')>}
2024-06-13 06:02:15,539 logger.py[line:35] INFO Change 2 Layer's Shape Out Of 4 Layer classes
2024-06-13 06:02:15,540 logger.py[line:35] INFO Changing 2 Layer's Shape.
2024-06-13 06:02:15,540 logger.py[line:35] INFO [Globally] Changing The Input Shape Of Layer: up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MShape From [None, 1, 1, 1, 25] To [None, 6, 5, 2, 6]
2024-06-13 06:02:15,540 logger.py[line:35] INFO [Globally] Changing The Input Shape Of Layer: repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MShape From [None, 25] To [None, 1]
2024-06-13 06:02:15,543 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MShape will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MShape': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MShape')>}
2024-06-13 06:02:15,788 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:02:16,233 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MShape will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 141/2170
The Configuration Coverage is: 372/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 69/354
The Shape Coverage Is: 132/295
The Input Coverage Is: 263/766
2024-06-13 06:02:16,449 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:02:16,910 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (55) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:02:24,786 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 7s
2024-06-13 06:02:24,786 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-MShape62 crash on backend pytorch when predicting
2024-06-13 06:02:24,807 logger.py[line:35] INFO coverage_c=14446
2024-06-13 06:02:24,868 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-MShape62
2024-06-13 06:02:24,868 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:02:24,868 logger.py[line:35] INFO after_prediction
2024-06-13 06:02:24,986 logger.py[line:35] INFO INFO: Mutation progress 63/100
2024-06-13 06:02:24,986 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:02:24,986 logger.py[line:35] INFO Score for NLAll is: 0.8375
2024-06-13 06:02:24,986 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:02:24,986 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:02:24,986 logger.py[line:35] INFO Score for MDtype is: 0.7662337662337663
2024-06-13 06:02:24,987 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:02:24,987 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:02:24,987 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:02:24,987 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:02:24,987 logger.py[line:35] INFO The last used seed is: MShape
2024-06-13 06:02:24,987 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:02:24,987 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll93
2024-06-13 06:02:24,987 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:02:38,714 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'leaky_re_lu_insert': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll')>, 'custom_pad_layer_2': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'custom_pad_layer_2_copy_NLAll')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'spatial_dropout2d_insert': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'spatial_dropout2d_insert_copy_NLAll')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>}
2024-06-13 06:02:49,128 logger.py[line:35] INFO Insert 2 out of 30 Local New Layers
2024-06-13 06:02:49,128 logger.py[line:35] INFO insert AlphaDropout after cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:02:49,129 logger.py[line:35] INFO insert Conv2DTranspose after locally_connected2d_insert_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.convolutional.Conv2DTranspose object at 0x7fad9825c7d0>
2024-06-13 06:02:59,128 logger.py[line:35] INFO Converting output shape (None, 123, 29, 131) to actual shape [None, 10, 28, 123]
[DEBUG] Inserting layer: <keras.layers.noise.AlphaDropout object at 0x7fad98233750>
2024-06-13 06:02:59,167 logger.py[line:35] INFO Converting output shape (None, 10, 10, 64) to actual shape [None, 10, 10, 64]
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'leaky_re_lu_insert_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll')>, 'custom_pad_layer_2_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'custom_pad_layer_2_copy_NLAll')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'spatial_dropout2d_insert_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'spatial_dropout2d_insert_copy_NLAll')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>}
2024-06-13 06:02:59,412 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 148/2170
The Configuration Coverage is: 396/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 69/354
The Shape Coverage Is: 141/295
The Input Coverage Is: 272/766
2024-06-13 06:03:12,456 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:03:12,918 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll93-NLAll63/resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll93-NLAll63.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:08:15,640 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 5m, 2s
2024-06-13 06:08:15,640 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll93-NLAll63 crash on backend pytorch when predicting
2024-06-13 06:08:15,661 logger.py[line:35] INFO coverage_c=14446
2024-06-13 06:08:15,748 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll93-NLAll63
2024-06-13 06:08:15,748 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:08:15,748 logger.py[line:35] INFO after_prediction
2024-06-13 06:08:16,154 logger.py[line:35] INFO INFO: Mutation progress 64/100
2024-06-13 06:08:16,155 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:08:16,155 logger.py[line:35] INFO Score for NLAll is: 0.8333333333333334
2024-06-13 06:08:16,155 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:08:16,155 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:08:16,155 logger.py[line:35] INFO Score for MDtype is: 0.7662337662337663
2024-06-13 06:08:16,155 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:08:16,155 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:08:16,155 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:08:16,155 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:08:16,155 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:08:16,155 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:08:16,160 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82
2024-06-13 06:08:16,160 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:08:20,586 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 06:08:21,864 logger.py[line:35] INFO Insert 2 out of 28 Local New Layers
2024-06-13 06:08:21,864 logger.py[line:35] INFO insert UpSampling2D after conv4_block6_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 06:08:21,864 logger.py[line:35] INFO insert ReLU after pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ReLU object at 0x7f2b6061c690>
2024-06-13 06:08:21,893 logger.py[line:35] INFO Converting output shape (None, 114, 114, 64) to actual shape [None, 114, 114, 64]
[DEBUG] Inserting layer: <keras.layers.convolutional.UpSampling2D object at 0x7f2b603c7a10>
2024-06-13 06:08:22,591 logger.py[line:35] INFO Converting output shape (None, 14, 112, 8192) to actual shape [None, 14, 14, 1024]
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 06:08:23,007 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 152/2170
The Configuration Coverage is: 396/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 69/354
The Shape Coverage Is: 143/295
The Input Coverage Is: 274/766
2024-06-13 06:08:25,122 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:08:25,585 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:09:00,067 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:09:00,068 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/batchnorm.py", line 65, in forward
    return self.bnu.forward(X)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 179, in forward
    self.eps,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2283, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: Expected weight to have type Float but got Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:09:03,852 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 38s
2024-06-13 06:09:03,852 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll64 crash on backend pytorch when predicting
2024-06-13 06:09:03,873 logger.py[line:35] INFO coverage_c=14527
2024-06-13 06:09:03,884 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll64
2024-06-13 06:09:03,885 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:09:03,885 logger.py[line:35] INFO after_prediction
2024-06-13 06:09:04,027 logger.py[line:35] INFO INFO: Mutation progress 65/100
2024-06-13 06:09:04,027 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:09:04,027 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:09:04,027 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:09:04,027 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:09:04,027 logger.py[line:35] INFO Score for MDtype is: 0.7662337662337663
2024-06-13 06:09:04,027 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:09:04,028 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:09:04,028 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:09:04,028 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:09:04,028 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:09:04,028 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:09:04,028 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99
2024-06-13 06:09:04,028 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:09:11,331 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MParam')>}
2024-06-13 06:09:14,834 logger.py[line:35] INFO Changing 2/15 of layer conv2d_193_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 06:09:14,834 logger.py[line:35] INFO changing config kernel_regularizer in layer conv2d_193_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MParam: from None to l2
2024-06-13 06:09:14,834 logger.py[line:35] INFO changing config data_format in layer conv2d_193_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MParam: from channels_last to channels_first
2024-06-13 06:09:14,834 logger.py[line:35] INFO changing config dilation_rate in layer conv2d_193_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MParam: from (1, 1) to [4, 1]
2024-06-13 06:09:14,835 logger.py[line:35] INFO Changing 1/15 of layer block8_5_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 06:09:14,835 logger.py[line:35] INFO changing config strides in layer block8_5_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MParam: from (1, 1) to [1, 3]
2024-06-13 06:09:14,835 logger.py[line:35] INFO changing config dilation_rate in layer block8_5_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MParam: from (1, 1) to [1, 2]
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 276, in change_layer_config
    x = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py", line 997, in _get_strides_and_dilation_rate
    "`strides > 1` not supported in conjunction with `dilation_rate > 1`. "
ValueError: Exception encountered when calling layer "block8_5_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MParam" (type Conv2D).

`strides > 1` not supported in conjunction with `dilation_rate > 1`. Received: strides=[1 3] and dilation_rate=[1 2]

Call arguments received:
   inputs=tf.Tensor(shape=(None, 8, 8, 448), dtype=float32)
2024-06-13 06:09:18,600 logger.py[line:35] INFO INFO: Mutation progress 65/100
2024-06-13 06:09:18,600 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:09:18,601 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:09:18,601 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:09:18,601 logger.py[line:35] INFO Score for Edge is: 0.7727272727272727
2024-06-13 06:09:18,601 logger.py[line:35] INFO Score for MDtype is: 0.7662337662337663
2024-06-13 06:09:18,601 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:09:18,601 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:09:18,601 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:09:18,601 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:09:18,601 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:09:18,601 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:09:18,601 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65
2024-06-13 06:09:18,601 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:09:21,560 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:09:22,158 logger.py[line:35] INFO Generating model using Edge
2024-06-13 06:09:22,161 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge')>}
Choosing 3 To Insert
2024-06-13 06:09:22,341 logger.py[line:35] INFO Insert 3 Local New Edges
2024-06-13 06:09:22,341 logger.py[line:35] INFO Candidate Edge: ('Dropout', 'RepeatVector')
2024-06-13 06:09:22,350 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:09:22,525 logger.py[line:35] INFO Trying Adding Edge: ['Dropout', 'RepeatVector'] by Connecting dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge and repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 06:09:22,528 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:09:22,718 logger.py[line:35] INFO Successfully Add Edge: ['Dropout', 'RepeatVector'] by Connecting dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge and repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 06:09:22,718 logger.py[line:35] INFO Candidate Edge: ('RepeatVector', 'LSTM')
2024-06-13 06:09:22,730 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:09:22,927 logger.py[line:35] INFO Trying Adding Edge: ['RepeatVector', 'LSTM'] by Connecting repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 and lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 06:09:22,930 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:09:23,026 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:09:23,310 logger.py[line:35] INFO Successfully Add Edge: ['RepeatVector', 'LSTM'] by Connecting repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 and lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 06:09:23,311 logger.py[line:35] INFO Candidate Edge: ('LSTM', 'RepeatVector')
2024-06-13 06:09:23,321 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:09:23,333 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:09:23,608 logger.py[line:35] INFO Trying Adding Edge: ['LSTM', 'RepeatVector'] by Connecting lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 and repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2
2024-06-13 06:09:23,611 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:09:23,801 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:09:23,898 logger.py[line:35] INFO Successfully Add Edge: ['LSTM', 'RepeatVector'] by Connecting lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 and repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2
2024-06-13 06:09:23,942 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:09:24,387 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:09:24,399 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 152/2170
The Configuration Coverage is: 396/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 69/354
The Shape Coverage Is: 143/295
The Input Coverage Is: 274/766
2024-06-13 06:09:24,697 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:09:25,166 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:09:34,049 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:09:34,050 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 208, in forward
    outputs = op((self,), activations, *in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/loop.py", line 95, in forward
    while i < M and cond:
RuntimeError: t == DeviceType::CUDAINTERNAL ASSERT FAILED at "/root/dl_libraries/pytorch/c10/cuda/impl/CUDAGuardImpl.h":24, please report a bug to PyTorch. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:09:36,346 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 11s
2024-06-13 06:09:36,347 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65-Edge65 crash on backend pytorch when predicting
2024-06-13 06:09:36,368 logger.py[line:35] INFO coverage_c=14527
2024-06-13 06:09:36,419 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65-Edge65
2024-06-13 06:09:36,419 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:09:36,420 logger.py[line:35] INFO after_prediction
2024-06-13 06:09:36,420 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65-Edge65, do not increase the reward
2024-06-13 06:09:36,546 logger.py[line:35] INFO INFO: Mutation progress 66/100
2024-06-13 06:09:36,546 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:09:36,546 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:09:36,546 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:09:36,546 logger.py[line:35] INFO Score for MDtype is: 0.7662337662337663
2024-06-13 06:09:36,546 logger.py[line:35] INFO Score for Edge is: 0.7611940298507462
2024-06-13 06:09:36,546 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:09:36,546 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:09:36,546 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:09:36,546 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:09:36,546 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 06:09:36,546 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:09:36,547 logger.py[line:35] INFO Choose seed: densenet121-MDims75
2024-06-13 06:09:36,547 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:09:42,024 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_MDims': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MDims_copy_Edge')>}
Choosing 6 To Insert
2024-06-13 06:09:43,919 logger.py[line:35] INFO Insert 6 Local New Edges
2024-06-13 06:09:43,919 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'ZeroPadding2D')
2024-06-13 06:09:46,226 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'ZeroPadding2D'] by Connecting zero_padding2d_1_copy_MDims_copy_Edge and zero_padding2d_2_copy_MDims_copy_Edge
2024-06-13 06:09:48,225 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'ZeroPadding2D'] by Connecting zero_padding2d_1_copy_MDims_copy_Edge and zero_padding2d_2_copy_MDims_copy_Edge
2024-06-13 06:09:48,225 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'Conv2D')
2024-06-13 06:09:50,438 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'Conv2D'] by Connecting conv5_block9_2_conv_copy_MDims_copy_Edge and conv3_block10_1_conv_copy_MDims_copy_Edge
2024-06-13 06:09:52,559 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'Conv2D'] by Connecting conv5_block9_2_conv_copy_MDims_copy_Edge and conv3_block10_1_conv_copy_MDims_copy_Edge
2024-06-13 06:09:52,559 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'AveragePooling2D')
2024-06-13 06:09:54,776 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'AveragePooling2D'] by Connecting pool2_pool_copy_MDims_copy_Edge and pool2_pool_copy_MDims_copy_Edge
2024-06-13 06:09:56,872 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'AveragePooling2D'] by Connecting pool2_pool_copy_MDims_copy_Edge and pool2_pool_copy_MDims_copy_Edge
2024-06-13 06:09:56,872 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'AveragePooling2D')
2024-06-13 06:09:59,102 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'AveragePooling2D'] by Connecting conv4_block2_0_bn_copy_MDims_copy_Edge and pool2_pool_copy_MDims_copy_Edge_1
2024-06-13 06:10:01,225 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'AveragePooling2D'] by Connecting conv4_block2_0_bn_copy_MDims_copy_Edge and pool2_pool_copy_MDims_copy_Edge_1
2024-06-13 06:10:01,225 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'MaxPooling2D')
2024-06-13 06:10:03,460 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'MaxPooling2D'] by Connecting pool3_pool_copy_MDims_copy_Edge and pool1_copy_MDims_copy_Edge
2024-06-13 06:10:05,353 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'MaxPooling2D'] by Connecting pool3_pool_copy_MDims_copy_Edge and pool1_copy_MDims_copy_Edge
2024-06-13 06:10:05,353 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'ZeroPadding2D')
2024-06-13 06:10:07,814 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'ZeroPadding2D'] by Connecting conv4_block19_1_conv_copy_MDims_copy_Edge and zero_padding2d_1_copy_MDims_copy_Edge
2024-06-13 06:10:09,716 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'ZeroPadding2D'] by Connecting conv4_block19_1_conv_copy_MDims_copy_Edge and zero_padding2d_1_copy_MDims_copy_Edge
2024-06-13 06:10:09,929 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 152/2170
The Configuration Coverage is: 396/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 69/354
The Shape Coverage Is: 143/295
The Input Coverage Is: 274/766
2024-06-13 06:10:13,654 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:10:14,117 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:10:41,206 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:10:41,207 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/reshape.py", line 31, in forward
    return torch.reshape(input, tuple(shape))
RuntimeError: shape '[-1, 14112]' is invalid for input of size 1233792

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:10:46,524 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 32s
2024-06-13 06:10:46,524 logger.py[line:35] INFO densenet121-MDims75-Edge66 crash on backend pytorch when predicting
2024-06-13 06:10:46,546 logger.py[line:35] INFO coverage_c=14527
2024-06-13 06:10:46,608 logger.py[line:35] INFO Fail on backend: pytorch of model densenet121-MDims75-Edge66
2024-06-13 06:10:46,608 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:10:46,608 logger.py[line:35] INFO after_prediction
2024-06-13 06:10:46,608 logger.py[line:35] INFO No representative seed generated: densenet121-MDims75-Edge66, do not increase the reward
2024-06-13 06:10:46,767 logger.py[line:35] INFO INFO: Mutation progress 67/100
2024-06-13 06:10:46,767 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:10:46,767 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:10:46,767 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:10:46,767 logger.py[line:35] INFO Score for MDtype is: 0.7662337662337663
2024-06-13 06:10:46,768 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:10:46,768 logger.py[line:35] INFO Score for Edge is: 0.75
2024-06-13 06:10:46,768 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:10:46,768 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:10:46,768 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:10:46,768 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 06:10:46,768 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:10:46,768 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42
2024-06-13 06:10:46,768 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:10:51,089 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>}
2024-06-13 06:10:52,168 logger.py[line:35] INFO Change 5 Layer's DType Out Of 9 Layer classes
2024-06-13 06:10:52,168 logger.py[line:35] INFO Changing 5 out of 9 Layer's DType.
2024-06-13 06:10:52,169 logger.py[line:35] INFO Selecting a Global DType float32 For Layer time_distributed_insert_copy_MDtype
2024-06-13 06:10:52,169 logger.py[line:35] INFO Selecting a Global DType bfloat16 For Layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype
2024-06-13 06:10:52,170 logger.py[line:35] INFO Selecting a Global DType bfloat16 For Layer conv4_block1_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype
2024-06-13 06:10:52,171 logger.py[line:35] INFO Selecting a Global DType bfloat16 For Layer cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype
2024-06-13 06:10:52,171 logger.py[line:35] INFO Selecting a Global DType float16 For Layer avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 64) dtype=float32 (created by layer 'custom_cast_layer_7')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'custom_cast_layer_9')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll_copy_MDtype')>}
2024-06-13 06:10:53,335 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 152/2170
The Configuration Coverage is: 396/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 72/354
The Shape Coverage Is: 143/295
The Input Coverage Is: 277/766
2024-06-13 06:10:55,498 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:10:55,961 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 58, in <module>
    transform_onnx(model_path)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 41, in transform_onnx
    model = keras.models.load_model(model_path, custom_objects=custom_objects())
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/save.py", line 201, in load_model
    compile)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/hdf5_format.py", line 184, in load_model_from_hdf5
    load_weights_from_hdf5_group(f['model_weights'], model.layers)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/hdf5_format.py", line 713, in load_weights_from_hdf5_group
    backend.batch_set_value(weight_value_tuples)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
    return target(*args, **kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/backend.py", line 3775, in batch_set_value
    x.assign(np.asarray(value, dtype=dtype_numpy(x)))
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/numpy/core/_asarray.py", line 83, in asarray
    return array(a, dtype, copy=False, order=order)
ValueError: No cast function available.
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42-MDtype67/resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42-MDtype67.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:11:03,237 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 7s
2024-06-13 06:11:03,237 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42-MDtype67 crash on backend pytorch when predicting
2024-06-13 06:11:03,258 logger.py[line:35] INFO coverage_c=14527
2024-06-13 06:11:03,317 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42-MDtype67
2024-06-13 06:11:03,317 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:11:03,317 logger.py[line:35] INFO after_prediction
2024-06-13 06:11:03,473 logger.py[line:35] INFO INFO: Mutation progress 68/100
2024-06-13 06:11:03,473 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:11:03,473 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:11:03,473 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:11:03,474 logger.py[line:35] INFO Score for MDtype is: 0.7628205128205128
2024-06-13 06:11:03,474 logger.py[line:35] INFO Score for Edge is: 0.75
2024-06-13 06:11:03,474 logger.py[line:35] INFO Score for LMerg is: 0.75
2024-06-13 06:11:03,474 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:11:03,474 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:11:03,474 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:11:03,474 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 06:11:03,474 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:11:03,474 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97
2024-06-13 06:11:03,474 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:11:06,432 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:11:06,445 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:11:07,176 logger.py[line:35] INFO Generating model using LMerg
2024-06-13 06:11:07,179 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:11:07,405 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_copy_LMerg')>, 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_LMerg')>, 'cropping3d': <KerasTensor: shape=(None, 1, 11, 11, 2025) dtype=float32 (created by layer 'cropping3d_copy_LMerg')>, 'lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_LMerg')>, 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 2, 25) dtype=float32 (created by layer 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 06:11:07,507 logger.py[line:35] INFO Insert 1 out of 8 Local New Layer
2024-06-13 06:11:07,507 logger.py[line:35] INFO Trying Merge Layers: custom_drop_dim_layer_copy_MDtype_copy_Edge_copy_LMerg and custom_cast_layer_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_copy_LMerg by Maximum
2024-06-13 06:11:07,510 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:11:07,738 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:11:07,838 logger.py[line:35] INFO Success on Merge Layers: custom_drop_dim_layer_copy_MDtype_copy_Edge_copy_LMerg and custom_cast_layer_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_copy_LMerg by Maximum
2024-06-13 06:11:07,886 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:11:08,540 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:11:08,557 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 152/2170
The Configuration Coverage is: 396/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 72/354
The Shape Coverage Is: 143/295
The Input Coverage Is: 277/766
2024-06-13 06:11:08,883 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:11:09,348 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:11:38,842 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:11:38,842 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 208, in forward
    outputs = op((self,), activations, *in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/loop.py", line 95, in forward
    while i < M and cond:
RuntimeError: t == DeviceType::CUDAINTERNAL ASSERT FAILED at "/root/dl_libraries/pytorch/c10/cuda/impl/CUDAGuardImpl.h":24, please report a bug to PyTorch. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:11:41,303 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 31s
2024-06-13 06:11:41,303 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97-LMerg68 crash on backend pytorch when predicting
2024-06-13 06:11:41,325 logger.py[line:35] INFO coverage_c=14527
2024-06-13 06:11:41,334 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97-LMerg68
2024-06-13 06:11:41,334 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:11:41,334 logger.py[line:35] INFO after_prediction
2024-06-13 06:11:41,334 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97-LMerg68, do not increase the reward
2024-06-13 06:11:41,463 logger.py[line:35] INFO INFO: Mutation progress 69/100
2024-06-13 06:11:41,464 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:11:41,464 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:11:41,464 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:11:41,464 logger.py[line:35] INFO Score for MDtype is: 0.7628205128205128
2024-06-13 06:11:41,464 logger.py[line:35] INFO Score for Edge is: 0.75
2024-06-13 06:11:41,464 logger.py[line:35] INFO Score for MDims is: 0.7386363636363636
2024-06-13 06:11:41,464 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:11:41,464 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:11:41,464 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:11:41,464 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 06:11:41,464 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:11:41,464 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99
2024-06-13 06:11:41,464 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:11:48,889 logger.py[line:35] INFO Generating model using MDims
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MDims')>}
2024-06-13 06:11:52,345 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 06:11:52,346 logger.py[line:35] INFO Global Layer Class: 0; Local Layer Class: 1; Total Layer Class: 1
2024-06-13 06:11:52,346 logger.py[line:35] INFO Changing 0 Layer's NDims.
2024-06-13 06:11:52,346 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 06:11:52,349 logger.py[line:35] INFO No Global NDims Can Be Found, Randomly Select NDims: 6 For Layer: batch_normalization_72_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MDims
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MDims': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_MDims')>}
2024-06-13 06:11:56,204 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 152/2170
The Configuration Coverage is: 396/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 72/354
The Shape Coverage Is: 143/295
The Input Coverage Is: 277/766
2024-06-13 06:12:02,460 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:12:02,925 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (1047) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:13:02,716 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 59s
2024-06-13 06:13:02,716 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99-MDims69 crash on backend pytorch when predicting
2024-06-13 06:13:02,737 logger.py[line:35] INFO coverage_c=14527
2024-06-13 06:13:02,752 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99-MDims69
2024-06-13 06:13:02,752 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:13:02,752 logger.py[line:35] INFO after_prediction
2024-06-13 06:13:02,752 logger.py[line:35] INFO No representative seed generated: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99-MDims69, do not increase the reward
2024-06-13 06:13:02,941 logger.py[line:35] INFO INFO: Mutation progress 70/100
2024-06-13 06:13:02,941 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:13:02,942 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:13:02,942 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:13:02,942 logger.py[line:35] INFO Score for MDtype is: 0.7628205128205128
2024-06-13 06:13:02,942 logger.py[line:35] INFO Score for Edge is: 0.75
2024-06-13 06:13:02,942 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:13:02,942 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:13:02,942 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:13:02,942 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:13:02,942 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 06:13:02,942 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:13:02,942 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102
2024-06-13 06:13:02,942 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:13:10,315 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam')>}
2024-06-13 06:13:13,811 logger.py[line:35] INFO Changing 3/15 of layer conv2d_91_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:13:13,812 logger.py[line:35] INFO changing config kernel_constraint in layer conv2d_91_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from None to UnitNorm
2024-06-13 06:13:13,812 logger.py[line:35] INFO changing config bias_constraint in layer conv2d_91_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from None to UnitNorm
2024-06-13 06:13:13,812 logger.py[line:35] INFO changing config filters in layer conv2d_91_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from 160 to 7
2024-06-13 06:13:13,812 logger.py[line:35] INFO changing config dilation_rate in layer conv2d_91_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from (1, 1) to [1, 1]
2024-06-13 06:13:13,812 logger.py[line:35] INFO Changing 1/5 of layer batch_normalization_82_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:13:13,812 logger.py[line:35] INFO changing config scale in layer batch_normalization_82_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from False to False
2024-06-13 06:13:13,812 logger.py[line:35] INFO changing config center in layer batch_normalization_82_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from True to True
2024-06-13 06:13:13,812 logger.py[line:35] INFO Changing 1/1 of layer block17_9_mixed_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:13:13,812 logger.py[line:35] INFO changing config axis in layer block17_9_mixed_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from 3 to -2
2024-06-13 06:13:13,812 logger.py[line:35] INFO Changing 1/15 of layer block8_1_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:13:13,813 logger.py[line:35] INFO changing config use_bias in layer block8_1_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:13:13,813 logger.py[line:35] INFO changing config bias_constraint in layer block8_1_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from None to UnitNorm
2024-06-13 06:13:13,813 logger.py[line:35] INFO Changing 1/5 of layer batch_normalization_158_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:13:13,813 logger.py[line:35] INFO changing config center in layer batch_normalization_158_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:13:13,813 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:13:13,813 logger.py[line:35] INFO changing config axis in layer batch_normalization_158_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:13:13,813 logger.py[line:35] INFO Changing 3/5 of layer batch_normalization_91_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:13:13,813 logger.py[line:35] INFO changing config axis in layer batch_normalization_91_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:13:13,813 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:13:13,813 logger.py[line:35] INFO changing config scale in layer batch_normalization_91_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from False to True
2024-06-13 06:13:13,814 logger.py[line:35] INFO changing config center in layer batch_normalization_91_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:13:13,814 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:13:13,814 logger.py[line:35] INFO Changing 3/5 of layer batch_normalization_125_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:13:13,814 logger.py[line:35] INFO changing config axis in layer batch_normalization_125_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:13:13,814 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:13:13,814 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:13:13,814 logger.py[line:35] INFO changing config scale in layer batch_normalization_125_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from False to True
2024-06-13 06:13:13,814 logger.py[line:35] INFO changing config center in layer batch_normalization_125_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:13:13,814 logger.py[line:35] INFO Changing 2/15 of layer conv2d_94_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:13:13,814 logger.py[line:35] INFO changing config strides in layer conv2d_94_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from (1, 1) to [1, 1]
2024-06-13 06:13:13,815 logger.py[line:35] INFO changing config use_bias in layer conv2d_94_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from False to False
2024-06-13 06:13:13,815 logger.py[line:35] INFO changing config kernel_regularizer in layer conv2d_94_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from None to l2
2024-06-13 06:13:13,815 logger.py[line:35] INFO Changing 1/5 of layer batch_normalization_147_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:13:13,815 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:13:13,815 logger.py[line:35] INFO changing config axis in layer batch_normalization_147_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:13:13,815 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:13:13,815 logger.py[line:35] INFO changing config center in layer batch_normalization_147_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam: from True to False
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "inception_resnet_v2.py", line 319, in <lambda>
ValueError: Exception encountered when calling layer "block17_9_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam" (type Lambda).

Dimensions must be equal, but are 17 and 34 for '{{node block17_9_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam/add}} = AddV2[T=DT_FLOAT](Placeholder, block17_9_copy_MParam_copy_MDtype_copy_MDtype_copy_MParam/mul)' with input shapes: [?,17,17,1088], [?,17,34,1088].

Call arguments received:
   inputs=['tf.Tensor(shape=(None, 17, 17, 1088), dtype=float32)', 'tf.Tensor(shape=(None, 17, 34, 1088), dtype=float32)']
   mask=None
   training=None
2024-06-13 06:13:16,388 logger.py[line:35] INFO INFO: Mutation progress 70/100
2024-06-13 06:13:16,388 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:13:16,389 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:13:16,389 logger.py[line:35] INFO Score for MParam is: 0.7741935483870968
2024-06-13 06:13:16,389 logger.py[line:35] INFO Score for MDtype is: 0.7628205128205128
2024-06-13 06:13:16,389 logger.py[line:35] INFO Score for Edge is: 0.75
2024-06-13 06:13:16,389 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:13:16,389 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:13:16,389 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:13:16,389 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:13:16,389 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:13:16,389 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:13:16,389 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype58-MDtype89
2024-06-13 06:13:16,389 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:13:20,602 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_Edge_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam')>, 'cropping2d_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'cropping2d_copy_MDtype_copy_MDtype_copy_MParam')>, 'avg_pool_copy_Edge_2_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_MDtype_copy_MParam')>}
2024-06-13 06:13:21,596 logger.py[line:35] INFO Changing 3/15 of layer conv4_block5_3_conv_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:13:21,596 logger.py[line:35] INFO changing config dilation_rate in layer conv4_block5_3_conv_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam: from (1, 1) to [3, 2]
2024-06-13 06:13:21,596 logger.py[line:35] INFO changing config activity_regularizer in layer conv4_block5_3_conv_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam: from None to l2
2024-06-13 06:13:21,596 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:13:21,596 logger.py[line:35] INFO changing config bias_regularizer in layer conv4_block5_3_conv_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam: from None to l2
2024-06-13 06:13:21,597 logger.py[line:35] INFO changing config use_bias in layer conv4_block5_3_conv_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:13:21,597 logger.py[line:35] INFO Changing 1/5 of layer conv3_block3_3_bn_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:13:21,597 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:13:21,597 logger.py[line:35] INFO changing config scale in layer conv3_block3_3_bn_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:13:21,597 logger.py[line:35] INFO changing config axis in layer conv3_block3_3_bn_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:13:21,597 logger.py[line:35] INFO Changing 2/15 of layer conv2_block1_3_conv_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:13:21,597 logger.py[line:35] INFO changing config kernel_initializer in layer conv2_block1_3_conv_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam: from {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}} to he_normal
2024-06-13 06:13:21,597 logger.py[line:35] INFO changing config activity_regularizer in layer conv2_block1_3_conv_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam: from None to l1
2024-06-13 06:13:21,597 logger.py[line:35] INFO changing config bias_regularizer in layer conv2_block1_3_conv_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam: from None to l1
model outputs {'predictions_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_MDtype_copy_MParam')>, 'cropping2d_copy_MDtype_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'cropping2d_copy_MDtype_copy_MDtype_copy_MParam')>, 'avg_pool_copy_Edge_2_copy_MDtype_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_MDtype_copy_MParam')>}
2024-06-13 06:13:22,594 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 152/2170
The Configuration Coverage is: 400/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 72/354
The Shape Coverage Is: 143/295
The Input Coverage Is: 277/766
2024-06-13 06:13:24,502 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:13:24,969 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,1,128,512) (1,1,28,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,1,128,512) (1,1,28,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,1,128,512) (1,1,28,1) 
2024-06-13 06:13:51,714 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:13:51,714 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [512, 64, 1, 1], expected input[101, 65, 56, 56] to have 64 channels, but got 65 channels instead

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:13:55,024 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 30s
2024-06-13 06:13:55,025 logger.py[line:35] INFO resnet50-Edge65-MDtype58-MDtype89-MParam70 crash on backend pytorch when predicting
2024-06-13 06:13:55,046 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:13:55,062 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-Edge65-MDtype58-MDtype89-MParam70
2024-06-13 06:13:55,062 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:13:55,062 logger.py[line:35] INFO after_prediction
2024-06-13 06:13:55,201 logger.py[line:35] INFO INFO: Mutation progress 71/100
2024-06-13 06:13:55,201 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:13:55,201 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:13:55,201 logger.py[line:35] INFO Score for MParam is: 0.765625
2024-06-13 06:13:55,201 logger.py[line:35] INFO Score for MDtype is: 0.7628205128205128
2024-06-13 06:13:55,201 logger.py[line:35] INFO Score for Edge is: 0.75
2024-06-13 06:13:55,201 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:13:55,201 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:13:55,201 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:13:55,201 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:13:55,201 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:13:55,201 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:13:55,201 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype58
2024-06-13 06:13:55,201 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:13:59,397 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_Edge_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_MParam')>, 'cropping2d_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'cropping2d_copy_MDtype_copy_MParam')>, 'avg_pool_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_MParam')>}
2024-06-13 06:14:00,382 logger.py[line:35] INFO Changing 3/15 of layer conv4_block2_1_conv_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:14:00,382 logger.py[line:35] INFO changing config bias_regularizer in layer conv4_block2_1_conv_copy_Edge_copy_MDtype_copy_MParam: from None to l2
2024-06-13 06:14:00,382 logger.py[line:35] INFO changing config strides in layer conv4_block2_1_conv_copy_Edge_copy_MDtype_copy_MParam: from (1, 1) to [3, 1]
2024-06-13 06:14:00,382 logger.py[line:35] INFO changing config use_bias in layer conv4_block2_1_conv_copy_Edge_copy_MDtype_copy_MParam: from True to True
2024-06-13 06:14:00,382 logger.py[line:35] INFO changing config bias_constraint in layer conv4_block2_1_conv_copy_Edge_copy_MDtype_copy_MParam: from None to NonNeg
2024-06-13 06:14:00,382 logger.py[line:35] INFO Changing 2/15 of layer conv3_block4_2_conv_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:14:00,382 logger.py[line:35] INFO changing config data_format in layer conv3_block4_2_conv_copy_Edge_copy_MDtype_copy_MParam: from channels_last to channels_first
2024-06-13 06:14:00,382 logger.py[line:35] INFO changing config bias_constraint in layer conv3_block4_2_conv_copy_Edge_copy_MDtype_copy_MParam: from None to Constraint
2024-06-13 06:14:00,382 logger.py[line:35] INFO changing config bias_initializer in layer conv3_block4_2_conv_copy_Edge_copy_MDtype_copy_MParam: from {'class_name': 'Zeros', 'config': {}} to lecun_uniform
2024-06-13 06:14:00,382 logger.py[line:35] INFO Changing 2/15 of layer conv4_block5_2_conv_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:14:00,382 logger.py[line:35] INFO changing config activity_regularizer in layer conv4_block5_2_conv_copy_Edge_copy_MDtype_copy_MParam: from None to l2
2024-06-13 06:14:00,383 logger.py[line:35] INFO changing config kernel_initializer in layer conv4_block5_2_conv_copy_Edge_copy_MDtype_copy_MParam: from {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}} to he_normal
2024-06-13 06:14:00,383 logger.py[line:35] INFO changing config strides in layer conv4_block5_2_conv_copy_Edge_copy_MDtype_copy_MParam: from (1, 1) to [4, 2]
2024-06-13 06:14:00,383 logger.py[line:35] INFO Changing 2/15 of layer conv4_block4_1_conv_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:14:00,383 logger.py[line:35] INFO changing config kernel_constraint in layer conv4_block4_1_conv_copy_Edge_copy_MDtype_copy_MParam: from None to UnitNorm
2024-06-13 06:14:00,383 logger.py[line:35] INFO changing config strides in layer conv4_block4_1_conv_copy_Edge_copy_MDtype_copy_MParam: from (1, 1) to [1, 1]
2024-06-13 06:14:00,383 logger.py[line:35] INFO changing config bias_constraint in layer conv4_block4_1_conv_copy_Edge_copy_MDtype_copy_MParam: from None to Constraint
2024-06-13 06:14:00,383 logger.py[line:35] INFO Changing 2/15 of layer conv4_block2_3_conv_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:14:00,383 logger.py[line:35] INFO changing config bias_regularizer in layer conv4_block2_3_conv_copy_Edge_copy_MDtype_copy_MParam: from None to l2
2024-06-13 06:14:00,383 logger.py[line:35] INFO changing config activation in layer conv4_block2_3_conv_copy_Edge_copy_MDtype_copy_MParam: from linear to exponential
2024-06-13 06:14:00,383 logger.py[line:35] INFO changing config kernel_initializer in layer conv4_block2_3_conv_copy_Edge_copy_MDtype_copy_MParam: from {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}} to glorot_normal
2024-06-13 06:14:00,383 logger.py[line:35] INFO Changing 1/5 of layer conv4_block3_2_bn_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:14:00,383 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:14:00,383 logger.py[line:35] INFO changing config scale in layer conv4_block3_2_bn_copy_Edge_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:14:00,383 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:14:00,383 logger.py[line:35] INFO changing config axis in layer conv4_block3_2_bn_copy_Edge_copy_MDtype_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:14:00,384 logger.py[line:35] INFO Changing 2/2 of layer avg_pool_copy_Edge_1_copy_MDtype_copy_MParam's configuration
2024-06-13 06:14:00,384 logger.py[line:35] INFO changing config keepdims in layer avg_pool_copy_Edge_1_copy_MDtype_copy_MParam: from False to True
2024-06-13 06:14:00,384 logger.py[line:35] INFO changing config data_format in layer avg_pool_copy_Edge_1_copy_MDtype_copy_MParam: from channels_last to channels_first
2024-06-13 06:14:00,384 logger.py[line:35] INFO Changing 1/5 of layer conv2_block2_2_bn_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:14:00,384 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:14:00,384 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:14:00,384 logger.py[line:35] INFO changing config axis in layer conv2_block2_2_bn_copy_Edge_copy_MDtype_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:14:00,384 logger.py[line:35] INFO changing config center in layer conv2_block2_2_bn_copy_Edge_copy_MDtype_copy_MParam: from True to False
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/merge.py", line 79, in _compute_elemwise_op_output_shape
    'Inputs have incompatible shapes. '
ValueError: Inputs have incompatible shapes. Received shapes (28, 28, 512) and (128, 28, 512)
2024-06-13 06:14:01,262 logger.py[line:35] INFO INFO: Mutation progress 71/100
2024-06-13 06:14:01,262 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:14:01,262 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:14:01,262 logger.py[line:35] INFO Score for MParam is: 0.765625
2024-06-13 06:14:01,262 logger.py[line:35] INFO Score for MDtype is: 0.7628205128205128
2024-06-13 06:14:01,262 logger.py[line:35] INFO Score for Edge is: 0.75
2024-06-13 06:14:01,262 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:14:01,262 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:14:01,262 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:14:01,262 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:14:01,262 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:14:01,263 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:14:01,263 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype60
2024-06-13 06:14:01,263 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:14:04,690 logger.py[line:35] INFO Generating model using Edge
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge')>}
Choosing 3 To Insert
2024-06-13 06:14:04,796 logger.py[line:35] INFO Insert 1 Global New Edges
2024-06-13 06:14:04,796 logger.py[line:35] INFO Insert 2 Local New Edges
2024-06-13 06:14:04,796 logger.py[line:35] INFO Candidate Edge: ('Dropout', 'Flatten')
2024-06-13 06:14:04,905 logger.py[line:35] INFO Trying Adding Edge: ['Dropout', 'Flatten'] by Connecting dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge and flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 06:14:05,008 logger.py[line:35] INFO Successfully Add Edge: ['Dropout', 'Flatten'] by Connecting dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge and flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 06:14:05,008 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'Dropout')
2024-06-13 06:14:05,119 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'Dropout'] by Connecting conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge and dropout_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 06:14:05,224 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'Dropout'] by Connecting conv2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge and dropout_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 06:14:05,224 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'Dropout')
2024-06-13 06:14:05,337 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'Dropout'] by Connecting batch_normalization_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge and dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 06:14:05,444 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'Dropout'] by Connecting batch_normalization_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge and dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge
2024-06-13 06:14:05,485 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 153/2170
The Configuration Coverage is: 400/2049
The NDims Coverage Is: 62/117
The DType Coverage Is: 72/354
The Shape Coverage Is: 143/295
The Input Coverage Is: 277/766
2024-06-13 06:14:06,276 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:14:06,743 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:14:27,908 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:14:27,909 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/batchnorm.py", line 65, in forward
    return self.bnu.forward(X)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 179, in forward
    self.eps,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2283, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: Expected weight to have type Float but got Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:14:31,140 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 06:14:31,140 logger.py[line:35] INFO alexnet-SpecialI120-MDims44-MDtype60-Edge71 crash on backend pytorch when predicting
2024-06-13 06:14:31,162 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:14:31,217 logger.py[line:35] INFO Fail on backend: pytorch of model alexnet-SpecialI120-MDims44-MDtype60-Edge71
2024-06-13 06:14:31,217 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:14:31,218 logger.py[line:35] INFO after_prediction
2024-06-13 06:14:31,338 logger.py[line:35] INFO INFO: Mutation progress 72/100
2024-06-13 06:14:31,338 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:14:31,338 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:14:31,338 logger.py[line:35] INFO Score for MParam is: 0.765625
2024-06-13 06:14:31,338 logger.py[line:35] INFO Score for MDtype is: 0.7628205128205128
2024-06-13 06:14:31,338 logger.py[line:35] INFO Score for Edge is: 0.7463768115942029
2024-06-13 06:14:31,338 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:14:31,338 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:14:31,338 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:14:31,338 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:14:31,338 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 06:14:31,338 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:14:31,339 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MDtype113-MDtype54-SpecialI59-NLAll73
2024-06-13 06:14:31,339 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:14:34,304 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:14:35,077 logger.py[line:35] INFO Generating model using MParam
2024-06-13 06:14:35,082 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_NLAll_copy_MParam')>}
2024-06-13 06:14:35,334 logger.py[line:35] INFO Changing 2/25 of layer conv_lstm2d_insert_copy_MParam's configuration
2024-06-13 06:14:35,335 logger.py[line:35] INFO changing config recurrent_constraint in layer conv_lstm2d_insert_copy_MParam: from {'class_name': 'MaxNorm', 'config': {'max_value': 2, 'axis': 0}} to MinMaxNorm
2024-06-13 06:14:35,335 logger.py[line:35] INFO changing config recurrent_dropout in layer conv_lstm2d_insert_copy_MParam: from 0.4435873500198181 to 0.2684369893053612
2024-06-13 06:14:35,335 logger.py[line:35] INFO changing config recurrent_initializer in layer conv_lstm2d_insert_copy_MParam: from {'class_name': 'Zeros', 'config': {}} to RandomNormal
2024-06-13 06:14:35,335 logger.py[line:35] INFO Changing 1/21 of layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_NLAll_copy_MParam's configuration
2024-06-13 06:14:35,335 logger.py[line:35] INFO changing config dropout in layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_NLAll_copy_MParam: from 0.0 to 0.628264871068835
2024-06-13 06:14:35,335 logger.py[line:35] INFO changing config unroll in layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_NLAll_copy_MParam: from False to True
2024-06-13 06:14:35,340 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_NLAll_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:14:35,342 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_NLAll_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_NLAll_copy_MParam': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_NLAll_copy_MParam')>}
2024-06-13 06:14:35,652 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:14:36,112 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_NLAll_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 155/2170
The Configuration Coverage is: 430/2049
The NDims Coverage Is: 64/117
The DType Coverage Is: 73/354
The Shape Coverage Is: 145/295
The Input Coverage Is: 282/766
2024-06-13 06:14:36,341 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:14:36,803 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 148, in convert_operations
    **extract_attributes(node),
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/loop.py", line 40, in __init__
    body, opset_version, batch_dim
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 104, in convert_operations
    op = convert_layer(node, "Conv", params)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/layer.py", line 80, in convert_layer
    layer = layer(**kwargs)
TypeError: __init__() missing 2 required positional arguments: 'in_channels' and 'out_channels'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
Automatic inference of operator: neg
2024-06-13 06:14:45,030 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 8s
2024-06-13 06:14:45,030 logger.py[line:35] INFO lstm2-NLAll38-SpecialI47-MDtype113-MDtype54-SpecialI59-NLAll73-MParam72 crash on backend pytorch when predicting
2024-06-13 06:14:45,051 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:14:45,061 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-SpecialI47-MDtype113-MDtype54-SpecialI59-NLAll73-MParam72
2024-06-13 06:14:45,061 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:14:45,062 logger.py[line:35] INFO after_prediction
2024-06-13 06:14:45,184 logger.py[line:35] INFO INFO: Mutation progress 73/100
2024-06-13 06:14:45,184 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:14:45,184 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:14:45,184 logger.py[line:35] INFO Score for MDtype is: 0.7628205128205128
2024-06-13 06:14:45,184 logger.py[line:35] INFO Score for MParam is: 0.7575757575757576
2024-06-13 06:14:45,185 logger.py[line:35] INFO Score for Edge is: 0.7463768115942029
2024-06-13 06:14:45,185 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:14:45,185 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:14:45,185 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:14:45,185 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:14:45,185 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:14:45,185 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:14:45,185 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94
2024-06-13 06:14:45,185 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:14:49,488 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge')>}
Choosing 9 To Insert
2024-06-13 06:14:50,476 logger.py[line:35] INFO Insert 9 Local New Edges
2024-06-13 06:14:50,477 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'MaxPooling2D')
2024-06-13 06:14:51,454 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'MaxPooling2D'] by Connecting conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge
2024-06-13 06:14:52,351 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'MaxPooling2D'] by Connecting conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge
2024-06-13 06:14:52,351 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'MaxPooling2D')
2024-06-13 06:14:53,437 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'MaxPooling2D'] by Connecting conv2_block2_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge_2
2024-06-13 06:14:54,340 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'MaxPooling2D'] by Connecting conv2_block2_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge_2
2024-06-13 06:14:54,340 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'MaxPooling2D')
2024-06-13 06:14:55,329 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'MaxPooling2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge_2_1 and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge_1
2024-06-13 06:14:56,406 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'MaxPooling2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge_2_1 and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge_1
2024-06-13 06:14:56,406 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'BatchNormalization')
2024-06-13 06:14:57,402 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'BatchNormalization'] by Connecting conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge and conv3_block4_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge
2024-06-13 06:14:58,315 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'BatchNormalization'] by Connecting conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge and conv3_block4_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge
2024-06-13 06:14:58,315 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'GlobalAveragePooling2D')
2024-06-13 06:14:59,320 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'GlobalAveragePooling2D'] by Connecting conv4_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge
2024-06-13 06:15:00,414 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'GlobalAveragePooling2D'] by Connecting conv4_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge
2024-06-13 06:15:00,414 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'Conv2D')
2024-06-13 06:15:01,434 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'Conv2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge_1_1 and conv2_block1_0_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge
2024-06-13 06:15:02,361 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'Conv2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge_1_1 and conv2_block1_0_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge
2024-06-13 06:15:02,361 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'BatchNormalization')
2024-06-13 06:15:03,381 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting conv3_block3_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge and conv5_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge
2024-06-13 06:15:04,523 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting conv3_block3_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge and conv5_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge
2024-06-13 06:15:04,523 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'GlobalAveragePooling2D')
2024-06-13 06:15:05,553 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'GlobalAveragePooling2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge_2_2 and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge_2
2024-06-13 06:15:06,493 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'GlobalAveragePooling2D'] by Connecting pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge_2_2 and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge_2
2024-06-13 06:15:06,493 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'BatchNormalization')
2024-06-13 06:15:07,704 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'BatchNormalization'] by Connecting conv5_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge and conv3_block4_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge
2024-06-13 06:15:08,649 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'BatchNormalization'] by Connecting conv5_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge and conv3_block4_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_Edge
2024-06-13 06:15:08,800 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 155/2170
The Configuration Coverage is: 430/2049
The NDims Coverage Is: 64/117
The DType Coverage Is: 73/354
The Shape Coverage Is: 145/295
The Input Coverage Is: 282/766
2024-06-13 06:15:10,939 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:15:11,407 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:15:43,563 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:15:43,563 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/batchnorm.py", line 65, in forward
    return self.bnu.forward(X)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 179, in forward
    self.eps,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2283, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: running_mean should contain 6 elements not 3

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:15:45,969 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 34s
2024-06-13 06:15:45,969 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-MParam94-Edge73 crash on backend pytorch when predicting
2024-06-13 06:15:45,991 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:15:46,000 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-MParam94-Edge73
2024-06-13 06:15:46,000 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:15:46,000 logger.py[line:35] INFO after_prediction
2024-06-13 06:15:46,000 logger.py[line:35] INFO No representative seed generated: resnet50-LMerg2-MShape5-MDtype6-MParam94-Edge73, do not increase the reward
2024-06-13 06:15:46,156 logger.py[line:35] INFO INFO: Mutation progress 74/100
2024-06-13 06:15:46,156 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:15:46,156 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:15:46,156 logger.py[line:35] INFO Score for MDtype is: 0.7628205128205128
2024-06-13 06:15:46,156 logger.py[line:35] INFO Score for MParam is: 0.7575757575757576
2024-06-13 06:15:46,156 logger.py[line:35] INFO Score for Edge is: 0.7357142857142858
2024-06-13 06:15:46,156 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:15:46,156 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:15:46,156 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:15:46,156 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:15:46,156 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 06:15:46,157 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:15:46,157 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MDtype113-MDtype54-SpecialI59
2024-06-13 06:15:46,157 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:15:49,132 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:15:49,824 logger.py[line:35] INFO Generating model using MDtype
2024-06-13 06:15:49,828 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_MDtype')>}
2024-06-13 06:15:49,986 logger.py[line:35] INFO Change 1 Layer's DType Out Of 4 Layer classes
2024-06-13 06:15:49,986 logger.py[line:35] INFO Changing 1 out of 4 Layer's DType.
2024-06-13 06:15:49,987 logger.py[line:35] INFO Selecting a Global DType bfloat16 For Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_MDtype
2024-06-13 06:15:49,991 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MDtype_copy_SpecialI_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:15:50,020 deprecation.py[line:347] WARNING From /opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3686: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.linalg.matmul` instead
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 91, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_dtype(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 426, in mutate_dtype
    new_model = utils.ModelUtils.functional_model_operation(MDtype_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 416, in mdtype_mutation
    layer_input = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/recurrent.py", line 679, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
TypeError: Exception encountered when calling layer "lstm_cell_2" (type LSTMCell).

Input 'y' of 'Mul' Op has type bfloat16 that does not match type float32 of argument 'x'.

Call arguments received:
   inputs=tf.Tensor(shape=(None, 240), dtype=float32)
   states=('tf.Tensor(shape=(None, 25), dtype=bfloat16)', 'tf.Tensor(shape=(None, 25), dtype=bfloat16)')
   training=None
2024-06-13 06:15:50,461 logger.py[line:35] INFO INFO: Mutation progress 74/100
2024-06-13 06:15:50,461 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:15:50,461 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:15:50,461 logger.py[line:35] INFO Score for MDtype is: 0.7628205128205128
2024-06-13 06:15:50,461 logger.py[line:35] INFO Score for MParam is: 0.7575757575757576
2024-06-13 06:15:50,461 logger.py[line:35] INFO Score for Edge is: 0.7357142857142858
2024-06-13 06:15:50,461 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:15:50,461 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:15:50,461 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:15:50,461 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:15:50,461 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 06:15:50,462 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:15:50,462 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81
2024-06-13 06:15:50,462 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:15:57,928 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge')>}
Choosing 8 To Insert
2024-06-13 06:16:01,365 logger.py[line:35] INFO Insert 8 Local New Edges
2024-06-13 06:16:01,365 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'Conv2D')
2024-06-13 06:16:05,740 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'Conv2D'] by Connecting conv2d_166_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and conv2d_72_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:16:09,235 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'Conv2D'] by Connecting conv2d_166_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and conv2d_72_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:16:09,235 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'GlobalAveragePooling2D')
2024-06-13 06:16:13,503 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'GlobalAveragePooling2D'] by Connecting max_pooling2d_4_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:16:17,127 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'GlobalAveragePooling2D'] by Connecting max_pooling2d_4_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:16:17,127 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'BatchNormalization')
2024-06-13 06:16:21,677 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting batch_normalization_23_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and batch_normalization_182_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:16:25,192 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting batch_normalization_23_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and batch_normalization_182_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:16:25,192 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'GlobalAveragePooling2D')
2024-06-13 06:16:29,476 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'GlobalAveragePooling2D'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge_2
2024-06-13 06:16:33,106 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'GlobalAveragePooling2D'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge_2
2024-06-13 06:16:33,106 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'GlobalAveragePooling2D')
2024-06-13 06:16:37,694 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'GlobalAveragePooling2D'] by Connecting block17_6_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge_1
2024-06-13 06:16:41,003 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'GlobalAveragePooling2D'] by Connecting block17_6_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge_1
2024-06-13 06:16:41,003 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'BatchNormalization')
2024-06-13 06:16:45,542 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'BatchNormalization'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and batch_normalization_13_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:16:49,048 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'BatchNormalization'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and batch_normalization_13_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:16:49,048 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'BatchNormalization')
2024-06-13 06:16:53,625 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'BatchNormalization'] by Connecting max_pooling2d_2_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and batch_normalization_197_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:16:56,962 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'BatchNormalization'] by Connecting max_pooling2d_2_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and batch_normalization_197_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:16:56,962 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'MaxPooling2D')
2024-06-13 06:17:01,463 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'MaxPooling2D'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and max_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:17:05,144 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'MaxPooling2D'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge and max_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:17:05,499 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 155/2170
The Configuration Coverage is: 430/2049
The NDims Coverage Is: 64/117
The DType Coverage Is: 74/354
The Shape Coverage Is: 145/295
The Input Coverage Is: 283/766
2024-06-13 06:17:11,997 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:17:12,461 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
2024-06-13 06:18:17,228 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:18:17,228 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: expected scalar type Float but found Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:18:20,813 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 1m, 8s
2024-06-13 06:18:20,813 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81-Edge74 crash on backend pytorch when predicting
2024-06-13 06:18:20,835 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:18:20,903 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81-Edge74
2024-06-13 06:18:20,903 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:18:20,903 logger.py[line:35] INFO after_prediction
2024-06-13 06:18:21,086 logger.py[line:35] INFO INFO: Mutation progress 75/100
2024-06-13 06:18:21,086 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:18:21,086 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:18:21,087 logger.py[line:35] INFO Score for MDtype is: 0.7628205128205128
2024-06-13 06:18:21,087 logger.py[line:35] INFO Score for MParam is: 0.7575757575757576
2024-06-13 06:18:21,087 logger.py[line:35] INFO Score for Edge is: 0.7323943661971831
2024-06-13 06:18:21,087 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:18:21,087 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:18:21,087 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:18:21,087 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:18:21,087 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 06:18:21,087 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:18:21,087 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55
2024-06-13 06:18:21,087 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:18:24,044 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:18:24,748 logger.py[line:35] INFO Generating model using MDtype
2024-06-13 06:18:24,751 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype')>}
2024-06-13 06:18:24,925 logger.py[line:35] INFO Change 1 Layer's DType Out Of 4 Layer classes
2024-06-13 06:18:24,925 logger.py[line:35] INFO Changing 1 out of 4 Layer's DType.
2024-06-13 06:18:24,925 logger.py[line:35] INFO Selecting a Global DType float16 For Layer up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype
2024-06-13 06:18:24,928 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype')>}
2024-06-13 06:18:25,119 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:18:25,568 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 155/2170
The Configuration Coverage is: 430/2049
The NDims Coverage Is: 64/117
The DType Coverage Is: 74/354
The Shape Coverage Is: 145/295
The Input Coverage Is: 283/766
2024-06-13 06:18:25,767 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:18:26,232 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (47) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:18:34,058 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 7s
2024-06-13 06:18:34,059 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype75 crash on backend pytorch when predicting
2024-06-13 06:18:34,080 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:18:34,185 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype75
2024-06-13 06:18:34,186 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:18:34,186 logger.py[line:35] INFO after_prediction
2024-06-13 06:18:34,186 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype75, do not increase the reward
2024-06-13 06:18:34,304 logger.py[line:35] INFO INFO: Mutation progress 76/100
2024-06-13 06:18:34,304 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:18:34,304 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:18:34,304 logger.py[line:35] INFO Score for MParam is: 0.7575757575757576
2024-06-13 06:18:34,304 logger.py[line:35] INFO Score for MDtype is: 0.7531645569620253
2024-06-13 06:18:34,304 logger.py[line:35] INFO Score for Edge is: 0.7323943661971831
2024-06-13 06:18:34,304 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:18:34,304 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:18:34,304 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:18:34,304 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:18:34,304 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 06:18:34,305 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:18:34,305 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94
2024-06-13 06:18:34,305 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:18:38,675 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam')>}
2024-06-13 06:18:39,667 logger.py[line:35] INFO Changing 2/5 of layer conv5_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 06:18:39,667 logger.py[line:35] INFO changing config axis in layer conv5_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:18:39,667 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:18:39,667 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:18:39,667 logger.py[line:35] INFO changing config center in layer conv5_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to True
2024-06-13 06:18:39,667 logger.py[line:35] INFO changing config scale in layer conv5_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to True
2024-06-13 06:18:39,667 logger.py[line:35] INFO Changing 3/5 of layer conv4_block2_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 06:18:39,667 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:18:39,667 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:18:39,668 logger.py[line:35] INFO changing config center in layer conv4_block2_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to False
2024-06-13 06:18:39,668 logger.py[line:35] INFO changing config axis in layer conv4_block2_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:18:39,668 logger.py[line:35] INFO changing config scale in layer conv4_block2_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to False
2024-06-13 06:18:39,668 logger.py[line:35] INFO Changing 1/15 of layer conv4_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 06:18:39,668 logger.py[line:35] INFO changing config dilation_rate in layer conv4_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from (1, 1) to [2, 4]
2024-06-13 06:18:39,668 logger.py[line:35] INFO changing config kernel_regularizer in layer conv4_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from None to l1
2024-06-13 06:18:39,668 logger.py[line:35] INFO Changing 1/15 of layer conv2_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 06:18:39,668 logger.py[line:35] INFO changing config bias_constraint in layer conv2_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from None to Constraint
2024-06-13 06:18:39,668 logger.py[line:35] INFO changing config activity_regularizer in layer conv2_block1_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from None to l1
2024-06-13 06:18:39,668 logger.py[line:35] INFO Changing 1/15 of layer conv4_block1_0_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 06:18:39,668 logger.py[line:35] INFO changing config kernel_constraint in layer conv4_block1_0_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from None to MaxNorm
2024-06-13 06:18:39,669 logger.py[line:35] INFO changing config use_bias in layer conv4_block1_0_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to False
2024-06-13 06:18:39,669 logger.py[line:35] INFO Changing 3/15 of layer conv4_block3_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 06:18:39,669 logger.py[line:35] INFO changing config padding in layer conv4_block3_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from same to same
2024-06-13 06:18:39,669 logger.py[line:35] INFO changing config dilation_rate in layer conv4_block3_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from (1, 1) to [1, 4]
2024-06-13 06:18:39,669 logger.py[line:35] INFO changing config activation in layer conv4_block3_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from linear to softsign
2024-06-13 06:18:39,669 logger.py[line:35] INFO changing config strides in layer conv4_block3_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from (1, 1) to [3, 4]
2024-06-13 06:18:39,669 logger.py[line:35] INFO Changing 3/5 of layer conv4_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 06:18:39,669 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:18:39,669 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:18:39,670 logger.py[line:35] INFO changing config scale in layer conv4_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to True
2024-06-13 06:18:39,670 logger.py[line:35] INFO changing config axis in layer conv4_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:18:39,670 logger.py[line:35] INFO changing config center in layer conv4_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to False
2024-06-13 06:18:39,670 logger.py[line:35] INFO Changing 3/15 of layer conv4_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 06:18:39,670 logger.py[line:35] INFO changing config kernel_constraint in layer conv4_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from None to Constraint
2024-06-13 06:18:39,670 logger.py[line:35] INFO changing config padding in layer conv4_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from valid to valid
2024-06-13 06:18:39,670 logger.py[line:35] INFO changing config kernel_regularizer in layer conv4_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from None to l2
2024-06-13 06:18:39,670 logger.py[line:35] INFO changing config use_bias in layer conv4_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to True
2024-06-13 06:18:39,670 logger.py[line:35] INFO Changing 2/5 of layer conv4_block4_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam's configuration
2024-06-13 06:18:39,671 logger.py[line:35] INFO changing config scale in layer conv4_block4_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to True
2024-06-13 06:18:39,671 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:18:39,671 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:18:39,671 logger.py[line:35] INFO changing config axis in layer conv4_block4_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:18:39,671 logger.py[line:35] INFO changing config center in layer conv4_block4_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam: from True to True
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 276, in change_layer_config
    x = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py", line 997, in _get_strides_and_dilation_rate
    "`strides > 1` not supported in conjunction with `dilation_rate > 1`. "
ValueError: Exception encountered when calling layer "conv4_block3_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MParam" (type Conv2D).

`strides > 1` not supported in conjunction with `dilation_rate > 1`. Received: strides=[3 4] and dilation_rate=[1 4]

Call arguments received:
   inputs=tf.Tensor(shape=(None, 14, 14, 256), dtype=float32)
2024-06-13 06:18:40,777 logger.py[line:35] INFO INFO: Mutation progress 76/100
2024-06-13 06:18:40,777 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:18:40,777 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:18:40,777 logger.py[line:35] INFO Score for MParam is: 0.7575757575757576
2024-06-13 06:18:40,777 logger.py[line:35] INFO Score for MDtype is: 0.7531645569620253
2024-06-13 06:18:40,777 logger.py[line:35] INFO Score for Edge is: 0.7323943661971831
2024-06-13 06:18:40,777 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:18:40,777 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:18:40,777 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:18:40,777 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:18:40,777 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:18:40,777 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:18:40,777 logger.py[line:35] INFO Choose seed: lenet-LMerg90-NLAll105-NLAll116-Edge130-LMerg32
2024-06-13 06:18:40,777 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:18:44,425 logger.py[line:35] INFO Generating model using NLAll
model outputs {'dense_15_copy_LMerg_copy_NLAll_copy_NLAll_copy_Edge_copy_LMerg': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_15_copy_LMerg_copy_NLAll_copy_NLAll_copy_Edge_copy_LMerg_copy_NLAll')>, 'cropping1d_copy_LMerg': <KerasTensor: shape=(None, 10, 2) dtype=float32 (created by layer 'cropping1d_copy_LMerg_copy_NLAll')>, 'dot_copy_ML': <KerasTensor: shape=(None, 10, 10, 10, 10) dtype=float32 (created by layer 'dot_copy_ML_copy_NLAll')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_1_copy_LMerg': <KerasTensor: shape=(None, 14, 14, 6) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_1_copy_LMerg_copy_NLAll')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_2_copy_LMerg': <KerasTensor: shape=(None, 120) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_2_2_copy_LMerg_copy_NLAll')>, 'elu_insert_copy_Edge_1_2_1_copy_LMerg': <KerasTensor: shape=(None, 120) dtype=float32 (created by layer 'elu_insert_copy_Edge_1_2_1_copy_LMerg_copy_NLAll')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_1_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 16) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_1_copy_LMerg_copy_NLAll')>, 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_2_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 16) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll_copy_Edge_1_2_2_copy_LMerg_copy_NLAll')>, 'cropping1d_1_copy_LMerg': <KerasTensor: shape=(None, 10, 2) dtype=float32 (created by layer 'cropping1d_1_copy_LMerg_copy_NLAll')>}
2024-06-13 06:18:44,634 logger.py[line:35] INFO Insert 5 out of 10 Global New Layers
2024-06-13 06:18:44,634 logger.py[line:35] INFO insert UpSampling1D after cropping1d_copy_LMerg_copy_NLAll
2024-06-13 06:18:44,635 logger.py[line:35] INFO insert DepthwiseConv1D after dropout_5_copy_LMerg_merge1_copy_NLAll_copy_NLAll_copy_Edge_2_copy_LMerg_copy_NLAll
2024-06-13 06:18:44,635 logger.py[line:35] INFO insert Conv1D after elu_insert_copy_Edge_1_2_2_copy_LMerg_copy_NLAll
2024-06-13 06:18:44,635 logger.py[line:35] INFO insert GRU after cropping1d_1_copy_LMerg_copy_NLAll
2024-06-13 06:18:44,635 logger.py[line:35] INFO insert MaxPooling1D after elu_insert_copy_Edge_1_2_2_copy_LMerg_copy_NLAll
2024-06-13 06:18:44,635 logger.py[line:35] INFO Insert 1 out of 37 Local New Layers
2024-06-13 06:18:44,635 logger.py[line:35] INFO insert SpatialDropout2D after leaky_re_lu_insert_copy_NLAll_copy_Edge_1_1_copy_LMerg_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.core.spatial_dropout.SpatialDropout2D object at 0x7f6ef86e0cd0>
2024-06-13 06:18:44,685 logger.py[line:35] INFO Converting output shape (None, 5, 5, 16) to actual shape [None, 5, 5, 16]
[DEBUG] Inserting layer: <keras.layers.convolutional.DepthwiseConv1D object at 0x7f6f78c39bd0>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/initializers/initializers_v2.py", line 674, in __call__
    'Identity matrix initializer can only be used for 2D matrices. '
ValueError: Identity matrix initializer can only be used for 2D matrices. Received: shape=(1, 2, 1) of rank 3.
2024-06-13 06:18:45,164 logger.py[line:35] INFO INFO: Mutation progress 76/100
2024-06-13 06:18:45,164 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:18:45,165 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:18:45,165 logger.py[line:35] INFO Score for MParam is: 0.7575757575757576
2024-06-13 06:18:45,165 logger.py[line:35] INFO Score for MDtype is: 0.7531645569620253
2024-06-13 06:18:45,165 logger.py[line:35] INFO Score for Edge is: 0.7323943661971831
2024-06-13 06:18:45,165 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:18:45,165 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:18:45,165 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:18:45,165 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:18:45,165 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:18:45,165 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:18:45,165 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97
2024-06-13 06:18:45,165 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:18:48,169 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:18:48,182 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:18:49,028 logger.py[line:35] INFO Generating model using MParam
2024-06-13 06:18:49,031 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:18:49,258 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_copy_MParam')>, 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'cropping3d': <KerasTensor: shape=(None, 1, 11, 11, 2025) dtype=float32 (created by layer 'cropping3d_copy_MParam')>, 'lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 2, 25) dtype=float32 (created by layer 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_MParam')>}
2024-06-13 06:18:49,359 logger.py[line:35] INFO Changing 1/1 of layer up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_MParam's configuration
2024-06-13 06:18:49,359 logger.py[line:35] INFO changing config data_format in layer up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_MParam: from channels_first to channels_first
2024-06-13 06:18:49,359 logger.py[line:35] INFO Changing 1/1 of layer up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam's configuration
2024-06-13 06:18:49,360 logger.py[line:35] INFO changing config data_format in layer up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam: from channels_first to channels_first
2024-06-13 06:18:49,360 logger.py[line:35] INFO Changing 1/1 of layer cropping3d_copy_MParam's configuration
2024-06-13 06:18:49,360 logger.py[line:35] INFO changing config cropping in layer cropping3d_copy_MParam: from ((0, 0), (35, 35), (35, 35)) to [8, 9, 1]
2024-06-13 06:18:49,363 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:18:49,595 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_copy_MParam': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_copy_MParam')>, 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'cropping3d_copy_MParam': <KerasTensor: shape=(None, 0, 63, 79, 2025) dtype=float32 (created by layer 'cropping3d_copy_MParam')>, 'lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam': <KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam')>, 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_MParam': <KerasTensor: shape=(None, 2, 25) dtype=float32 (created by layer 'dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_MParam')>}
2024-06-13 06:18:49,740 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:18:50,237 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_1_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:18:50,250 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_Edge_2_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 155/2170
The Configuration Coverage is: 431/2049
The NDims Coverage Is: 64/117
The DType Coverage Is: 74/354
The Shape Coverage Is: 145/295
The Input Coverage Is: 283/766
2024-06-13 06:18:50,579 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:18:51,051 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:19:02,740 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:19:02,741 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 208, in forward
    outputs = op((self,), activations, *in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/loop.py", line 95, in forward
    while i < M and cond:
RuntimeError: t == DeviceType::CUDAINTERNAL ASSERT FAILED at "/root/dl_libraries/pytorch/c10/cuda/impl/CUDAGuardImpl.h":24, please report a bug to PyTorch. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:19:04,986 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 13s
2024-06-13 06:19:04,986 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97-MParam76 crash on backend pytorch when predicting
2024-06-13 06:19:05,014 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:19:05,108 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-Edge97-MParam76
2024-06-13 06:19:05,108 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:19:05,108 logger.py[line:35] INFO after_prediction
2024-06-13 06:19:05,236 logger.py[line:35] INFO INFO: Mutation progress 77/100
2024-06-13 06:19:05,236 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:19:05,236 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:19:05,236 logger.py[line:35] INFO Score for MDtype is: 0.7531645569620253
2024-06-13 06:19:05,236 logger.py[line:35] INFO Score for MParam is: 0.75
2024-06-13 06:19:05,236 logger.py[line:35] INFO Score for Edge is: 0.7323943661971831
2024-06-13 06:19:05,236 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:19:05,236 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:19:05,236 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:19:05,236 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:19:05,236 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:19:05,236 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:19:05,236 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-NLAll99-MDtype111-MDims14-SpecialI56
2024-06-13 06:19:05,236 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:19:09,848 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_NLAll')>}
2024-06-13 06:19:11,059 logger.py[line:35] INFO Insert 2 out of 2 Global New Layers
2024-06-13 06:19:11,059 logger.py[line:35] INFO insert MaxPooling3D after conv2_block1_0_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_NLAll
2024-06-13 06:19:11,059 logger.py[line:35] INFO insert Conv3D after conv2_block1_0_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_NLAll
2024-06-13 06:19:11,060 logger.py[line:35] INFO Insert 5 out of 31 Local New Layers
2024-06-13 06:19:11,060 logger.py[line:35] INFO insert SeparableConv2D after pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_NLAll
2024-06-13 06:19:11,060 logger.py[line:35] INFO insert ConvLSTM2D after conv2_block1_0_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_NLAll
2024-06-13 06:19:11,060 logger.py[line:35] INFO insert Cropping3D after conv2_block1_0_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_NLAll
2024-06-13 06:19:11,060 logger.py[line:35] INFO insert ConvLSTM1D after conv2_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_NLAll
2024-06-13 06:19:11,060 logger.py[line:35] INFO insert AveragePooling3D after conv2_block1_0_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_NLAll
2024-06-13 06:19:11,060 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 3
2024-06-13 06:19:11,064 logger.py[line:35] INFO insert Conv3DTranspose after custom_expand_layer_copy_SpecialI_copy_NLAll
2024-06-13 06:19:11,068 logger.py[line:35] INFO insert Permute after custom_expand_layer_copy_MDtype_copy_MDims_copy_SpecialI_copy_NLAll
2024-06-13 06:19:11,078 logger.py[line:35] INFO insert Softmax after conv5_block3_add_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.convolutional.SeparableConv2D object at 0x7f679c4d7290>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/initializers/initializers_v2.py", line 674, in __call__
    'Identity matrix initializer can only be used for 2D matrices. '
ValueError: Identity matrix initializer can only be used for 2D matrices. Received: shape=(1, 1, 64, 64) of rank 4.
2024-06-13 06:19:11,771 logger.py[line:35] INFO INFO: Mutation progress 77/100
2024-06-13 06:19:11,771 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:19:11,771 logger.py[line:35] INFO Score for NLAll is: 0.8292682926829268
2024-06-13 06:19:11,771 logger.py[line:35] INFO Score for MDtype is: 0.7531645569620253
2024-06-13 06:19:11,771 logger.py[line:35] INFO Score for MParam is: 0.75
2024-06-13 06:19:11,771 logger.py[line:35] INFO Score for Edge is: 0.7323943661971831
2024-06-13 06:19:11,771 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:19:11,771 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:19:11,771 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:19:11,771 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:19:11,771 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:19:11,771 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:19:11,771 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-NLAll94
2024-06-13 06:19:11,771 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:19:14,782 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:19:15,533 logger.py[line:35] INFO Generating model using NLAll
2024-06-13 06:19:15,536 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll')>}
2024-06-13 06:19:15,764 logger.py[line:35] INFO Insert 4 out of 13 Global New Layers
2024-06-13 06:19:15,764 logger.py[line:35] INFO insert Conv1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:19:15,764 logger.py[line:35] INFO insert ZeroPadding1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:19:15,764 logger.py[line:35] INFO insert GRU after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:19:15,764 logger.py[line:35] INFO insert Cropping1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:19:15,764 logger.py[line:35] INFO Insert 3 out of 21 Local New Layers
2024-06-13 06:19:15,764 logger.py[line:35] INFO insert SeparableConv1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:19:15,764 logger.py[line:35] INFO insert GaussianNoise after dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:19:15,765 logger.py[line:35] INFO insert RepeatVector after global_max_pooling1d_insert_copy_NLAll
2024-06-13 06:19:15,765 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 1
2024-06-13 06:19:15,765 logger.py[line:35] INFO insert Cropping3D after custom_expand_layer_2_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:19:15,768 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.convolutional.Cropping3D object at 0x7fc2403ddb90>
2024-06-13 06:19:15,872 logger.py[line:35] INFO Converting output shape (None, 1, 0, 0, 25) to actual shape [None, 1, 1, 1, 25]
[DEBUG] Inserting layer: <keras.layers.noise.GaussianNoise object at 0x7fc24039f0d0>
2024-06-13 06:19:15,917 logger.py[line:35] INFO Converting output shape (None, 1, 1, 1, 1, 25) to actual shape [None, 1, 1, 1, 1, 25]
[DEBUG] Inserting layer: <keras.layers.convolutional.SeparableConv1D object at 0x7fc240340e50>
2024-06-13 06:19:16,043 logger.py[line:35] INFO Converting output shape (None, 25, 25) to actual shape [None, 2, 25]
[DEBUG] Inserting layer: <keras.layers.core.repeat_vector.RepeatVector object at 0x7fc2a007c5d0>
2024-06-13 06:19:16,052 logger.py[line:35] INFO Converting output shape (None, 2, 25) to actual shape [None, 25]
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll')>}
2024-06-13 06:19:16,098 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:19:16,717 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 158/2170
The Configuration Coverage is: 442/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 76/354
The Shape Coverage Is: 146/295
The Input Coverage Is: 287/766
2024-06-13 06:19:16,954 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:19:17,420 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 58, in <module>
    transform_onnx(model_path)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 41, in transform_onnx
    model = keras.models.load_model(model_path, custom_objects=custom_objects())
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/save.py", line 201, in load_model
    compile)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/hdf5_format.py", line 181, in load_model_from_hdf5
    custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/model_config.py", line 52, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 678, in deserialize_keras_object
    list(custom_objects.items())))
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 663, in from_config
    config, custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1273, in reconstruct_from_config
    process_layer(layer_data)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1255, in process_layer
    layer = deserialize_layer(layer_data, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 681, in deserialize_keras_object
    deserialized_obj = cls.from_config(cls_config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 748, in from_config
    return cls(**config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/noise.py", line 56, in __init__
    super(GaussianNoise, self).__init__(**kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 323, in __init__
    generic_utils.validate_kwargs(kwargs, allowed_kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 1143, in validate_kwargs
    raise TypeError(error_message, kwarg)
TypeError: ('Keyword argument not understood:', 'seed')
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-NLAll94-NLAll77/lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-NLAll94-NLAll77.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:19:22,694 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 5s
2024-06-13 06:19:22,694 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-NLAll94-NLAll77 crash on backend pytorch when predicting
2024-06-13 06:19:22,715 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:19:22,773 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-NLAll94-NLAll77
2024-06-13 06:19:22,773 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:19:22,773 logger.py[line:35] INFO after_prediction
2024-06-13 06:19:22,896 logger.py[line:35] INFO INFO: Mutation progress 78/100
2024-06-13 06:19:22,896 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:19:22,896 logger.py[line:35] INFO Score for NLAll is: 0.8253012048192772
2024-06-13 06:19:22,896 logger.py[line:35] INFO Score for MDtype is: 0.7531645569620253
2024-06-13 06:19:22,896 logger.py[line:35] INFO Score for MParam is: 0.75
2024-06-13 06:19:22,896 logger.py[line:35] INFO Score for Edge is: 0.7323943661971831
2024-06-13 06:19:22,896 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:19:22,896 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:19:22,896 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:19:22,896 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:19:22,896 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:19:22,897 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:19:22,897 logger.py[line:35] INFO Choose seed: mobilenet.v2-MParam43
2024-06-13 06:19:22,897 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:19:27,020 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_NLAll')>}
2024-06-13 06:19:28,101 logger.py[line:35] INFO Insert 7 out of 29 Local New Layers
2024-06-13 06:19:28,101 logger.py[line:35] INFO insert ConvLSTM1D after block_2_depthwise_BN_copy_MParam_copy_NLAll
2024-06-13 06:19:28,102 logger.py[line:35] INFO insert ELU after block_13_expand_relu_copy_MParam_copy_NLAll
2024-06-13 06:19:28,102 logger.py[line:35] INFO insert LeakyReLU after block_11_depthwise_copy_MParam_copy_NLAll
2024-06-13 06:19:28,102 logger.py[line:35] INFO insert GaussianDropout after block_13_depthwise_relu_copy_MParam_copy_NLAll
2024-06-13 06:19:28,102 logger.py[line:35] INFO insert ZeroPadding2D after block_13_depthwise_relu_copy_MParam_copy_NLAll
2024-06-13 06:19:28,102 logger.py[line:35] INFO insert Dropout after block_6_pad_copy_MParam_copy_NLAll
2024-06-13 06:19:28,102 logger.py[line:35] INFO insert Conv2D after block_7_depthwise_copy_MParam_copy_NLAll
2024-06-13 06:19:28,102 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 1
2024-06-13 06:19:28,111 logger.py[line:35] INFO insert PReLU after block_16_expand_relu_copy_MParam_copy_NLAll
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 62, in new_layer_addition
    layer_list = selected_layer(output_shape)
  File "/root/implementations/scripts/generation/layer_pools.py", line 463, in conv_lstm_1d
    inserted_layer = ConfigurationUtils.random_config(candidate_layer)
  File "/root/implementations/scripts/generation/layer_pools.py", line 57, in random_config
    new_layer = layer.from_config(layer_config)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 970, in from_config
    return cls(**config)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 1134, in __init__
    **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 842, in __init__
    **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 141, in __init__
    'Unrolling is not possible with convolutional RNNs. '
TypeError: Unrolling is not possible with convolutional RNNs. Received: unroll=True
2024-06-13 06:19:28,701 logger.py[line:35] INFO INFO: Mutation progress 78/100
2024-06-13 06:19:28,701 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:19:28,701 logger.py[line:35] INFO Score for NLAll is: 0.8253012048192772
2024-06-13 06:19:28,701 logger.py[line:35] INFO Score for MDtype is: 0.7531645569620253
2024-06-13 06:19:28,701 logger.py[line:35] INFO Score for MParam is: 0.75
2024-06-13 06:19:28,701 logger.py[line:35] INFO Score for Edge is: 0.7323943661971831
2024-06-13 06:19:28,701 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:19:28,702 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:19:28,702 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:19:28,702 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:19:28,702 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:19:28,702 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:19:28,702 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-LMerg10-NLAll66
2024-06-13 06:19:28,702 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:19:32,915 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_LMerg_copy_LMerg_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_MDtype')>}
2024-06-13 06:19:33,874 logger.py[line:35] INFO Change 2 Layer's DType Out Of 6 Layer classes
2024-06-13 06:19:33,874 logger.py[line:35] INFO Changing 2 out of 6 Layer's DType.
2024-06-13 06:19:33,875 logger.py[line:35] INFO Selecting a Global DType float16 For Layer avg_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_MDtype
2024-06-13 06:19:33,875 logger.py[line:35] INFO Selecting a Global DType float64 For Layer pool1_pool_copy_LMerg_copy_LMerg_copy_NLAll_copy_MDtype
model outputs {'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_MDtype')>}
2024-06-13 06:19:34,846 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 158/2170
The Configuration Coverage is: 442/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 76/354
The Shape Coverage Is: 146/295
The Input Coverage Is: 287/766
2024-06-13 06:19:36,695 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:19:37,158 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (134) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:20:01,206 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 06:20:01,206 logger.py[line:35] INFO resnet50-LMerg2-LMerg10-NLAll66-MDtype78 crash on backend pytorch when predicting
2024-06-13 06:20:01,228 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:20:01,238 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-LMerg10-NLAll66-MDtype78
2024-06-13 06:20:01,238 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:20:01,238 logger.py[line:35] INFO after_prediction
2024-06-13 06:20:01,238 logger.py[line:35] INFO No representative seed generated: resnet50-LMerg2-LMerg10-NLAll66-MDtype78, do not increase the reward
2024-06-13 06:20:01,384 logger.py[line:35] INFO INFO: Mutation progress 79/100
2024-06-13 06:20:01,384 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:20:01,384 logger.py[line:35] INFO Score for NLAll is: 0.8253012048192772
2024-06-13 06:20:01,384 logger.py[line:35] INFO Score for MParam is: 0.75
2024-06-13 06:20:01,384 logger.py[line:35] INFO Score for MDtype is: 0.74375
2024-06-13 06:20:01,384 logger.py[line:35] INFO Score for Edge is: 0.7323943661971831
2024-06-13 06:20:01,384 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:20:01,384 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:20:01,384 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:20:01,384 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:20:01,384 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 06:20:01,385 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:20:01,385 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype58-Edge78
2024-06-13 06:20:01,385 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:20:05,652 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_Edge_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_Edge_copy_NLAll')>, 'avg_pool_copy_Edge_2_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_Edge_copy_NLAll')>, 'pool1_pool_copy_Edge_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 4, 4, 512) dtype=float32 (created by layer 'pool1_pool_copy_Edge_copy_MDtype_copy_Edge_2_copy_NLAll')>, 'pool1_pad_copy_Edge_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 12, 12, 512) dtype=float32 (created by layer 'pool1_pad_copy_Edge_copy_MDtype_copy_Edge_2_copy_NLAll')>}
2024-06-13 06:20:06,893 logger.py[line:35] INFO Insert 4 out of 28 Local New Layers
2024-06-13 06:20:06,894 logger.py[line:35] INFO insert Softmax after conv4_block3_1_bn_copy_Edge_copy_MDtype_copy_Edge_copy_NLAll
2024-06-13 06:20:06,894 logger.py[line:35] INFO insert GaussianDropout after conv3_block1_1_bn_copy_Edge_copy_MDtype_copy_Edge_copy_NLAll
2024-06-13 06:20:06,894 logger.py[line:35] INFO insert GlobalAveragePooling2D after cropping2d_copy_MDtype_copy_Edge_copy_NLAll
2024-06-13 06:20:06,894 logger.py[line:35] INFO insert LeakyReLU after conv2_block2_1_bn_copy_Edge_copy_MDtype_copy_Edge_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.advanced_activations.LeakyReLU object at 0x7f297015e0d0>
2024-06-13 06:20:06,999 logger.py[line:35] INFO Converting output shape (None, 56, 56, 64) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <keras.layers.noise.GaussianDropout object at 0x7f29700dcc50>
2024-06-13 06:20:07,098 logger.py[line:35] INFO Converting output shape (None, 28, 28, 128) to actual shape [None, 28, 28, 128]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.Softmax object at 0x7f297003ec90>
2024-06-13 06:20:07,416 logger.py[line:35] INFO Converting output shape (None, 14, 14, 256) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.pooling.GlobalAveragePooling2D object at 0x7f2920422f50>
2024-06-13 06:20:07,776 logger.py[line:35] INFO Converting output shape (None, 512) to actual shape [None, 10, 10, 512]
model outputs {'predictions_copy_Edge_copy_MDtype_copy_Edge_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_Edge_copy_NLAll')>, 'avg_pool_copy_Edge_2_copy_MDtype_copy_Edge_copy_NLAll': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_Edge_copy_NLAll')>, 'pool1_pool_copy_Edge_copy_MDtype_copy_Edge_2_copy_NLAll': <KerasTensor: shape=(None, 4, 4, 512) dtype=float32 (created by layer 'pool1_pool_copy_Edge_copy_MDtype_copy_Edge_2_copy_NLAll')>, 'pool1_pad_copy_Edge_copy_MDtype_copy_Edge_2_copy_NLAll': <KerasTensor: shape=(None, 12, 12, 512) dtype=float32 (created by layer 'pool1_pad_copy_Edge_copy_MDtype_copy_Edge_2_copy_NLAll')>}
2024-06-13 06:20:07,975 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 162/2170
The Configuration Coverage is: 442/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 76/354
The Shape Coverage Is: 148/295
The Input Coverage Is: 289/766
2024-06-13 06:20:09,929 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:20:10,397 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 58, in <module>
    transform_onnx(model_path)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 41, in transform_onnx
    model = keras.models.load_model(model_path, custom_objects=custom_objects())
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/save.py", line 201, in load_model
    compile)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/hdf5_format.py", line 181, in load_model_from_hdf5
    custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/model_config.py", line 52, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 678, in deserialize_keras_object
    list(custom_objects.items())))
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 663, in from_config
    config, custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1273, in reconstruct_from_config
    process_layer(layer_data)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1255, in process_layer
    layer = deserialize_layer(layer_data, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 681, in deserialize_keras_object
    deserialized_obj = cls.from_config(cls_config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 748, in from_config
    return cls(**config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/noise.py", line 107, in __init__
    super(GaussianDropout, self).__init__(**kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 323, in __init__
    generic_utils.validate_kwargs(kwargs, allowed_kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 1143, in validate_kwargs
    raise TypeError(error_message, kwarg)
TypeError: ('Keyword argument not understood:', 'seed')
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/resnet50-Edge65-MDtype58-Edge78-NLAll79/resnet50-Edge65-MDtype58-Edge78-NLAll79.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:20:15,821 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 5s
2024-06-13 06:20:15,821 logger.py[line:35] INFO resnet50-Edge65-MDtype58-Edge78-NLAll79 crash on backend pytorch when predicting
2024-06-13 06:20:15,843 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:20:15,945 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-Edge65-MDtype58-Edge78-NLAll79
2024-06-13 06:20:15,945 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:20:15,946 logger.py[line:35] INFO after_prediction
2024-06-13 06:20:16,092 logger.py[line:35] INFO INFO: Mutation progress 80/100
2024-06-13 06:20:16,092 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:20:16,092 logger.py[line:35] INFO Score for NLAll is: 0.8214285714285714
2024-06-13 06:20:16,092 logger.py[line:35] INFO Score for MParam is: 0.75
2024-06-13 06:20:16,092 logger.py[line:35] INFO Score for MDtype is: 0.74375
2024-06-13 06:20:16,092 logger.py[line:35] INFO Score for Edge is: 0.7323943661971831
2024-06-13 06:20:16,092 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:20:16,092 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:20:16,092 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:20:16,092 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:20:16,092 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:20:16,093 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:20:16,093 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25
2024-06-13 06:20:16,093 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:20:19,077 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:19,800 logger.py[line:35] INFO Generating model using MDtype
2024-06-13 06:20:19,803 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MDtype')>}
2024-06-13 06:20:20,013 logger.py[line:35] INFO Change 2 Layer's DType Out Of 8 Layer classes
2024-06-13 06:20:20,013 logger.py[line:35] INFO Changing 2 out of 8 Layer's DType.
2024-06-13 06:20:20,013 logger.py[line:35] INFO Selecting a Global DType half For Layer up_sampling3d_insert_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MDtype
2024-06-13 06:20:20,013 logger.py[line:35] INFO Selecting a Global DType float32 For Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MDtype
2024-06-13 06:20:20,016 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MDtype')>}
2024-06-13 06:20:20,279 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:20:20,765 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 162/2170
The Configuration Coverage is: 442/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 76/354
The Shape Coverage Is: 148/295
The Input Coverage Is: 289/766
2024-06-13 06:20:20,995 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:20:21,458 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 280, in convert_operations
    "Conversion not implemented for op_type={}.".format(node.op_type)
NotImplementedError: Conversion not implemented for op_type=ReduceSumSquare.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:20:29,486 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 8s
2024-06-13 06:20:29,487 logger.py[line:35] INFO lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-MDtype80 crash on backend pytorch when predicting
2024-06-13 06:20:29,508 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:20:29,517 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-MDtype80
2024-06-13 06:20:29,517 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:20:29,517 logger.py[line:35] INFO after_prediction
2024-06-13 06:20:29,517 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-MDtype80, do not increase the reward
2024-06-13 06:20:29,636 logger.py[line:35] INFO INFO: Mutation progress 81/100
2024-06-13 06:20:29,636 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:20:29,636 logger.py[line:35] INFO Score for NLAll is: 0.8214285714285714
2024-06-13 06:20:29,637 logger.py[line:35] INFO Score for MParam is: 0.75
2024-06-13 06:20:29,637 logger.py[line:35] INFO Score for MDtype is: 0.7345679012345679
2024-06-13 06:20:29,637 logger.py[line:35] INFO Score for Edge is: 0.7323943661971831
2024-06-13 06:20:29,637 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:20:29,637 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:20:29,637 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:20:29,637 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:20:29,637 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 06:20:29,637 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:20:29,637 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype64
2024-06-13 06:20:29,637 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:20:33,115 logger.py[line:35] INFO Generating model using NLAll
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_NLAll')>}
2024-06-13 06:20:33,253 logger.py[line:35] INFO Insert 5 out of 20 Local New Layers
2024-06-13 06:20:33,253 logger.py[line:35] INFO insert SeparableConv2D after max_pooling2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:20:33,253 logger.py[line:35] INFO insert DepthwiseConv2D after max_pooling2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:20:33,253 logger.py[line:35] INFO insert ActivityRegularization after flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:20:33,253 logger.py[line:35] INFO insert LocallyConnected2D after max_pooling2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:20:33,253 logger.py[line:35] INFO insert LayerNormalization after dropout_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_NLAll
2024-06-13 06:20:33,254 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 1
2024-06-13 06:20:33,254 logger.py[line:35] INFO Fail to find suitable insertion point for dimension: [3]
2024-06-13 06:20:33,254 logger.py[line:35] INFO insert Cropping1D after conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.local.LocallyConnected2D object at 0x7f58d047b550>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/local.py", line 499, in build
    f'One of the dimensions in the output is <= 0 '
ValueError: One of the dimensions in the output is <= 0 due to downsampling in locally_connected2d_insert. Consider increasing the input size. Received input shape (None, 8, 8, 96) which would produce output shape with a zero or negative value in a dimension.
2024-06-13 06:20:33,697 logger.py[line:35] INFO INFO: Mutation progress 81/100
2024-06-13 06:20:33,698 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:20:33,698 logger.py[line:35] INFO Score for NLAll is: 0.8214285714285714
2024-06-13 06:20:33,698 logger.py[line:35] INFO Score for MParam is: 0.75
2024-06-13 06:20:33,698 logger.py[line:35] INFO Score for MDtype is: 0.7345679012345679
2024-06-13 06:20:33,698 logger.py[line:35] INFO Score for Edge is: 0.7323943661971831
2024-06-13 06:20:33,698 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:20:33,698 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:20:33,698 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:20:33,698 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:20:33,698 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:20:33,698 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:20:33,698 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25
2024-06-13 06:20:33,698 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:20:36,687 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:37,409 logger.py[line:35] INFO Generating model using Edge
2024-06-13 06:20:37,412 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge')>}
Choosing 5 To Insert
2024-06-13 06:20:37,625 logger.py[line:35] INFO Insert 5 Global New Edges
2024-06-13 06:20:37,625 logger.py[line:35] INFO Candidate Edge: ('Conv3DTranspose', 'UpSampling3D')
2024-06-13 06:20:37,636 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:37,846 logger.py[line:35] INFO Trying Adding Edge: ['Conv3DTranspose', 'UpSampling3D'] by Connecting conv3d_transpose_insert_copy_Edge and up_sampling3d_insert_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 06:20:37,849 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:38,076 logger.py[line:35] INFO Successfully Add Edge: ['Conv3DTranspose', 'UpSampling3D'] by Connecting conv3d_transpose_insert_copy_Edge and up_sampling3d_insert_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 06:20:38,076 logger.py[line:35] INFO Candidate Edge: ('LayerNormalization', 'LSTM')
2024-06-13 06:20:38,087 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:38,406 logger.py[line:35] INFO Trying Adding Edge: ['LayerNormalization', 'LSTM'] by Connecting layer_normalization_insert_copy_Edge and lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 06:20:38,409 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:38,505 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:38,727 logger.py[line:35] INFO Successfully Add Edge: ['LayerNormalization', 'LSTM'] by Connecting layer_normalization_insert_copy_Edge and lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 06:20:38,728 logger.py[line:35] INFO Candidate Edge: ('GlobalAveragePooling3D', 'Dropout')
2024-06-13 06:20:38,739 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:38,753 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:39,059 logger.py[line:35] INFO Trying Adding Edge: ['GlobalAveragePooling3D', 'Dropout'] by Connecting global_average_pooling3d_insert_copy_Edge and dropout_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 06:20:39,063 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:39,291 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:39,386 logger.py[line:35] INFO Successfully Add Edge: ['GlobalAveragePooling3D', 'Dropout'] by Connecting global_average_pooling3d_insert_copy_Edge and dropout_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 06:20:39,386 logger.py[line:35] INFO Candidate Edge: ('Conv3DTranspose', 'Dropout')
2024-06-13 06:20:39,398 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:39,414 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:39,721 logger.py[line:35] INFO Trying Adding Edge: ['Conv3DTranspose', 'Dropout'] by Connecting conv3d_transpose_insert_copy_Edge and dropout_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_1
2024-06-13 06:20:39,723 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:39,948 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:40,050 logger.py[line:35] INFO Successfully Add Edge: ['Conv3DTranspose', 'Dropout'] by Connecting conv3d_transpose_insert_copy_Edge and dropout_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_1
2024-06-13 06:20:40,050 logger.py[line:35] INFO Candidate Edge: ('GlobalAveragePooling3D', 'RepeatVector')
2024-06-13 06:20:40,062 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:40,077 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:40,392 logger.py[line:35] INFO Trying Adding Edge: ['GlobalAveragePooling3D', 'RepeatVector'] by Connecting global_average_pooling3d_insert_copy_Edge and repeat_vector_insert_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 06:20:40,395 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:40,621 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:40,725 logger.py[line:35] INFO Successfully Add Edge: ['GlobalAveragePooling3D', 'RepeatVector'] by Connecting global_average_pooling3d_insert_copy_Edge and repeat_vector_insert_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge
2024-06-13 06:20:40,782 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:20:41,327 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:20:41,342 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_Edge_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 168/2170
The Configuration Coverage is: 443/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 76/354
The Shape Coverage Is: 148/295
The Input Coverage Is: 289/766
2024-06-13 06:20:41,675 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:20:42,136 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 280, in convert_operations
    "Conversion not implemented for op_type={}.".format(node.op_type)
NotImplementedError: Conversion not implemented for op_type=ReduceSumSquare.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:20:54,820 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 12s
2024-06-13 06:20:54,820 logger.py[line:35] INFO lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-Edge81 crash on backend pytorch when predicting
2024-06-13 06:20:54,841 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:20:54,901 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-Edge81
2024-06-13 06:20:54,902 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:20:54,902 logger.py[line:35] INFO after_prediction
2024-06-13 06:20:55,026 logger.py[line:35] INFO INFO: Mutation progress 82/100
2024-06-13 06:20:55,026 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:20:55,026 logger.py[line:35] INFO Score for NLAll is: 0.8214285714285714
2024-06-13 06:20:55,026 logger.py[line:35] INFO Score for MParam is: 0.75
2024-06-13 06:20:55,026 logger.py[line:35] INFO Score for MDtype is: 0.7345679012345679
2024-06-13 06:20:55,026 logger.py[line:35] INFO Score for Edge is: 0.7291666666666666
2024-06-13 06:20:55,026 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:20:55,026 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:20:55,026 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:20:55,026 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:20:55,026 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 06:20:55,026 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:20:55,026 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype132-SpecialI1-MShape20
2024-06-13 06:20:55,026 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:20:59,456 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll')>, 'custom_cast_layer_5_copy_SpecialI_copy_MShape': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'custom_cast_layer_5_copy_SpecialI_copy_MShape_copy_NLAll')>, 'custom_pad_layer_1': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'custom_pad_layer_1_copy_NLAll')>}
2024-06-13 06:21:00,859 logger.py[line:35] INFO Insert 6 out of 27 Local New Layers
2024-06-13 06:21:00,859 logger.py[line:35] INFO insert LocallyConnected2D after conv4_block3_3_bn_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll
2024-06-13 06:21:00,859 logger.py[line:35] INFO insert ThresholdedReLU after cropping2d_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll
2024-06-13 06:21:00,859 logger.py[line:35] INFO insert SpatialDropout2D after pool1_pool_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll
2024-06-13 06:21:00,859 logger.py[line:35] INFO insert ReLU after pool1_pool_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll
2024-06-13 06:21:00,860 logger.py[line:35] INFO insert TimeDistributed after pool1_pool_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll
2024-06-13 06:21:00,860 logger.py[line:35] INFO insert GaussianDropout after cropping2d_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll
2024-06-13 06:21:00,860 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 3
2024-06-13 06:21:00,863 logger.py[line:35] INFO Fail to find suitable insertion point for dimension: [5]
2024-06-13 06:21:00,864 logger.py[line:35] INFO insert ZeroPadding3D after conv2_block1_2_relu_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll
2024-06-13 06:21:00,874 logger.py[line:35] INFO insert Dropout after conv2_block1_1_conv_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll
2024-06-13 06:21:00,884 logger.py[line:35] INFO insert LayerNormalization after conv4_block6_2_relu_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.wrappers.TimeDistributed object at 0x7f8560134e10>
2024-06-13 06:21:00,926 logger.py[line:35] INFO Converting output shape (None, 56, 56, 64) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <keras.layers.core.dropout.Dropout object at 0x7f8560046110>
2024-06-13 06:21:00,935 logger.py[line:35] INFO Converting output shape (None, 56, 56, 64) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <scripts.generation.custom_layers.CustomExpandLayer object at 0x7f856005be90>
[DEBUG] Inserting layer: <keras.layers.convolutional.ZeroPadding3D object at 0x7f8560064a10>
2024-06-13 06:21:00,993 logger.py[line:35] INFO Converting output shape (None, 1, 64, 62, 70) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <keras.layers.local.LocallyConnected2D object at 0x7f8538436b10>
2024-06-13 06:21:01,829 logger.py[line:35] INFO Converting output shape (None, 10, 11, 10) to actual shape [None, 14, 14, 1024]
[DEBUG] Inserting layer: <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x7f8538264610>
2024-06-13 06:21:01,983 logger.py[line:35] INFO Converting output shape (None, 14, 14, 256) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.noise.GaussianDropout object at 0x7f8538182e10>
2024-06-13 06:21:02,185 logger.py[line:35] INFO Converting output shape (None, 10, 10, 512) to actual shape [None, 10, 10, 512]
model outputs {'predictions_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_SpecialI_copy_MShape_copy_NLAll')>, 'custom_cast_layer_5_copy_SpecialI_copy_MShape_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'custom_cast_layer_5_copy_SpecialI_copy_MShape_copy_NLAll')>, 'custom_pad_layer_1_copy_NLAll': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'custom_pad_layer_1_copy_NLAll')>}
2024-06-13 06:21:02,306 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 173/2170
The Configuration Coverage is: 452/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 76/354
The Shape Coverage Is: 153/295
The Input Coverage Is: 294/766
2024-06-13 06:21:04,954 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:21:05,426 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 58, in <module>
    transform_onnx(model_path)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 41, in transform_onnx
    model = keras.models.load_model(model_path, custom_objects=custom_objects())
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/save.py", line 201, in load_model
    compile)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/hdf5_format.py", line 181, in load_model_from_hdf5
    custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/model_config.py", line 52, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 678, in deserialize_keras_object
    list(custom_objects.items())))
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 663, in from_config
    config, custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1273, in reconstruct_from_config
    process_layer(layer_data)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1255, in process_layer
    layer = deserialize_layer(layer_data, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 681, in deserialize_keras_object
    deserialized_obj = cls.from_config(cls_config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 748, in from_config
    return cls(**config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/noise.py", line 107, in __init__
    super(GaussianDropout, self).__init__(**kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 323, in __init__
    generic_utils.validate_kwargs(kwargs, allowed_kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 1143, in validate_kwargs
    raise TypeError(error_message, kwarg)
TypeError: ('Keyword argument not understood:', 'seed')
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/resnet50-Edge65-MDtype132-SpecialI1-MShape20-NLAll82/resnet50-Edge65-MDtype132-SpecialI1-MShape20-NLAll82.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:21:11,000 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 5s
2024-06-13 06:21:11,000 logger.py[line:35] INFO resnet50-Edge65-MDtype132-SpecialI1-MShape20-NLAll82 crash on backend pytorch when predicting
2024-06-13 06:21:11,022 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:21:11,073 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-Edge65-MDtype132-SpecialI1-MShape20-NLAll82
2024-06-13 06:21:11,073 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:21:11,073 logger.py[line:35] INFO after_prediction
2024-06-13 06:21:11,249 logger.py[line:35] INFO INFO: Mutation progress 83/100
2024-06-13 06:21:11,250 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:21:11,250 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:21:11,250 logger.py[line:35] INFO Score for MParam is: 0.75
2024-06-13 06:21:11,250 logger.py[line:35] INFO Score for MDtype is: 0.7345679012345679
2024-06-13 06:21:11,250 logger.py[line:35] INFO Score for Edge is: 0.7291666666666666
2024-06-13 06:21:11,250 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:21:11,250 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:21:11,250 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:21:11,250 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:21:11,250 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:21:11,250 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:21:11,250 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype58
2024-06-13 06:21:11,250 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:21:15,552 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_Edge_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_MParam')>, 'cropping2d_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'cropping2d_copy_MDtype_copy_MParam')>, 'avg_pool_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_MParam')>}
2024-06-13 06:21:16,552 logger.py[line:35] INFO Changing 3/5 of layer conv2_block1_2_bn_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:21:16,552 logger.py[line:35] INFO changing config scale in layer conv2_block1_2_bn_copy_Edge_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:21:16,553 logger.py[line:35] INFO changing config center in layer conv2_block1_2_bn_copy_Edge_copy_MDtype_copy_MParam: from True to True
2024-06-13 06:21:16,553 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:21:16,553 logger.py[line:35] INFO changing config axis in layer conv2_block1_2_bn_copy_Edge_copy_MDtype_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:21:16,553 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:21:16,553 logger.py[line:35] INFO Changing 3/5 of layer conv3_block2_3_bn_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:21:16,553 logger.py[line:35] INFO changing config center in layer conv3_block2_3_bn_copy_Edge_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:21:16,553 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:21:16,553 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:21:16,553 logger.py[line:35] INFO changing config axis in layer conv3_block2_3_bn_copy_Edge_copy_MDtype_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:21:16,553 logger.py[line:35] INFO changing config scale in layer conv3_block2_3_bn_copy_Edge_copy_MDtype_copy_MParam: from True to True
2024-06-13 06:21:16,554 logger.py[line:35] INFO Changing 3/5 of layer conv3_block4_2_bn_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:21:16,554 logger.py[line:35] INFO changing config axis in layer conv3_block4_2_bn_copy_Edge_copy_MDtype_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:21:16,554 logger.py[line:35] INFO changing config center in layer conv3_block4_2_bn_copy_Edge_copy_MDtype_copy_MParam: from True to True
2024-06-13 06:21:16,554 logger.py[line:35] INFO changing config scale in layer conv3_block4_2_bn_copy_Edge_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:21:16,554 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:21:16,554 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:21:16,554 logger.py[line:35] INFO Changing 2/5 of layer conv4_block3_2_bn_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:21:16,554 logger.py[line:35] INFO changing config scale in layer conv4_block3_2_bn_copy_Edge_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:21:16,554 logger.py[line:35] INFO changing config axis in layer conv4_block3_2_bn_copy_Edge_copy_MDtype_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:21:16,555 logger.py[line:35] INFO changing config center in layer conv4_block3_2_bn_copy_Edge_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:21:16,555 logger.py[line:35] INFO Changing 3/5 of layer conv2_block3_1_bn_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:21:16,555 logger.py[line:35] INFO changing config axis in layer conv2_block3_1_bn_copy_Edge_copy_MDtype_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:21:16,555 logger.py[line:35] INFO changing config scale in layer conv2_block3_1_bn_copy_Edge_copy_MDtype_copy_MParam: from True to True
2024-06-13 06:21:16,555 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:21:16,555 logger.py[line:35] INFO changing config center in layer conv2_block3_1_bn_copy_Edge_copy_MDtype_copy_MParam: from True to True
2024-06-13 06:21:16,555 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:21:16,555 logger.py[line:35] INFO Changing 2/15 of layer conv3_block1_1_conv_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:21:16,555 logger.py[line:35] INFO changing config dilation_rate in layer conv3_block1_1_conv_copy_Edge_copy_MDtype_copy_MParam: from (1, 1) to [4, 3]
2024-06-13 06:21:16,555 logger.py[line:35] INFO changing config data_format in layer conv3_block1_1_conv_copy_Edge_copy_MDtype_copy_MParam: from channels_last to channels_first
2024-06-13 06:21:16,556 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:21:16,556 logger.py[line:35] INFO changing config bias_regularizer in layer conv3_block1_1_conv_copy_Edge_copy_MDtype_copy_MParam: from None to l2
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 276, in change_layer_config
    x = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py", line 997, in _get_strides_and_dilation_rate
    "`strides > 1` not supported in conjunction with `dilation_rate > 1`. "
ValueError: Exception encountered when calling layer "conv3_block1_1_conv_copy_Edge_copy_MDtype_copy_MParam" (type Conv2D).

`strides > 1` not supported in conjunction with `dilation_rate > 1`. Received: strides=[2 2] and dilation_rate=[4 3]

Call arguments received:
   inputs=tf.Tensor(shape=(None, 56, 56, 256), dtype=float32)
2024-06-13 06:21:17,447 logger.py[line:35] INFO INFO: Mutation progress 83/100
2024-06-13 06:21:17,447 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:21:17,447 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:21:17,447 logger.py[line:35] INFO Score for MParam is: 0.75
2024-06-13 06:21:17,447 logger.py[line:35] INFO Score for MDtype is: 0.7345679012345679
2024-06-13 06:21:17,447 logger.py[line:35] INFO Score for Edge is: 0.7291666666666666
2024-06-13 06:21:17,447 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:21:17,447 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:21:17,447 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:21:17,447 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:21:17,447 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:21:17,448 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:21:17,448 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-NLAll58
2024-06-13 06:21:17,448 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:21:20,454 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:21:21,153 logger.py[line:35] INFO Generating model using MParam
2024-06-13 06:21:21,156 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_MParam')>}
2024-06-13 06:21:21,307 logger.py[line:35] INFO Changing 3/21 of layer lstm_1_copy_NLAll_copy_NLAll_copy_MParam's configuration
2024-06-13 06:21:21,307 logger.py[line:35] INFO changing config recurrent_dropout in layer lstm_1_copy_NLAll_copy_NLAll_copy_MParam: from 0.0 to 0.18290896070926177
2024-06-13 06:21:21,307 logger.py[line:35] INFO changing config unroll in layer lstm_1_copy_NLAll_copy_NLAll_copy_MParam: from False to True
2024-06-13 06:21:21,307 logger.py[line:35] INFO changing config activation in layer lstm_1_copy_NLAll_copy_NLAll_copy_MParam: from tanh to None
2024-06-13 06:21:21,307 logger.py[line:35] INFO changing config recurrent_activation in layer lstm_1_copy_NLAll_copy_NLAll_copy_MParam: from hard_sigmoid to linear
2024-06-13 06:21:21,310 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:21:21,313 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_NLAll_copy_MParam': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_MParam')>}
2024-06-13 06:21:21,422 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:21:21,858 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 173/2170
The Configuration Coverage is: 455/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 76/354
The Shape Coverage Is: 153/295
The Input Coverage Is: 294/766
2024-06-13 06:21:21,979 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:21:22,449 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (46) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:21:28,973 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 6s
2024-06-13 06:21:28,974 logger.py[line:35] INFO lstm2-NLAll38-NLAll58-MParam83 crash on backend pytorch when predicting
2024-06-13 06:21:28,995 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:21:29,099 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-NLAll58-MParam83
2024-06-13 06:21:29,099 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:21:29,099 logger.py[line:35] INFO after_prediction
2024-06-13 06:21:29,220 logger.py[line:35] INFO INFO: Mutation progress 84/100
2024-06-13 06:21:29,221 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:21:29,221 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:21:29,221 logger.py[line:35] INFO Score for MParam is: 0.7428571428571429
2024-06-13 06:21:29,221 logger.py[line:35] INFO Score for MDtype is: 0.7345679012345679
2024-06-13 06:21:29,221 logger.py[line:35] INFO Score for Edge is: 0.7291666666666666
2024-06-13 06:21:29,221 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:21:29,221 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:21:29,221 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:21:29,221 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:21:29,221 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:21:29,221 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:21:29,221 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype58
2024-06-13 06:21:29,221 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:21:33,500 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_Edge_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_MParam')>, 'cropping2d_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'cropping2d_copy_MDtype_copy_MParam')>, 'avg_pool_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_MParam')>}
2024-06-13 06:21:34,489 logger.py[line:35] INFO Changing 3/5 of layer conv4_block5_3_bn_copy_Edge_copy_MDtype_copy_MParam's configuration
2024-06-13 06:21:34,489 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:21:34,489 logger.py[line:35] INFO changing config scale in layer conv4_block5_3_bn_copy_Edge_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:21:34,489 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:21:34,489 logger.py[line:35] INFO changing config axis in layer conv4_block5_3_bn_copy_Edge_copy_MDtype_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:21:34,489 logger.py[line:35] INFO changing config center in layer conv4_block5_3_bn_copy_Edge_copy_MDtype_copy_MParam: from True to False
model outputs {'predictions_copy_Edge_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_MParam')>, 'cropping2d_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'cropping2d_copy_MDtype_copy_MParam')>, 'avg_pool_copy_Edge_2_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_MParam')>}
2024-06-13 06:21:35,473 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 173/2170
The Configuration Coverage is: 455/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 76/354
The Shape Coverage Is: 153/295
The Input Coverage Is: 294/766
2024-06-13 06:21:37,391 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:21:37,854 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,1,256,1024) (1,1,14,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,1,256,1024) (1,1,14,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,1,256,1024) (1,1,14,1) 
2024-06-13 06:22:04,843 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:22:04,844 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [512, 64, 1, 1], expected input[101, 65, 56, 56] to have 64 channels, but got 65 channels instead

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:22:08,161 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 30s
2024-06-13 06:22:08,161 logger.py[line:35] INFO resnet50-Edge65-MDtype58-MParam84 crash on backend pytorch when predicting
2024-06-13 06:22:08,182 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:22:08,243 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-Edge65-MDtype58-MParam84
2024-06-13 06:22:08,243 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:22:08,243 logger.py[line:35] INFO after_prediction
2024-06-13 06:22:08,410 logger.py[line:35] INFO INFO: Mutation progress 85/100
2024-06-13 06:22:08,410 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:22:08,410 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:22:08,410 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:22:08,410 logger.py[line:35] INFO Score for MDtype is: 0.7345679012345679
2024-06-13 06:22:08,410 logger.py[line:35] INFO Score for Edge is: 0.7291666666666666
2024-06-13 06:22:08,410 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:22:08,410 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:22:08,410 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:22:08,410 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:22:08,410 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:22:08,411 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:22:08,411 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-MDtype67-MDtype82-NLAll93
2024-06-13 06:22:08,411 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:22:22,282 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'leaky_re_lu_insert': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'leaky_re_lu_insert_copy_NLAll')>, 'custom_pad_layer_2': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'custom_pad_layer_2_copy_NLAll')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'spatial_dropout2d_insert': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'spatial_dropout2d_insert_copy_NLAll')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll')>}
2024-06-13 06:22:32,557 logger.py[line:35] INFO Insert 6 out of 30 Local New Layers
2024-06-13 06:22:32,557 logger.py[line:35] INFO insert SeparableConv2D after depthwise_conv2d_insert_copy_NLAll
2024-06-13 06:22:32,557 logger.py[line:35] INFO insert Softmax after cropping2d_4_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:22:32,557 logger.py[line:35] INFO insert GaussianDropout after pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_2_1_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:22:32,557 logger.py[line:35] INFO insert LocallyConnected2D after depthwise_conv2d_insert_copy_NLAll
2024-06-13 06:22:32,557 logger.py[line:35] INFO insert LeakyReLU after cropping2d_2_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:22:32,557 logger.py[line:35] INFO insert PReLU after conv2_block1_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:22:32,558 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 1
2024-06-13 06:22:32,562 logger.py[line:35] INFO insert MaxPooling3D after custom_expand_layer_insert_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.advanced_activations.PReLU object at 0x7f3c8c057dd0>
2024-06-13 06:22:32,618 logger.py[line:35] INFO Converting output shape (None, 56, 56, 64) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <keras.layers.local.LocallyConnected2D object at 0x7f3c74782e10>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/initializers/initializers_v2.py", line 674, in __call__
    'Identity matrix initializer can only be used for 2D matrices. '
ValueError: Identity matrix initializer can only be used for 2D matrices. Received: shape=(2970, 1536, 10) of rank 3.
2024-06-13 06:22:34,044 logger.py[line:35] INFO INFO: Mutation progress 85/100
2024-06-13 06:22:34,045 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:22:34,045 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:22:34,045 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:22:34,045 logger.py[line:35] INFO Score for MDtype is: 0.7345679012345679
2024-06-13 06:22:34,045 logger.py[line:35] INFO Score for Edge is: 0.7291666666666666
2024-06-13 06:22:34,045 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:22:34,045 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:22:34,045 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:22:34,045 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:22:34,045 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:22:34,045 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:22:34,045 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4
2024-06-13 06:22:34,045 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:22:41,544 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype')>}
2024-06-13 06:22:45,029 logger.py[line:35] INFO Change 2 Layer's DType Out Of 5 Layer classes
2024-06-13 06:22:45,030 logger.py[line:35] INFO Changing 2 out of 5 Layer's DType.
2024-06-13 06:22:45,032 logger.py[line:35] INFO Selecting a Global DType bfloat16 For Layer max_pooling2d_3_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype
2024-06-13 06:22:45,034 logger.py[line:35] INFO Selecting a Global DType bfloat16 For Layer avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MDtype')>}
2024-06-13 06:22:48,894 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 173/2170
The Configuration Coverage is: 455/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 77/354
The Shape Coverage Is: 153/295
The Input Coverage Is: 295/766
2024-06-13 06:22:55,268 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:22:55,735 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (1042) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:23:54,875 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 59s
2024-06-13 06:23:54,876 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MDtype85 crash on backend pytorch when predicting
2024-06-13 06:23:54,897 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:23:54,956 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MDtype85
2024-06-13 06:23:54,956 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:23:54,956 logger.py[line:35] INFO after_prediction
2024-06-13 06:23:55,149 logger.py[line:35] INFO INFO: Mutation progress 86/100
2024-06-13 06:23:55,149 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:23:55,149 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:23:55,149 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:23:55,149 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:23:55,149 logger.py[line:35] INFO Score for Edge is: 0.7291666666666666
2024-06-13 06:23:55,149 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:23:55,149 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:23:55,149 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:23:55,149 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:23:55,149 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 06:23:55,149 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:23:55,150 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84
2024-06-13 06:23:55,150 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:23:58,128 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:23:58,854 logger.py[line:35] INFO Generating model using NLAll
2024-06-13 06:23:58,857 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_NLAll')>}
2024-06-13 06:23:59,113 logger.py[line:35] INFO Insert 2 out of 12 Global New Layers
2024-06-13 06:23:59,113 logger.py[line:35] INFO insert GlobalAveragePooling1D after layer_normalization_insert_copy_LMerg_copy_NLAll
2024-06-13 06:23:59,113 logger.py[line:35] INFO insert MaxPooling3D after dropout_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_NLAll
2024-06-13 06:23:59,116 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.pooling.MaxPooling3D object at 0x7f86807a5490>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1939, in _create_c_op
    raise ValueError(e.message)
ValueError: Exception encountered when calling layer "max_pooling3d_insert" (type MaxPooling3D).

Negative dimension size caused by subtracting 9 from 1 for '{{node max_pooling3d_insert/MaxPool3D}} = MaxPool3D[T=DT_FLOAT, data_format="NDHWC", ksize=[1, 9, 8, 6, 1], padding="VALID", strides=[1, 1, 1, 1, 1]](Placeholder)' with input shapes: [?,1,1,1,0].

Call arguments received:
   inputs=tf.Tensor(shape=(None, 1, 1, 1, 0), dtype=float32)
2024-06-13 06:23:59,732 logger.py[line:35] INFO INFO: Mutation progress 86/100
2024-06-13 06:23:59,732 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:23:59,732 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:23:59,732 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:23:59,732 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:23:59,732 logger.py[line:35] INFO Score for Edge is: 0.7291666666666666
2024-06-13 06:23:59,732 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:23:59,732 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:23:59,732 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:23:59,732 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:23:59,732 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:23:59,733 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:23:59,733 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype64-Edge69-LMerg85
2024-06-13 06:23:59,733 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:24:03,257 logger.py[line:35] INFO Generating model using NLAll
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_LMerg': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_LMerg_copy_NLAll')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_LMerg': <KerasTensor: shape=(None, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_LMerg_copy_NLAll')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_copy_LMerg': <KerasTensor: shape=(None, 8, 8, 256) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_copy_LMerg_copy_NLAll')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_LMerg': <KerasTensor: shape=(None, 16384) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_1_copy_LMerg_copy_NLAll')>, 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_LMerg': <KerasTensor: shape=(None, 1, 1, 256) dtype=float32 (created by layer 'conv2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_LMerg_copy_NLAll')>, 'minimum_copy_ML': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'minimum_copy_ML_copy_NLAll')>, 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_LMerg': <KerasTensor: shape=(None, 8, 8, 96) dtype=bfloat16 (created by layer 'dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_LMerg_copy_NLAll')>, 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_LMerg': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'batch_normalization_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_LMerg_copy_NLAll')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1_copy_LMerg': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_1_copy_LMerg_copy_NLAll')>, 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2_copy_LMerg': <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_2_2_copy_LMerg_copy_NLAll')>, 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_LMerg': <KerasTensor: shape=(None, 3, 3, 256) dtype=float64 (created by layer 'conv2d_5_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_2_copy_LMerg_copy_NLAll')>}
2024-06-13 06:24:03,452 logger.py[line:35] INFO Insert 6 out of 28 Local New Layers
2024-06-13 06:24:03,453 logger.py[line:35] INFO insert TimeDistributed after dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_LMerg_copy_NLAll
2024-06-13 06:24:03,453 logger.py[line:35] INFO insert ZeroPadding2D after dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_LMerg_copy_NLAll
2024-06-13 06:24:03,453 logger.py[line:35] INFO insert GaussianDropout after dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_2_copy_LMerg_copy_NLAll
2024-06-13 06:24:03,453 logger.py[line:35] INFO insert SeparableConv2D after max_pooling2d_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_LMerg_copy_NLAll
2024-06-13 06:24:03,453 logger.py[line:35] INFO insert Conv2DTranspose after max_pooling2d_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_LMerg_copy_NLAll
2024-06-13 06:24:03,453 logger.py[line:35] INFO insert ReLU after dropout_2_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_1_1_copy_LMerg_copy_NLAll
2024-06-13 06:24:03,453 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 2
2024-06-13 06:24:03,454 logger.py[line:35] INFO insert MaxPooling3D after custom_expand_layer_copy_MDtype_copy_Edge_copy_LMerg_copy_NLAll
2024-06-13 06:24:03,455 logger.py[line:35] INFO Fail to find suitable insertion point for dimension: [3]
2024-06-13 06:24:03,455 logger.py[line:35] INFO insert UpSampling1D after batch_normalization_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_Edge_copy_LMerg_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.convolutional.Conv2DTranspose object at 0x7f5dc2d55090>
2024-06-13 06:24:03,483 logger.py[line:35] INFO Converting output shape (None, 9, 14, 96) to actual shape [None, 8, 8, 96]
[DEBUG] Inserting layer: <keras.layers.convolutional.SeparableConv2D object at 0x7f5db00b1110>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/initializers/initializers_v2.py", line 674, in __call__
    'Identity matrix initializer can only be used for 2D matrices. '
ValueError: Identity matrix initializer can only be used for 2D matrices. Received: shape=(8, 7, 3, 1) of rank 4.
2024-06-13 06:24:04,004 logger.py[line:35] INFO INFO: Mutation progress 86/100
2024-06-13 06:24:04,005 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:24:04,005 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:24:04,005 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:24:04,005 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:24:04,005 logger.py[line:35] INFO Score for Edge is: 0.7291666666666666
2024-06-13 06:24:04,005 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:24:04,005 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:24:04,005 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:24:04,005 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:24:04,005 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:24:04,005 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:24:04,005 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MDtype4-NLAll12-NLAll32-NLAll93-NLAll-1
2024-06-13 06:24:04,005 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:24:08,749 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll')>}
2024-06-13 06:24:10,141 logger.py[line:35] INFO Insert 9 out of 10 Global New Layers
2024-06-13 06:24:10,141 logger.py[line:35] INFO insert GRU after repeat_vector_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,142 logger.py[line:35] INFO insert ZeroPadding1D after conv1d_insert_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,142 logger.py[line:35] INFO insert UpSampling1D after simple_rnn_insert_copy_NLAll_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,142 logger.py[line:35] INFO insert LocallyConnected1D after repeat_vector_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,142 logger.py[line:35] INFO insert Conv1D after conv1d_insert_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,142 logger.py[line:35] INFO insert Cropping1D after separable_conv1d_insert_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,142 logger.py[line:35] INFO insert MaxPooling1D after simple_rnn_insert_copy_NLAll_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,142 logger.py[line:35] INFO insert DepthwiseConv1D after conv1d_insert_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,142 logger.py[line:35] INFO insert GlobalAveragePooling1D after separable_conv1d_insert_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,142 logger.py[line:35] INFO Insert 5 out of 37 Local New Layers
2024-06-13 06:24:10,142 logger.py[line:35] INFO insert ActivityRegularization after zero_padding2d_insert_copy_NLAll
2024-06-13 06:24:10,142 logger.py[line:35] INFO insert Flatten after softmax_insert_copy_NLAll
2024-06-13 06:24:10,142 logger.py[line:35] INFO insert SpatialDropout1D after separable_conv1d_insert_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,143 logger.py[line:35] INFO insert Cropping2D after activity_regularization_insert_copy_NLAll_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,143 logger.py[line:35] INFO insert Bidirectional after simple_rnn_insert_copy_NLAll_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,143 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 2
2024-06-13 06:24:10,147 logger.py[line:35] INFO Fail to find suitable insertion point for dimension: [5]
2024-06-13 06:24:10,147 logger.py[line:35] INFO insert AveragePooling3D after conv3_block1_2_conv_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll
2024-06-13 06:24:10,151 logger.py[line:35] INFO Fail to find suitable insertion point for dimension: [5]
2024-06-13 06:24:10,152 logger.py[line:35] INFO insert ZeroPadding3D after conv5_block3_3_bn_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.convolutional.Cropping2D object at 0x7f8a5032d490>
2024-06-13 06:24:10,334 logger.py[line:35] INFO Converting output shape (None, 56, 54, 62) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <scripts.generation.custom_layers.CustomExpandLayer object at 0x7f8a502f0490>
[DEBUG] Inserting layer: <keras.layers.pooling.AveragePooling3D object at 0x7f8a502c7510>
2024-06-13 06:24:10,422 logger.py[line:35] INFO Converting output shape (None, 1, 23, 27, 123) to actual shape [None, 28, 28, 128]
[DEBUG] Inserting layer: <keras.layers.core.flatten.Flatten object at 0x7f8a501fe590>
2024-06-13 06:24:10,779 logger.py[line:35] INFO Converting output shape (None, 50176) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.core.activity_regularization.ActivityRegularization object at 0x7f8a50048f10>
2024-06-13 06:24:11,146 logger.py[line:35] INFO Converting output shape (None, 7, 13, 2052) to actual shape [None, 7, 13, 2052]
[DEBUG] Inserting layer: <scripts.generation.custom_layers.CustomExpandLayer object at 0x7f8a500543d0>
[DEBUG] Inserting layer: <keras.layers.convolutional.ZeroPadding3D object at 0x7f8a5005b8d0>
2024-06-13 06:24:11,163 logger.py[line:35] INFO Converting output shape (None, 1, 15, 13, 2056) to actual shape [None, 7, 7, 2048]
[DEBUG] Inserting layer: <keras.layers.local.LocallyConnected1D object at 0x7f8a50075bd0>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/local.py", line 178, in build
    f'One of the dimensions in the output is <= 0 '
ValueError: One of the dimensions in the output is <= 0 due to downsampling in locally_connected1d_insert. Consider increasing the input size. Received input shape (None, 2, 2048) which would produce output shape with a zero or negative value in a dimension.
2024-06-13 06:24:11,916 logger.py[line:35] INFO INFO: Mutation progress 86/100
2024-06-13 06:24:11,917 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:24:11,917 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:24:11,917 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:24:11,917 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:24:11,917 logger.py[line:35] INFO Score for Edge is: 0.7291666666666666
2024-06-13 06:24:11,917 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:24:11,917 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:24:11,917 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:24:11,917 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:24:11,917 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:24:11,917 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:24:11,917 logger.py[line:35] INFO Choose seed: alexnet
2024-06-13 06:24:11,917 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:24:15,356 logger.py[line:35] INFO Generating model using Edge
model outputs {'dense_3': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_Edge')>}
Choosing 3 To Insert
2024-06-13 06:24:15,445 logger.py[line:35] INFO Insert 3 Local New Edges
2024-06-13 06:24:15,445 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'BatchNormalization')
2024-06-13 06:24:15,537 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting batch_normalization_3_copy_Edge and batch_normalization_2_copy_Edge
2024-06-13 06:24:15,630 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting batch_normalization_3_copy_Edge and batch_normalization_2_copy_Edge
2024-06-13 06:24:15,630 logger.py[line:35] INFO Candidate Edge: ('MaxPooling2D', 'BatchNormalization')
2024-06-13 06:24:15,731 logger.py[line:35] INFO Trying Adding Edge: ['MaxPooling2D', 'BatchNormalization'] by Connecting max_pooling2d_1_copy_Edge and batch_normalization_3_copy_Edge
2024-06-13 06:24:15,831 logger.py[line:35] INFO Successfully Add Edge: ['MaxPooling2D', 'BatchNormalization'] by Connecting max_pooling2d_1_copy_Edge and batch_normalization_3_copy_Edge
2024-06-13 06:24:15,831 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'Flatten')
2024-06-13 06:24:15,939 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'Flatten'] by Connecting conv2d_4_copy_Edge and flatten_1_copy_Edge
2024-06-13 06:24:16,042 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'Flatten'] by Connecting conv2d_4_copy_Edge and flatten_1_copy_Edge
2024-06-13 06:24:16,084 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 173/2170
The Configuration Coverage is: 455/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 77/354
The Shape Coverage Is: 153/295
The Input Coverage Is: 295/766
2024-06-13 06:24:16,884 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:24:17,349 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:24:38,160 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:24:38,160 logger.py[line:35] INFO Now pytorch is using: cuda
2024-06-13 06:24:40,802 logger.py[line:35] INFO SUCCESS:Get prediction for alexnet-Edge86 successfully on pytorch!
2024-06-13 06:24:41,446 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 06:24:41,446 logger.py[line:35] INFO loading the redis
2024-06-13 06:24:41,449 logger.py[line:35] INFO finish loading from redis
2024-06-13 06:24:41,470 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:24:41,525 logger.py[line:35] INFO Success on backend: pytorch of model alexnet-Edge86
2024-06-13 06:24:41,525 logger.py[line:35] INFO Traceback (most recent call last):
  File "/root/implementations/scripts/generation/run.py", line 562, in gen
    model_name=new_model_name)
  File "/root/implementations/scripts/generation/run.py", line 432, in analyze_inference_result
    if (len(predict_output) >= 2 or len(predict_output) == len(self.backends)) and status["tensorflow"] == 0:
KeyError: 'tensorflow'

2024-06-13 06:24:41,551 logger.py[line:35] INFO INFO: Mutation progress 86/100
2024-06-13 06:24:41,551 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:24:41,551 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:24:41,551 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:24:41,551 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:24:41,551 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:24:41,551 logger.py[line:35] INFO Score for Edge is: 0.7191780821917808
2024-06-13 06:24:41,551 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:24:41,551 logger.py[line:35] INFO Score for SpecialI is: 0.575
2024-06-13 06:24:41,551 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:24:41,551 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 06:24:41,552 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:24:41,552 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7
2024-06-13 06:24:41,552 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:24:45,979 logger.py[line:35] INFO Generating model using SpecialI
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_SpecialI')>, 'cropping2d': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_SpecialI')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_SpecialI')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2_copy_SpecialI')>, 'cropping2d_1': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI')>, 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 20, 20, 256) dtype=float32 (created by layer 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_SpecialI')>, 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_SpecialI')>, 'cropping2d_2': <KerasTensor: shape=(None, 11, 11, 64) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI')>}
2024-06-13 06:24:46,990 logger.py[line:35] INFO Change Input Of Layer: conv4_block2_2_relu_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_SpecialI To: 0.0
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_SpecialI': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_SpecialI')>, 'cropping2d_copy_SpecialI': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_SpecialI': <KerasTensor: shape=(None, 3) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_SpecialI')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_SpecialI': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_SpecialI')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2_copy_SpecialI': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2_copy_SpecialI')>, 'cropping2d_1_copy_SpecialI': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI')>, 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_SpecialI': <KerasTensor: shape=(None, 20, 20, 256) dtype=float32 (created by layer 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_SpecialI')>, 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_SpecialI': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_SpecialI')>, 'cropping2d_2_copy_SpecialI': <KerasTensor: shape=(None, 11, 11, 64) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI')>}
2024-06-13 06:24:48,054 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 173/2170
The Configuration Coverage is: 455/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 77/354
The Shape Coverage Is: 153/295
The Input Coverage Is: 295/766
2024-06-13 06:24:50,247 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:24:50,704 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:25:25,352 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:25:25,353 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/operations/batchnorm.py", line 65, in forward
    return self.bnu.forward(X)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 179, in forward
    self.eps,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2283, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: running_mean should contain 6 elements not 3

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:25:27,766 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 37s
2024-06-13 06:25:27,766 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7-SpecialI86 crash on backend pytorch when predicting
2024-06-13 06:25:27,787 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:25:27,806 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7-SpecialI86
2024-06-13 06:25:27,806 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:25:27,806 logger.py[line:35] INFO after_prediction
2024-06-13 06:25:27,806 logger.py[line:35] INFO No representative seed generated: resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7-SpecialI86, do not increase the reward
2024-06-13 06:25:27,961 logger.py[line:35] INFO INFO: Mutation progress 87/100
2024-06-13 06:25:27,961 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:25:27,961 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:25:27,961 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:25:27,961 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:25:27,961 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:25:27,961 logger.py[line:35] INFO Score for Edge is: 0.7191780821917808
2024-06-13 06:25:27,961 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:25:27,962 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:25:27,962 logger.py[line:35] INFO Score for SpecialI is: 0.5476190476190477
2024-06-13 06:25:27,962 logger.py[line:35] INFO The last used seed is: SpecialI
2024-06-13 06:25:27,962 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:25:27,962 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-NLAll95
2024-06-13 06:25:27,962 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:25:30,957 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:25:32,067 logger.py[line:35] INFO Generating model using LMerg
2024-06-13 06:25:32,070 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_NLAll_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 06:25:32,716 logger.py[line:35] INFO Insert 2 out of 8 Local New Layer
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 72, in generate_model_by_model_mutation
    return InteractionMutationUtils.merge_layers(model=model, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 165, in merge_layers
    assert len(selected_layer_name_list) == 1
AssertionError
2024-06-13 06:25:33,173 logger.py[line:35] INFO INFO: Mutation progress 87/100
2024-06-13 06:25:33,177 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:25:33,177 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:25:33,177 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:25:33,177 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:25:33,177 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:25:33,177 logger.py[line:35] INFO Score for Edge is: 0.7191780821917808
2024-06-13 06:25:33,177 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:25:33,177 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:25:33,177 logger.py[line:35] INFO Score for SpecialI is: 0.5476190476190477
2024-06-13 06:25:33,177 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 06:25:33,177 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:25:33,177 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype60
2024-06-13 06:25:33,177 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:25:36,677 logger.py[line:35] INFO Generating model using SpecialI
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_SpecialI')>}
2024-06-13 06:25:36,779 logger.py[line:35] INFO Change Input Of Layer: lambda_copy_MDims_copy_MDtype_copy_SpecialI To: 0.0
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_SpecialI': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_SpecialI')>}
2024-06-13 06:25:36,898 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 173/2170
The Configuration Coverage is: 455/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 77/354
The Shape Coverage Is: 153/295
The Input Coverage Is: 295/766
2024-06-13 06:25:37,642 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:25:38,105 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (31) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:25:58,547 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 20s
2024-06-13 06:25:58,548 logger.py[line:35] INFO alexnet-SpecialI120-MDims44-MDtype60-SpecialI87 crash on backend pytorch when predicting
2024-06-13 06:25:58,569 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:25:58,578 logger.py[line:35] INFO Fail on backend: pytorch of model alexnet-SpecialI120-MDims44-MDtype60-SpecialI87
2024-06-13 06:25:58,578 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:25:58,578 logger.py[line:35] INFO after_prediction
2024-06-13 06:25:58,578 logger.py[line:35] INFO No representative seed generated: alexnet-SpecialI120-MDims44-MDtype60-SpecialI87, do not increase the reward
2024-06-13 06:25:58,698 logger.py[line:35] INFO INFO: Mutation progress 88/100
2024-06-13 06:25:58,698 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:25:58,698 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:25:58,698 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:25:58,698 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:25:58,698 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:25:58,698 logger.py[line:35] INFO Score for Edge is: 0.7191780821917808
2024-06-13 06:25:58,698 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:25:58,698 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:25:58,698 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:25:58,698 logger.py[line:35] INFO The last used seed is: SpecialI
2024-06-13 06:25:58,699 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:25:58,699 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42
2024-06-13 06:25:58,699 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:26:03,275 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge')>}
Choosing 10 To Insert
2024-06-13 06:26:04,271 logger.py[line:35] INFO Insert 10 Global New Edges
2024-06-13 06:26:04,271 logger.py[line:35] INFO Candidate Edge: ('DepthwiseConv2D', 'TimeDistributed')
2024-06-13 06:26:05,372 logger.py[line:35] INFO Trying Adding Edge: ['DepthwiseConv2D', 'TimeDistributed'] by Connecting depthwise_conv2d_insert_copy_Edge and time_distributed_insert_copy_Edge
2024-06-13 06:26:06,481 logger.py[line:35] INFO Successfully Add Edge: ['DepthwiseConv2D', 'TimeDistributed'] by Connecting depthwise_conv2d_insert_copy_Edge and time_distributed_insert_copy_Edge
2024-06-13 06:26:06,481 logger.py[line:35] INFO Candidate Edge: ('DepthwiseConv2D', 'ZeroPadding2D')
2024-06-13 06:26:07,594 logger.py[line:35] INFO Trying Adding Edge: ['DepthwiseConv2D', 'ZeroPadding2D'] by Connecting depthwise_conv2d_insert_copy_Edge and pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge
2024-06-13 06:26:08,613 logger.py[line:35] INFO Successfully Add Edge: ['DepthwiseConv2D', 'ZeroPadding2D'] by Connecting depthwise_conv2d_insert_copy_Edge and pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge
2024-06-13 06:26:08,613 logger.py[line:35] INFO Candidate Edge: ('TimeDistributed', 'GlobalAveragePooling2D')
2024-06-13 06:26:09,932 logger.py[line:35] INFO Trying Adding Edge: ['TimeDistributed', 'GlobalAveragePooling2D'] by Connecting time_distributed_insert_copy_Edge_2 and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge
2024-06-13 06:26:10,939 logger.py[line:35] INFO Successfully Add Edge: ['TimeDistributed', 'GlobalAveragePooling2D'] by Connecting time_distributed_insert_copy_Edge_2 and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_Edge
2024-06-13 06:26:10,939 logger.py[line:35] INFO Candidate Edge: ('TimeDistributed', 'DepthwiseConv2D')
2024-06-13 06:26:12,051 logger.py[line:35] INFO Trying Adding Edge: ['TimeDistributed', 'DepthwiseConv2D'] by Connecting time_distributed_insert_copy_Edge_1 and depthwise_conv2d_insert_copy_Edge
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 75, in generate_model_by_model_mutation
    return InteractionMutationUtils.connect_layers(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 209, in connect_layers
    Edge_model = ArchitectureUtils.connect_two_layers(Edge_model, layer1_name, layer2_name)
  File "/root/implementations/scripts/tools/architecture_utils.py", line 635, in connect_two_layers
    edge_output = right_cloned_layer(left_output)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/backend.py", line 5717, in depthwise_conv2d
    data_format=tf_data_format)
ValueError: Exception encountered when calling layer "depthwise_conv2d_insert_copy_Edge_2" (type DepthwiseConv2D).

Negative dimension size caused by subtracting 9 from 7 for '{{node depthwise_conv2d_insert_copy_Edge_2/depthwise}} = DepthwiseConv2dNative[T=DT_FLOAT, data_format="NCHW", dilations=[1, 1, 1, 1], explicit_paddings=[], padding="VALID", strides=[1, 1, 1, 1]](Placeholder, depthwise_conv2d_insert_copy_Edge_2/depthwise/ReadVariableOp)' with input shapes: [?,7,7,2048], [9,9,7,1].

Call arguments received:
   inputs=tf.Tensor(shape=(None, 7, 7, 2048), dtype=float32)
2024-06-13 06:26:13,682 logger.py[line:35] INFO INFO: Mutation progress 88/100
2024-06-13 06:26:13,682 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:26:13,682 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:26:13,682 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:26:13,682 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:26:13,682 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:26:13,683 logger.py[line:35] INFO Score for Edge is: 0.7191780821917808
2024-06-13 06:26:13,683 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:26:13,683 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:26:13,683 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:26:13,683 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 06:26:13,683 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:26:13,683 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-NLAll94
2024-06-13 06:26:13,683 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:26:16,683 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:26:17,430 logger.py[line:35] INFO Generating model using NLAll
2024-06-13 06:26:17,433 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll')>}
2024-06-13 06:26:17,660 logger.py[line:35] INFO Insert 5 out of 13 Global New Layers
2024-06-13 06:26:17,660 logger.py[line:35] INFO insert MaxPooling3D after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:26:17,660 logger.py[line:35] INFO insert Cropping1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:26:17,661 logger.py[line:35] INFO insert ConvLSTM3D after dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:26:17,661 logger.py[line:35] INFO insert UpSampling1D after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:26:17,661 logger.py[line:35] INFO insert SimpleRNN after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:26:17,661 logger.py[line:35] INFO Insert 2 out of 19 Local New Layers
2024-06-13 06:26:17,661 logger.py[line:35] INFO insert TimeDistributed after repeat_vector_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:26:17,661 logger.py[line:35] INFO insert LayerNormalization after up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:26:17,661 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 2
2024-06-13 06:26:17,662 logger.py[line:35] INFO insert UpSampling3D after custom_expand_layer_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:26:17,662 logger.py[line:35] INFO insert DepthwiseConv1D after custom_drop_dim_layer_1_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll
2024-06-13 06:26:17,666 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[DEBUG] Inserting layer: <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x7f49b06e82d0>
2024-06-13 06:26:17,785 logger.py[line:35] INFO Converting output shape (None, 1, 9, 9, 225) to actual shape [None, 1, 9, 9, 225]
[DEBUG] Inserting layer: <keras.layers.convolutional.DepthwiseConv1D object at 0x7f49b0681390>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/initializers/initializers_v2.py", line 674, in __call__
    'Identity matrix initializer can only be used for 2D matrices. '
ValueError: Identity matrix initializer can only be used for 2D matrices. Received: shape=(7, 9, 1) of rank 3.
2024-06-13 06:26:18,252 logger.py[line:35] INFO INFO: Mutation progress 88/100
2024-06-13 06:26:18,252 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:26:18,252 logger.py[line:35] INFO Score for NLAll is: 0.8176470588235294
2024-06-13 06:26:18,252 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:26:18,252 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:26:18,252 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:26:18,252 logger.py[line:35] INFO Score for Edge is: 0.7191780821917808
2024-06-13 06:26:18,252 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:26:18,252 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:26:18,252 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:26:18,252 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:26:18,253 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:26:18,253 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81
2024-06-13 06:26:18,253 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:26:25,754 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 06:26:30,421 logger.py[line:35] INFO Insert 3 out of 23 Local New Layers
2024-06-13 06:26:30,422 logger.py[line:35] INFO insert GaussianNoise after block8_6_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 06:26:30,422 logger.py[line:35] INFO insert UpSampling2D after max_pooling2d_2_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 06:26:30,422 logger.py[line:35] INFO insert ActivityRegularization after average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.convolutional.UpSampling2D object at 0x7f04380c1190>
2024-06-13 06:26:30,508 logger.py[line:35] INFO Converting output shape (None, 35, 140, 768) to actual shape [None, 35, 35, 192]
[DEBUG] Inserting layer: <keras.layers.core.activity_regularization.ActivityRegularization object at 0x7f04380c1dd0>
2024-06-13 06:26:30,635 logger.py[line:35] INFO Converting output shape (None, 35, 35, 192) to actual shape [None, 35, 35, 192]
[DEBUG] Inserting layer: <keras.layers.noise.GaussianNoise object at 0x7f03f8764590>
2024-06-13 06:26:33,661 logger.py[line:35] INFO Converting output shape (None, 8, 8, 2080) to actual shape [None, 8, 8, 2080]
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 06:26:34,286 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 176/2170
The Configuration Coverage is: 456/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 78/354
The Shape Coverage Is: 156/295
The Input Coverage Is: 299/766
2024-06-13 06:26:40,623 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:26:41,088 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 58, in <module>
    transform_onnx(model_path)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 41, in transform_onnx
    model = keras.models.load_model(model_path, custom_objects=custom_objects())
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/save.py", line 201, in load_model
    compile)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/hdf5_format.py", line 181, in load_model_from_hdf5
    custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/model_config.py", line 52, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 678, in deserialize_keras_object
    list(custom_objects.items())))
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 663, in from_config
    config, custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1273, in reconstruct_from_config
    process_layer(layer_data)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1255, in process_layer
    layer = deserialize_layer(layer_data, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 681, in deserialize_keras_object
    deserialized_obj = cls.from_config(cls_config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 748, in from_config
    return cls(**config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/noise.py", line 56, in __init__
    super(GaussianNoise, self).__init__(**kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 323, in __init__
    generic_utils.validate_kwargs(kwargs, allowed_kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 1143, in validate_kwargs
    raise TypeError(error_message, kwarg)
TypeError: ('Keyword argument not understood:', 'seed')
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81-NLAll88/inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81-NLAll88.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:26:47,263 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 6s
2024-06-13 06:26:47,263 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81-NLAll88 crash on backend pytorch when predicting
2024-06-13 06:26:47,284 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:26:47,342 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81-NLAll88
2024-06-13 06:26:47,342 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:26:47,343 logger.py[line:35] INFO after_prediction
2024-06-13 06:26:47,567 logger.py[line:35] INFO INFO: Mutation progress 89/100
2024-06-13 06:26:47,567 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:26:47,567 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:26:47,567 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:26:47,567 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:26:47,567 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:26:47,567 logger.py[line:35] INFO Score for Edge is: 0.7191780821917808
2024-06-13 06:26:47,567 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:26:47,567 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:26:47,567 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:26:47,567 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:26:47,567 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:26:47,567 logger.py[line:35] INFO Choose seed: alexnet
2024-06-13 06:26:47,567 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:26:51,004 logger.py[line:35] INFO Generating model using NLAll
model outputs {'dense_3': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_NLAll')>}
2024-06-13 06:26:51,117 logger.py[line:35] INFO Insert 5 out of 18 Local New Layers
2024-06-13 06:26:51,118 logger.py[line:35] INFO insert RepeatVector after flatten_1_copy_NLAll
2024-06-13 06:26:51,118 logger.py[line:35] INFO insert PReLU after dropout_1_copy_NLAll
2024-06-13 06:26:51,118 logger.py[line:35] INFO insert DepthwiseConv2D after max_pooling2d_3_copy_NLAll
2024-06-13 06:26:51,118 logger.py[line:35] INFO insert ELU after max_pooling2d_3_copy_NLAll
2024-06-13 06:26:51,118 logger.py[line:35] INFO insert SeparableConv2D after max_pooling2d_3_copy_NLAll
2024-06-13 06:26:51,118 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 2
2024-06-13 06:26:51,119 logger.py[line:35] INFO insert ThresholdedReLU after conv2d_2_copy_NLAll
2024-06-13 06:26:51,119 logger.py[line:35] INFO Fail to find suitable insertion point for dimension: [5]
2024-06-13 06:26:51,119 logger.py[line:35] INFO insert GlobalMaxPooling3D after conv2d_1_copy_NLAll
[DEBUG] Inserting layer: <scripts.generation.custom_layers.CustomExpandLayer object at 0x7f7530374ad0>
[DEBUG] Inserting layer: <keras.layers.pooling.GlobalMaxPooling3D object at 0x7f75303e9310>
2024-06-13 06:26:51,157 logger.py[line:35] INFO Converting output shape (None, 1) to actual shape [None, 16, 16, 96]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ThresholdedReLU object at 0x7f753030e810>
2024-06-13 06:26:51,218 logger.py[line:35] INFO Converting output shape (None, 8, 8, 256) to actual shape [None, 8, 8, 256]
[DEBUG] Inserting layer: <keras.layers.convolutional.SeparableConv2D object at 0x7f7530299ed0>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1939, in _create_c_op
    raise ValueError(e.message)
ValueError: Exception encountered when calling layer "separable_conv2d_insert" (type SeparableConv2D).

Negative dimension size caused by subtracting 4 from 1 for '{{node separable_conv2d_insert/separable_conv2d/depthwise}} = DepthwiseConv2dNative[T=DT_FLOAT, data_format="NCHW", dilations=[1, 1, 1, 1], explicit_paddings=[], padding="VALID", strides=[1, 1, 1, 1]](Placeholder, separable_conv2d_insert/separable_conv2d/ReadVariableOp)' with input shapes: [?,1,1,256], [4,2,1,1].

Call arguments received:
   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)
2024-06-13 06:26:51,700 logger.py[line:35] INFO INFO: Mutation progress 89/100
2024-06-13 06:26:51,700 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:26:51,700 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:26:51,700 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:26:51,700 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:26:51,700 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:26:51,700 logger.py[line:35] INFO Score for Edge is: 0.7191780821917808
2024-06-13 06:26:51,700 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:26:51,700 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:26:51,700 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:26:51,700 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:26:51,701 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:26:51,701 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-LMerg70
2024-06-13 06:26:51,701 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:26:56,181 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge')>}
Choosing 3 To Insert
2024-06-13 06:26:57,238 logger.py[line:35] INFO Insert 3 Global New Edges
2024-06-13 06:26:57,238 logger.py[line:35] INFO Candidate Edge: ('Cropping2D', 'Cropping2D')
2024-06-13 06:26:58,302 logger.py[line:35] INFO Trying Adding Edge: ['Cropping2D', 'Cropping2D'] by Connecting cropping2d_5_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge and cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 75, in generate_model_by_model_mutation
    return InteractionMutationUtils.connect_layers(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 209, in connect_layers
    Edge_model = ArchitectureUtils.connect_two_layers(Edge_model, layer1_name, layer2_name)
  File "/root/implementations/scripts/tools/architecture_utils.py", line 635, in connect_two_layers
    edge_output = right_cloned_layer(left_output)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional.py", line 3554, in call
    raise ValueError('Argument `cropping` must be '
ValueError: Exception encountered when calling layer "cropping2d_3_copy_SpecialI_copy_MDtype_copy_LMerg_copy_Edge_2" (type Cropping2D).

Argument `cropping` must be greater than the input shape. Received: inputs.shape=(None, 10, 10, 64), and cropping=((10, 10), (10, 10))

Call arguments received:
   inputs=tf.Tensor(shape=(None, 10, 10, 64), dtype=float32)
2024-06-13 06:26:59,792 logger.py[line:35] INFO INFO: Mutation progress 89/100
2024-06-13 06:26:59,793 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:26:59,793 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:26:59,793 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:26:59,793 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:26:59,793 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:26:59,793 logger.py[line:35] INFO Score for Edge is: 0.7191780821917808
2024-06-13 06:26:59,793 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:26:59,793 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:26:59,793 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:26:59,793 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 06:26:59,793 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:26:59,793 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MParam115-MDims8-NLAll25-LMerg84
2024-06-13 06:26:59,793 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:27:02,814 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:27:03,542 logger.py[line:35] INFO Generating model using MParam
2024-06-13 06:27:03,545 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_MParam')>}
2024-06-13 06:27:03,758 logger.py[line:35] INFO Changing 3/4 of layer max_pooling2d_insert_copy_LMerg_copy_MParam's configuration
2024-06-13 06:27:03,758 logger.py[line:35] INFO changing config padding in layer max_pooling2d_insert_copy_LMerg_copy_MParam: from same to same
2024-06-13 06:27:03,758 logger.py[line:35] INFO changing config data_format in layer max_pooling2d_insert_copy_LMerg_copy_MParam: from channels_last to channels_first
2024-06-13 06:27:03,758 logger.py[line:35] INFO changing config strides in layer max_pooling2d_insert_copy_LMerg_copy_MParam: from (1, 1) to [2, 3]
2024-06-13 06:27:03,758 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:27:03,758 logger.py[line:35] INFO Changing 1/16 of layer conv3d_transpose_insert_copy_LMerg_copy_MParam's configuration
2024-06-13 06:27:03,758 logger.py[line:35] INFO changing config use_bias in layer conv3d_transpose_insert_copy_LMerg_copy_MParam: from False to True
2024-06-13 06:27:03,759 logger.py[line:35] INFO changing config strides in layer conv3d_transpose_insert_copy_LMerg_copy_MParam: from (1, 1, 1) to [2, 3, 4]
2024-06-13 06:27:03,759 logger.py[line:35] INFO Changing 2/2 of layer global_average_pooling3d_insert_copy_LMerg_copy_MParam's configuration
2024-06-13 06:27:03,759 logger.py[line:35] INFO changing config data_format in layer global_average_pooling3d_insert_copy_LMerg_copy_MParam: from channels_last to channels_first
2024-06-13 06:27:03,759 logger.py[line:35] INFO changing config keepdims in layer global_average_pooling3d_insert_copy_LMerg_copy_MParam: from False to True
2024-06-13 06:27:03,762 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MParam_copy_MDims_copy_NLAll_copy_LMerg_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 276, in change_layer_config
    x = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional.py", line 1566, in build
    raise ValueError('Inputs should have rank 5. '
ValueError: Inputs should have rank 5. Received input_shape=(None, 9, 9, 9, 1, 1, 1, 1).
2024-06-13 06:27:04,326 logger.py[line:35] INFO INFO: Mutation progress 89/100
2024-06-13 06:27:04,327 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:27:04,327 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:27:04,327 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:27:04,327 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:27:04,327 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:27:04,327 logger.py[line:35] INFO Score for Edge is: 0.7191780821917808
2024-06-13 06:27:04,327 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:27:04,327 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:27:04,327 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:27:04,327 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:27:04,327 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:27:04,327 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102
2024-06-13 06:27:04,327 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:27:11,799 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge')>}
Choosing 9 To Insert
2024-06-13 06:27:15,468 logger.py[line:35] INFO Insert 9 Local New Edges
2024-06-13 06:27:15,469 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'AveragePooling2D')
2024-06-13 06:27:19,896 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'AveragePooling2D'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:27:23,430 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'AveragePooling2D'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:27:23,430 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'Conv2D')
2024-06-13 06:27:28,000 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'Conv2D'] by Connecting batch_normalization_93_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and conv2d_73_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:27:31,322 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'Conv2D'] by Connecting batch_normalization_93_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and conv2d_73_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:27:31,322 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'GlobalAveragePooling2D')
2024-06-13 06:27:35,853 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'GlobalAveragePooling2D'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge_2 and avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:27:39,366 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'GlobalAveragePooling2D'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge_2 and avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:27:39,366 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'GlobalAveragePooling2D')
2024-06-13 06:27:43,928 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'GlobalAveragePooling2D'] by Connecting block17_8_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge_1
2024-06-13 06:27:47,257 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'GlobalAveragePooling2D'] by Connecting block17_8_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and avg_pool_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge_1
2024-06-13 06:27:47,258 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'BatchNormalization')
2024-06-13 06:27:51,784 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting batch_normalization_169_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and batch_normalization_98_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:27:55,289 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting batch_normalization_169_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and batch_normalization_98_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:27:55,289 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'BatchNormalization')
2024-06-13 06:27:59,579 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'BatchNormalization'] by Connecting conv2d_8_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and batch_normalization_175_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:28:03,246 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'BatchNormalization'] by Connecting conv2d_8_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and batch_normalization_175_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:28:03,246 logger.py[line:35] INFO Candidate Edge: ('AveragePooling2D', 'MaxPooling2D')
2024-06-13 06:28:07,811 logger.py[line:35] INFO Trying Adding Edge: ['AveragePooling2D', 'MaxPooling2D'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge_2 and max_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:28:11,214 logger.py[line:35] INFO Successfully Add Edge: ['AveragePooling2D', 'MaxPooling2D'] by Connecting average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge_2 and max_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge
2024-06-13 06:28:11,214 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'MaxPooling2D')
2024-06-13 06:28:15,829 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'MaxPooling2D'] by Connecting batch_normalization_150_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and max_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge_1
2024-06-13 06:28:19,371 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'MaxPooling2D'] by Connecting batch_normalization_150_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and max_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge_1
2024-06-13 06:28:19,371 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'AveragePooling2D')
2024-06-13 06:28:23,968 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'AveragePooling2D'] by Connecting batch_normalization_186_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge_1
2024-06-13 06:28:27,310 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'AveragePooling2D'] by Connecting batch_normalization_186_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge and average_pooling2d_1_copy_MParam_copy_MDtype_copy_MDtype_copy_Edge_1
2024-06-13 06:28:27,886 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 176/2170
The Configuration Coverage is: 456/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 79/354
The Shape Coverage Is: 156/295
The Input Coverage Is: 300/766
2024-06-13 06:28:34,590 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:28:35,055 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
2024-06-13 06:29:43,820 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:29:43,820 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: expected scalar type Float but found Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:29:47,963 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 1m, 12s
2024-06-13 06:29:47,963 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-Edge89 crash on backend pytorch when predicting
2024-06-13 06:29:47,985 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:29:48,002 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-Edge89
2024-06-13 06:29:48,002 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:29:48,002 logger.py[line:35] INFO after_prediction
2024-06-13 06:29:48,186 logger.py[line:35] INFO INFO: Mutation progress 90/100
2024-06-13 06:29:48,186 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:29:48,186 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:29:48,186 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:29:48,186 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:29:48,186 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:29:48,186 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:29:48,186 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:29:48,186 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:29:48,186 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:29:48,186 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 06:29:48,186 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:29:48,186 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94
2024-06-13 06:29:48,186 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:29:52,616 logger.py[line:35] INFO Generating model using LMerg
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 06:29:53,593 logger.py[line:35] INFO Insert 2 out of 8 Local New Layer
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 72, in generate_model_by_model_mutation
    return InteractionMutationUtils.merge_layers(model=model, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 165, in merge_layers
    assert len(selected_layer_name_list) == 1
AssertionError
2024-06-13 06:29:54,065 logger.py[line:35] INFO INFO: Mutation progress 90/100
2024-06-13 06:29:54,065 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:29:54,065 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:29:54,065 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:29:54,065 logger.py[line:35] INFO Score for MDtype is: 0.7317073170731707
2024-06-13 06:29:54,065 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:29:54,065 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:29:54,065 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:29:54,065 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:29:54,065 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:29:54,065 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 06:29:54,066 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:29:54,066 logger.py[line:35] INFO Choose seed: alexnet-SpecialI120-MDims44-MDtype64
2024-06-13 06:29:54,066 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:29:57,568 logger.py[line:35] INFO Generating model using MDtype
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype')>}
2024-06-13 06:29:57,673 logger.py[line:35] INFO Change 1 Layer's DType Out Of 5 Layer classes
2024-06-13 06:29:57,674 logger.py[line:35] INFO Changing 1 out of 5 Layer's DType.
2024-06-13 06:29:57,674 logger.py[line:35] INFO Selecting a Global DType float64 For Layer flatten_1_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype
model outputs {'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_SpecialI_copy_MDims_copy_MDtype_copy_MDtype')>}
2024-06-13 06:29:57,798 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 176/2170
The Configuration Coverage is: 456/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 79/354
The Shape Coverage Is: 156/295
The Input Coverage Is: 300/766
2024-06-13 06:29:58,551 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:29:59,012 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (34) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:30:19,254 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 20s
2024-06-13 06:30:19,254 logger.py[line:35] INFO alexnet-SpecialI120-MDims44-MDtype64-MDtype90 crash on backend pytorch when predicting
2024-06-13 06:30:19,276 logger.py[line:35] INFO coverage_c=14535
2024-06-13 06:30:19,287 logger.py[line:35] INFO Fail on backend: pytorch of model alexnet-SpecialI120-MDims44-MDtype64-MDtype90
2024-06-13 06:30:19,287 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:30:19,287 logger.py[line:35] INFO after_prediction
2024-06-13 06:30:19,287 logger.py[line:35] INFO No representative seed generated: alexnet-SpecialI120-MDims44-MDtype64-MDtype90, do not increase the reward
2024-06-13 06:30:19,440 logger.py[line:35] INFO INFO: Mutation progress 91/100
2024-06-13 06:30:19,440 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:30:19,440 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:30:19,440 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:30:19,440 logger.py[line:35] INFO Score for MDtype is: 0.7228915662650602
2024-06-13 06:30:19,440 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:30:19,440 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:30:19,440 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:30:19,440 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:30:19,440 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:30:19,440 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 06:30:19,440 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:30:19,441 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-NLAll99-MDtype111-MDims14-SpecialI56
2024-06-13 06:30:19,441 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:30:24,115 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_NLAll')>}
2024-06-13 06:30:25,319 logger.py[line:35] INFO Insert 1 out of 2 Global New Layers
2024-06-13 06:30:25,320 logger.py[line:35] INFO insert Conv3D after conv2_block1_0_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_NLAll_copy_MDtype_copy_MDims_copy_SpecialI_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.convolutional.Conv3D object at 0x7f2ccc1a4910>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1939, in _create_c_op
    raise ValueError(e.message)
ValueError: Exception encountered when calling layer "conv3d_insert" (type Conv3D).

Negative dimension size caused by subtracting 2 from 1 for '{{node conv3d_insert/Conv3D}} = Conv3D[T=DT_FLOAT, data_format="NDHWC", dilations=[1, 1, 1, 1, 1], padding="VALID", strides=[1, 1, 1, 1, 1]](Placeholder, conv3d_insert/Conv3D/ReadVariableOp)' with input shapes: [?,1,56,56,256], [2,5,3,256,256].

Call arguments received:
   inputs=tf.Tensor(shape=(None, 1, 56, 56, 256), dtype=float32)
2024-06-13 06:30:25,992 logger.py[line:35] INFO INFO: Mutation progress 91/100
2024-06-13 06:30:25,992 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:30:25,992 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:30:25,992 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:30:25,992 logger.py[line:35] INFO Score for MDtype is: 0.7228915662650602
2024-06-13 06:30:25,992 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:30:25,992 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:30:25,992 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:30:25,992 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:30:25,992 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:30:25,992 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:30:25,992 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:30:25,992 logger.py[line:35] INFO Choose seed: alexnet-Edge76
2024-06-13 06:30:25,993 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:30:29,441 logger.py[line:35] INFO Generating model using Edge
model outputs {'dense_3_copy_Edge': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_Edge_copy_Edge')>, 'dropout_2_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'dropout_2_copy_Edge_2_copy_Edge')>}
Choosing 3 To Insert
2024-06-13 06:30:29,532 logger.py[line:35] INFO Insert 3 Global New Edges
2024-06-13 06:30:29,532 logger.py[line:35] INFO Candidate Edge: ('Dropout', 'BatchNormalization')
2024-06-13 06:30:29,626 logger.py[line:35] INFO Trying Adding Edge: ['Dropout', 'BatchNormalization'] by Connecting dropout_1_copy_Edge_copy_Edge and batch_normalization_3_copy_Edge_copy_Edge
2024-06-13 06:30:29,751 logger.py[line:35] INFO Successfully Add Edge: ['Dropout', 'BatchNormalization'] by Connecting dropout_1_copy_Edge_copy_Edge and batch_normalization_3_copy_Edge_copy_Edge
2024-06-13 06:30:29,751 logger.py[line:35] INFO Candidate Edge: ('Dropout', 'Conv2D')
2024-06-13 06:30:29,858 logger.py[line:35] INFO Trying Adding Edge: ['Dropout', 'Conv2D'] by Connecting dropout_1_copy_Edge_copy_Edge and conv2d_3_copy_Edge_copy_Edge
2024-06-13 06:30:29,970 logger.py[line:35] INFO Successfully Add Edge: ['Dropout', 'Conv2D'] by Connecting dropout_1_copy_Edge_copy_Edge and conv2d_3_copy_Edge_copy_Edge
2024-06-13 06:30:29,970 logger.py[line:35] INFO Candidate Edge: ('Dropout', 'MaxPooling2D')
2024-06-13 06:30:30,088 logger.py[line:35] INFO Trying Adding Edge: ['Dropout', 'MaxPooling2D'] by Connecting dropout_1_copy_Edge_copy_Edge and max_pooling2d_2_copy_Edge_copy_Edge
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 75, in generate_model_by_model_mutation
    return InteractionMutationUtils.connect_layers(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 209, in connect_layers
    Edge_model = ArchitectureUtils.connect_two_layers(Edge_model, layer1_name, layer2_name)
  File "/root/implementations/scripts/tools/architecture_utils.py", line 635, in connect_two_layers
    edge_output = right_cloned_layer(left_output)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1939, in _create_c_op
    raise ValueError(e.message)
ValueError: Exception encountered when calling layer "max_pooling2d_2_copy_Edge_copy_Edge_2" (type MaxPooling2D).

Negative dimension size caused by subtracting 3 from 1 for '{{node max_pooling2d_2_copy_Edge_copy_Edge_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format="NHWC", explicit_paddings=[], ksize=[1, 3, 3, 1], padding="VALID", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,4096].

Call arguments received:
   inputs=tf.Tensor(shape=(None, 1, 1, 4096), dtype=float32)
2024-06-13 06:30:30,657 logger.py[line:35] INFO INFO: Mutation progress 91/100
2024-06-13 06:30:30,657 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:30:30,657 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:30:30,657 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:30:30,657 logger.py[line:35] INFO Score for MDtype is: 0.7228915662650602
2024-06-13 06:30:30,657 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:30:30,657 logger.py[line:35] INFO Score for LMerg is: 0.717391304347826
2024-06-13 06:30:30,657 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:30:30,657 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:30:30,657 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:30:30,657 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 06:30:30,658 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:30:30,658 logger.py[line:35] INFO Choose seed: alexnet-Edge76
2024-06-13 06:30:30,658 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:30:34,102 logger.py[line:35] INFO Generating model using LMerg
model outputs {'dense_3_copy_Edge': <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_3_copy_Edge_copy_LMerg')>, 'dropout_2_copy_Edge_2': <KerasTensor: shape=(None, 3, 3, 384) dtype=float32 (created by layer 'dropout_2_copy_Edge_2_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 06:30:34,193 logger.py[line:35] INFO Insert 1 out of 8 Local New Layer
2024-06-13 06:30:34,193 logger.py[line:35] INFO Trying Merge Layers: batch_normalization_2_copy_Edge_copy_LMerg and conv2d_5_copy_Edge_copy_LMerg by Minimum
2024-06-13 06:30:34,283 logger.py[line:35] INFO Success on Merge Layers: batch_normalization_2_copy_Edge_copy_LMerg and conv2d_5_copy_Edge_copy_LMerg by Minimum
2024-06-13 06:30:34,308 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 176/2170
The Configuration Coverage is: 456/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 79/354
The Shape Coverage Is: 156/295
The Input Coverage Is: 300/766
2024-06-13 06:30:35,026 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:30:35,489 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:30:55,779 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:30:55,779 logger.py[line:35] INFO Now pytorch is using: cuda
2024-06-13 06:30:58,509 logger.py[line:35] INFO SUCCESS:Get prediction for alexnet-Edge76-LMerg91 successfully on pytorch!
2024-06-13 06:30:59,234 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 23s
2024-06-13 06:30:59,234 logger.py[line:35] INFO loading the redis
2024-06-13 06:30:59,237 logger.py[line:35] INFO finish loading from redis
2024-06-13 06:30:59,258 logger.py[line:35] INFO coverage_c=14541
2024-06-13 06:30:59,266 logger.py[line:35] INFO Success on backend: pytorch of model alexnet-Edge76-LMerg91
2024-06-13 06:30:59,267 logger.py[line:35] INFO Traceback (most recent call last):
  File "/root/implementations/scripts/generation/run.py", line 562, in gen
    model_name=new_model_name)
  File "/root/implementations/scripts/generation/run.py", line 432, in analyze_inference_result
    if (len(predict_output) >= 2 or len(predict_output) == len(self.backends)) and status["tensorflow"] == 0:
KeyError: 'tensorflow'

2024-06-13 06:30:59,290 logger.py[line:35] INFO INFO: Mutation progress 91/100
2024-06-13 06:30:59,291 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:30:59,291 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:30:59,291 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:30:59,291 logger.py[line:35] INFO Score for MDtype is: 0.7228915662650602
2024-06-13 06:30:59,291 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:30:59,291 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:30:59,291 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:30:59,291 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:30:59,291 logger.py[line:35] INFO Score for SpecialI is: 0.5227272727272727
2024-06-13 06:30:59,291 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 06:30:59,291 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:30:59,291 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91
2024-06-13 06:30:59,291 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:31:02,287 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:31:02,995 logger.py[line:35] INFO Generating model using SpecialI
2024-06-13 06:31:02,998 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_SpecialI')>}
2024-06-13 06:31:03,170 logger.py[line:35] INFO Change Input Of Layer: custom_drop_dim_layer_1_copy_MDims_copy_MDtype_copy_SpecialI To: nan
2024-06-13 06:31:03,173 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_SpecialI will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_SpecialI': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_SpecialI')>}
2024-06-13 06:31:03,366 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:31:03,818 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_SpecialI will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 176/2170
The Configuration Coverage is: 456/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 79/354
The Shape Coverage Is: 156/295
The Input Coverage Is: 300/766
2024-06-13 06:31:04,020 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:31:04,483 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (46) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:31:12,259 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 7s
2024-06-13 06:31:12,259 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-SpecialI91 crash on backend pytorch when predicting
2024-06-13 06:31:12,281 logger.py[line:35] INFO coverage_c=14541
2024-06-13 06:31:12,338 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-SpecialI91
2024-06-13 06:31:12,338 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:31:12,338 logger.py[line:35] INFO after_prediction
2024-06-13 06:31:12,339 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-SpecialI91, do not increase the reward
2024-06-13 06:31:12,464 logger.py[line:35] INFO INFO: Mutation progress 92/100
2024-06-13 06:31:12,464 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:31:12,464 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:31:12,464 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:31:12,464 logger.py[line:35] INFO Score for MDtype is: 0.7228915662650602
2024-06-13 06:31:12,464 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:31:12,464 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:31:12,464 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:31:12,464 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:31:12,464 logger.py[line:35] INFO Score for SpecialI is: 0.5
2024-06-13 06:31:12,465 logger.py[line:35] INFO The last used seed is: SpecialI
2024-06-13 06:31:12,465 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:31:12,465 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MDtype39
2024-06-13 06:31:12,465 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:31:16,866 logger.py[line:35] INFO Generating model using MDtype
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_MDtype')>}
2024-06-13 06:31:17,846 logger.py[line:35] INFO Change 1 Layer's DType Out Of 5 Layer classes
2024-06-13 06:31:17,847 logger.py[line:35] INFO Changing 1 out of 5 Layer's DType.
2024-06-13 06:31:17,847 logger.py[line:35] INFO Selecting a Global DType half For Layer pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_MDtype
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MDtype_copy_MDtype')>}
2024-06-13 06:31:18,810 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 176/2170
The Configuration Coverage is: 456/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 79/354
The Shape Coverage Is: 156/295
The Input Coverage Is: 300/766
2024-06-13 06:31:20,692 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:31:21,156 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (138) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:31:46,004 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 24s
2024-06-13 06:31:46,004 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-MDtype39-MDtype92 crash on backend pytorch when predicting
2024-06-13 06:31:46,025 logger.py[line:35] INFO coverage_c=14541
2024-06-13 06:31:46,033 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-MDtype39-MDtype92
2024-06-13 06:31:46,033 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:31:46,033 logger.py[line:35] INFO after_prediction
2024-06-13 06:31:46,033 logger.py[line:35] INFO No representative seed generated: resnet50-LMerg2-MShape5-MDtype6-MDtype39-MDtype92, do not increase the reward
2024-06-13 06:31:46,173 logger.py[line:35] INFO INFO: Mutation progress 93/100
2024-06-13 06:31:46,174 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:31:46,174 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:31:46,174 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:31:46,174 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:31:46,174 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:31:46,174 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:31:46,174 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:31:46,174 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:31:46,174 logger.py[line:35] INFO Score for SpecialI is: 0.5
2024-06-13 06:31:46,174 logger.py[line:35] INFO The last used seed is: MDtype
2024-06-13 06:31:46,174 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:31:46,174 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99
2024-06-13 06:31:46,174 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:31:53,671 logger.py[line:35] INFO Generating model using SpecialI
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_SpecialI')>}
2024-06-13 06:31:57,236 logger.py[line:35] INFO Change Input Of Layer: activation_18_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_SpecialI To: nan
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_SpecialI': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam_copy_SpecialI')>}
2024-06-13 06:32:01,117 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 176/2170
The Configuration Coverage is: 456/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 79/354
The Shape Coverage Is: 156/295
The Input Coverage Is: 300/766
2024-06-13 06:32:07,629 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:32:08,094 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Failed to apply optimize_transpose
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py", line 62, in optimize_graph
    graph = opt.optimize(current, iteration) or graph
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 41, in optimize
    graph = self._optimize(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 157, in _optimize
    return self._apply_optimization(graph, self._optimize_at_current_graph_level)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py", line 62, in _apply_optimization
    graph = optimize_func(graph)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 170, in _optimize_at_current_graph_level
    if self._handle_nhwc_tranpose(n):
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 328, in _handle_nhwc_tranpose
    return op_handler(trans, p)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py", line 581, in _mul_handler
    result = np.multiply(transposed_val, mul_val)
ValueError: operands could not be broadcast together with shapes (1,3,192,224) (1,1,8,1) 
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (1041) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:33:07,395 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 59s
2024-06-13 06:33:07,395 logger.py[line:35] INFO inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99-SpecialI93 crash on backend pytorch when predicting
2024-06-13 06:33:07,417 logger.py[line:35] INFO coverage_c=14541
2024-06-13 06:33:07,424 logger.py[line:35] INFO Fail on backend: pytorch of model inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99-SpecialI93
2024-06-13 06:33:07,424 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:33:07,424 logger.py[line:35] INFO after_prediction
2024-06-13 06:33:07,424 logger.py[line:35] INFO No representative seed generated: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype4-MParam99-SpecialI93, do not increase the reward
2024-06-13 06:33:07,613 logger.py[line:35] INFO INFO: Mutation progress 94/100
2024-06-13 06:33:07,613 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:33:07,613 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:33:07,613 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:33:07,613 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:33:07,614 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:33:07,614 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:33:07,614 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:33:07,614 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:33:07,614 logger.py[line:35] INFO Score for SpecialI is: 0.4791666666666667
2024-06-13 06:33:07,614 logger.py[line:35] INFO The last used seed is: SpecialI
2024-06-13 06:33:07,614 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:33:07,614 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype131-Edge7
2024-06-13 06:33:07,614 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:33:12,079 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam')>, 'cropping2d': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_MParam')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 3) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_MParam')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_MParam')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2': <KerasTensor: shape=(None, 64) dtype=float64 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_1_2_copy_MParam')>, 'cropping2d_1': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_1_copy_MParam')>, 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2': <KerasTensor: shape=(None, 20, 20, 256) dtype=float32 (created by layer 'conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_MParam')>, 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2': <KerasTensor: shape=(None, 14, 14, 256) dtype=float32 (created by layer 'conv5_block1_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_2_copy_MParam')>, 'cropping2d_2': <KerasTensor: shape=(None, 11, 11, 64) dtype=float32 (created by layer 'cropping2d_2_copy_MParam')>}
2024-06-13 06:33:13,109 logger.py[line:35] INFO Changing 1/2 of layer conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_MParam's configuration
2024-06-13 06:33:13,110 logger.py[line:35] INFO changing config data_format in layer conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_MParam: from channels_last to channels_first
2024-06-13 06:33:13,110 logger.py[line:35] INFO changing config padding in layer conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1_2_copy_MParam: from ((3, 3), (3, 3)) to [2, 2]
2024-06-13 06:33:13,110 logger.py[line:35] INFO Changing 1/5 of layer conv4_block1_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 06:33:13,110 logger.py[line:35] INFO changing config scale in layer conv4_block1_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from True to False
2024-06-13 06:33:13,110 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:33:13,110 logger.py[line:35] INFO changing config axis in layer conv4_block1_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:33:13,110 logger.py[line:35] INFO Changing 3/5 of layer conv3_block1_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 06:33:13,110 logger.py[line:35] INFO changing config scale in layer conv3_block1_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from True to False
2024-06-13 06:33:13,111 logger.py[line:35] INFO changing config center in layer conv3_block1_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from True to False
2024-06-13 06:33:13,111 logger.py[line:35] INFO changing config axis in layer conv3_block1_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:33:13,111 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:33:13,111 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:33:13,111 logger.py[line:35] INFO Changing 1/5 of layer conv2_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 06:33:13,111 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:33:13,111 logger.py[line:35] INFO changing config center in layer conv2_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from True to True
2024-06-13 06:33:13,111 logger.py[line:35] INFO changing config scale in layer conv2_block3_2_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from True to False
2024-06-13 06:33:13,111 logger.py[line:35] INFO Changing 2/15 of layer conv4_block2_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 06:33:13,111 logger.py[line:35] INFO changing config filters in layer conv4_block2_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from 256 to 7
2024-06-13 06:33:13,112 logger.py[line:35] INFO changing config padding in layer conv4_block2_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from valid to valid
2024-06-13 06:33:13,112 logger.py[line:35] INFO changing config use_bias in layer conv4_block2_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from True to False
2024-06-13 06:33:13,112 logger.py[line:35] INFO Changing 3/15 of layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 06:33:13,112 logger.py[line:35] INFO changing config padding in layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from valid to same
2024-06-13 06:33:13,112 logger.py[line:35] INFO changing config bias_initializer in layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from {'class_name': 'Zeros', 'config': {}} to he_normal
2024-06-13 06:33:13,112 logger.py[line:35] INFO changing config activation in layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from linear to hard_sigmoid
2024-06-13 06:33:13,112 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:33:13,112 logger.py[line:35] INFO changing config use_bias in layer conv5_block3_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from True to True
2024-06-13 06:33:13,113 logger.py[line:35] INFO Changing 1/5 of layer conv3_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 06:33:13,113 logger.py[line:35] INFO changing config scale in layer conv3_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from True to False
2024-06-13 06:33:13,113 logger.py[line:35] INFO changing config axis in layer conv3_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:33:13,113 logger.py[line:35] INFO Changing 2/5 of layer conv5_block2_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 06:33:13,113 logger.py[line:35] INFO changing config axis in layer conv5_block2_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:33:13,113 logger.py[line:35] INFO changing config center in layer conv5_block2_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from True to True
2024-06-13 06:33:13,113 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:33:13,113 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:33:13,113 logger.py[line:35] INFO changing config scale in layer conv5_block2_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from True to False
2024-06-13 06:33:13,114 logger.py[line:35] INFO Changing 2/15 of layer conv3_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 06:33:13,114 logger.py[line:35] INFO changing config data_format in layer conv3_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from channels_last to channels_first
2024-06-13 06:33:13,114 logger.py[line:35] INFO changing config filters in layer conv3_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from 128 to 6
2024-06-13 06:33:13,114 logger.py[line:35] INFO changing config use_bias in layer conv3_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from True to True
2024-06-13 06:33:13,114 logger.py[line:35] INFO Changing 1/15 of layer conv4_block5_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam's configuration
2024-06-13 06:33:13,114 logger.py[line:35] INFO changing config kernel_constraint in layer conv4_block5_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from None to MinMaxNorm
2024-06-13 06:33:13,114 logger.py[line:35] INFO changing config padding in layer conv4_block5_3_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_copy_MParam: from valid to valid
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/merge.py", line 79, in _compute_elemwise_op_output_shape
    'Inputs have incompatible shapes. '
ValueError: Inputs have incompatible shapes. Received shapes (28, 28, 512) and (6, 28, 512)
2024-06-13 06:33:13,888 logger.py[line:35] INFO INFO: Mutation progress 94/100
2024-06-13 06:33:13,888 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:33:13,888 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:33:13,888 logger.py[line:35] INFO Score for MParam is: 0.7361111111111112
2024-06-13 06:33:13,888 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:33:13,888 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:33:13,888 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:33:13,888 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:33:13,888 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:33:13,888 logger.py[line:35] INFO Score for SpecialI is: 0.4791666666666667
2024-06-13 06:33:13,888 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:33:13,889 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:33:13,889 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-SpecialI47-MDtype113
2024-06-13 06:33:13,889 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:33:16,902 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:33:17,590 logger.py[line:35] INFO Generating model using MParam
2024-06-13 06:33:17,595 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MParam')>}
2024-06-13 06:33:17,741 logger.py[line:35] INFO Changing 1/1 of layer up_sampling3d_insert_copy_SpecialI_copy_MDtype_copy_MParam's configuration
2024-06-13 06:33:17,742 logger.py[line:35] INFO changing config data_format in layer up_sampling3d_insert_copy_SpecialI_copy_MDtype_copy_MParam: from channels_first to channels_last
2024-06-13 06:33:17,746 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MParam')>}
2024-06-13 06:33:17,903 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:33:18,340 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_SpecialI_copy_MDtype_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 176/2170
The Configuration Coverage is: 456/2049
The NDims Coverage Is: 65/117
The DType Coverage Is: 79/354
The Shape Coverage Is: 156/295
The Input Coverage Is: 300/766
2024-06-13 06:33:18,504 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:33:18,967 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (33) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:33:26,393 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 7s
2024-06-13 06:33:26,393 logger.py[line:35] INFO lstm2-NLAll38-SpecialI47-MDtype113-MParam94 crash on backend pytorch when predicting
2024-06-13 06:33:26,414 logger.py[line:35] INFO coverage_c=14541
2024-06-13 06:33:26,422 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-SpecialI47-MDtype113-MParam94
2024-06-13 06:33:26,422 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:33:26,422 logger.py[line:35] INFO after_prediction
2024-06-13 06:33:26,422 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-SpecialI47-MDtype113-MParam94, do not increase the reward
2024-06-13 06:33:26,548 logger.py[line:35] INFO INFO: Mutation progress 95/100
2024-06-13 06:33:26,548 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:33:26,548 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:33:26,548 logger.py[line:35] INFO Score for MDims is: 0.7222222222222222
2024-06-13 06:33:26,548 logger.py[line:35] INFO Score for MParam is: 0.7162162162162162
2024-06-13 06:33:26,548 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:33:26,548 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:33:26,549 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:33:26,549 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:33:26,549 logger.py[line:35] INFO Score for SpecialI is: 0.4791666666666667
2024-06-13 06:33:26,549 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:33:26,549 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:33:26,549 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MDtype4-NLAll12-NLAll32-NLAll93-NLAll-1
2024-06-13 06:33:26,549 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:33:31,332 logger.py[line:35] INFO Generating model using MDims
model outputs {'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDims')>}
2024-06-13 06:33:32,403 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 7 Layer classes
2024-06-13 06:33:32,403 logger.py[line:35] INFO Global Layer Class: 6; Local Layer Class: 1; Total Layer Class: 7
2024-06-13 06:33:32,403 logger.py[line:35] INFO Changing 1 out of 6 Layer's NDims.
2024-06-13 06:33:32,404 logger.py[line:35] INFO Selecting a Global NDims 5 For Layer elu_insert_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDims
model outputs {'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDims': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MDtype_copy_NLAll_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDims')>}
2024-06-13 06:33:33,562 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 178/2170
The Configuration Coverage is: 505/2049
The NDims Coverage Is: 68/117
The DType Coverage Is: 83/354
The Shape Coverage Is: 165/295
The Input Coverage Is: 316/766
2024-06-13 06:33:35,735 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:33:36,200 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 58, in <module>
    transform_onnx(model_path)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 41, in transform_onnx
    model = keras.models.load_model(model_path, custom_objects=custom_objects())
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/save.py", line 201, in load_model
    compile)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/hdf5_format.py", line 181, in load_model_from_hdf5
    custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/model_config.py", line 52, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 678, in deserialize_keras_object
    list(custom_objects.items())))
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 663, in from_config
    config, custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1273, in reconstruct_from_config
    process_layer(layer_data)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1255, in process_layer
    layer = deserialize_layer(layer_data, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 681, in deserialize_keras_object
    deserialized_obj = cls.from_config(cls_config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 748, in from_config
    return cls(**config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/noise.py", line 107, in __init__
    super(GaussianDropout, self).__init__(**kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 323, in __init__
    generic_utils.validate_kwargs(kwargs, allowed_kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 1143, in validate_kwargs
    raise TypeError(error_message, kwarg)
TypeError: ('Keyword argument not understood:', 'seed')
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/resnet50-LMerg2-MDtype4-NLAll12-NLAll32-NLAll93-NLAll-1-MDims95/resnet50-LMerg2-MDtype4-NLAll12-NLAll32-NLAll93-NLAll-1-MDims95.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:33:41,673 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 5s
2024-06-13 06:33:41,673 logger.py[line:35] INFO resnet50-LMerg2-MDtype4-NLAll12-NLAll32-NLAll93-NLAll-1-MDims95 crash on backend pytorch when predicting
2024-06-13 06:33:41,694 logger.py[line:35] INFO coverage_c=14541
2024-06-13 06:33:41,751 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MDtype4-NLAll12-NLAll32-NLAll93-NLAll-1-MDims95
2024-06-13 06:33:41,751 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:33:41,752 logger.py[line:35] INFO after_prediction
2024-06-13 06:33:41,925 logger.py[line:35] INFO INFO: Mutation progress 96/100
2024-06-13 06:33:41,925 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:33:41,925 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:33:41,925 logger.py[line:35] INFO Score for MDims is: 0.717391304347826
2024-06-13 06:33:41,925 logger.py[line:35] INFO Score for MParam is: 0.7162162162162162
2024-06-13 06:33:41,925 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:33:41,925 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:33:41,925 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:33:41,925 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:33:41,925 logger.py[line:35] INFO Score for SpecialI is: 0.4791666666666667
2024-06-13 06:33:41,925 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 06:33:41,926 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:33:41,926 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42
2024-06-13 06:33:41,926 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:33:46,529 logger.py[line:35] INFO Generating model using SpecialI
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>}
2024-06-13 06:33:47,511 logger.py[line:35] INFO Change Input Of Layer: conv4_block4_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI To: 0.0
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI': <KerasTensor: shape=(None, 64) dtype=float16 (created by layer 'avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI': <KerasTensor: shape=(None, 14, 14, 512) dtype=float32 (created by layer 'conv5_block1_1_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_Edge_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_1_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI': <KerasTensor: shape=(None, 10, 10, 3) dtype=float32 (created by layer 'cropping2d_2_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI': <KerasTensor: shape=(None, 10, 10, 128) dtype=float32 (created by layer 'cropping2d_3_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_4_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI': <KerasTensor: shape=(None, 10, 10, 64) dtype=float32 (created by layer 'cropping2d_5_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>, 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI': <KerasTensor: shape=(None, 10, 10, 256) dtype=float32 (created by layer 'cropping2d_6_copy_SpecialI_copy_MDtype_copy_NLAll_copy_SpecialI')>}
2024-06-13 06:33:48,668 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 178/2170
The Configuration Coverage is: 505/2049
The NDims Coverage Is: 68/117
The DType Coverage Is: 83/354
The Shape Coverage Is: 165/295
The Input Coverage Is: 316/766
2024-06-13 06:33:50,844 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:33:51,307 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:34:27,135 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:34:27,135 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: expected scalar type Float but found Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:34:31,124 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 39s
2024-06-13 06:34:31,124 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42-SpecialI96 crash on backend pytorch when predicting
2024-06-13 06:34:31,146 logger.py[line:35] INFO coverage_c=14541
2024-06-13 06:34:31,209 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42-SpecialI96
2024-06-13 06:34:31,209 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:34:31,210 logger.py[line:35] INFO after_prediction
2024-06-13 06:34:31,210 logger.py[line:35] INFO No representative seed generated: resnet50-LMerg2-MShape5-MDtype6-Edge24-SpecialI29-MDtype37-NLAll42-SpecialI96, do not increase the reward
2024-06-13 06:34:31,346 logger.py[line:35] INFO INFO: Mutation progress 97/100
2024-06-13 06:34:31,346 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:34:31,346 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:34:31,346 logger.py[line:35] INFO Score for MDims is: 0.717391304347826
2024-06-13 06:34:31,346 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:34:31,346 logger.py[line:35] INFO Score for MParam is: 0.7162162162162162
2024-06-13 06:34:31,346 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:34:31,347 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:34:31,347 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:34:31,347 logger.py[line:35] INFO Score for SpecialI is: 0.46
2024-06-13 06:34:31,347 logger.py[line:35] INFO The last used seed is: SpecialI
2024-06-13 06:34:31,347 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:34:31,347 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype91-NLAll94
2024-06-13 06:34:31,347 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:34:34,383 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:34:35,132 logger.py[line:35] INFO Generating model using LMerg
2024-06-13 06:34:35,135 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_NLAll_copy_LMerg')>}
Choosing Mutation Ratio Between 1 and 2
2024-06-13 06:34:35,319 logger.py[line:35] INFO Insert 2 out of 8 Local New Layer
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 72, in generate_model_by_model_mutation
    return InteractionMutationUtils.merge_layers(model=model, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 165, in merge_layers
    assert len(selected_layer_name_list) == 1
AssertionError
2024-06-13 06:34:35,745 logger.py[line:35] INFO INFO: Mutation progress 97/100
2024-06-13 06:34:35,745 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:34:35,745 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:34:35,745 logger.py[line:35] INFO Score for MDims is: 0.717391304347826
2024-06-13 06:34:35,745 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:34:35,745 logger.py[line:35] INFO Score for MParam is: 0.7162162162162162
2024-06-13 06:34:35,745 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:34:35,745 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:34:35,745 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:34:35,745 logger.py[line:35] INFO Score for SpecialI is: 0.46
2024-06-13 06:34:35,745 logger.py[line:35] INFO The last used seed is: LMerg
2024-06-13 06:34:35,746 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:34:35,746 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65
2024-06-13 06:34:35,746 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:34:38,783 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:34:39,490 logger.py[line:35] INFO Generating model using MDims
2024-06-13 06:34:39,493 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDims')>}
2024-06-13 06:34:39,669 logger.py[line:35] INFO Change 1 Layer's Dimension Out Of 1 Layer classes
2024-06-13 06:34:39,669 logger.py[line:35] INFO Global Layer Class: 0; Local Layer Class: 1; Total Layer Class: 1
2024-06-13 06:34:39,669 logger.py[line:35] INFO Changing 0 Layer's NDims.
2024-06-13 06:34:39,669 logger.py[line:35] INFO Changing 1 Layer's NDims.
2024-06-13 06:34:39,670 logger.py[line:35] INFO No Global NDims Can Be Found, Randomly Select NDims: 5 For Layer: dropout_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDims
2024-06-13 06:34:39,673 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDims': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDims')>}
2024-06-13 06:34:39,868 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:34:40,327 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MDtype_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 178/2170
The Configuration Coverage is: 505/2049
The NDims Coverage Is: 68/117
The DType Coverage Is: 83/354
The Shape Coverage Is: 165/295
The Input Coverage Is: 316/766
2024-06-13 06:34:40,529 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:34:40,993 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (50) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:34:48,855 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 7s
2024-06-13 06:34:48,855 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65-MDims97 crash on backend pytorch when predicting
2024-06-13 06:34:48,876 logger.py[line:35] INFO coverage_c=14541
2024-06-13 06:34:48,947 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65-MDims97
2024-06-13 06:34:48,948 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:34:48,948 logger.py[line:35] INFO after_prediction
2024-06-13 06:34:48,948 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-MDtype45-MDims17-MDims55-MDtype65-MDims97, do not increase the reward
2024-06-13 06:34:49,074 logger.py[line:35] INFO INFO: Mutation progress 98/100
2024-06-13 06:34:49,074 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:34:49,074 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:34:49,074 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:34:49,074 logger.py[line:35] INFO Score for MParam is: 0.7162162162162162
2024-06-13 06:34:49,074 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:34:49,074 logger.py[line:35] INFO Score for MDims is: 0.7021276595744681
2024-06-13 06:34:49,074 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:34:49,075 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:34:49,075 logger.py[line:35] INFO Score for SpecialI is: 0.46
2024-06-13 06:34:49,075 logger.py[line:35] INFO The last used seed is: MDims
2024-06-13 06:34:49,075 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:34:49,075 logger.py[line:35] INFO Choose seed: densenet121-SpecialI57-NLAll80
2024-06-13 06:34:49,075 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:34:54,996 logger.py[line:35] INFO Generating model using MShape
model outputs {'predictions_copy_SpecialI_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_SpecialI_copy_NLAll_copy_MShape')>}
2024-06-13 06:34:57,330 logger.py[line:35] INFO Change 2 Layer's Shape Out Of 13 Layer classes
2024-06-13 06:34:57,330 logger.py[line:35] INFO Changing 2 out of 5 Layer's Shape.
2024-06-13 06:34:57,332 logger.py[line:35] INFO [Globally] Changing The Input Shape Of Layer: zero_padding3d_insert_copy_MShape From [None, 1, 7, 7, 576] To [None, 7, 4, 8, 4]
2024-06-13 06:34:57,333 logger.py[line:35] INFO [Globally] Changing The Input Shape Of Layer: separable_conv2d_insert_copy_MShape From [None, 7, 7, 736] To [None, 0, 9, 4]
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 94, in generate_model_by_model_mutation
    return InputMutationUtils.mutate_shape(model=model, architecture_measure=architecture_measure, max_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 483, in mutate_shape
    new_model = InputMutationUtils.mshape(MShape_model, selected_layer_shape_pair, revert_shape=True)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 456, in mshape
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 447, in mshape_layer_mutation
    layer_input = layer(x)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1939, in _create_c_op
    raise ValueError(e.message)
ValueError: Exception encountered when calling layer "separable_conv2d_insert_copy_MShape" (type SeparableConv2D).

Depth of filter must not be 0 for '{{node separable_conv2d_insert_copy_MShape/separable_conv2d}} = Conv2D[T=DT_FLOAT, data_format="NCHW", dilations=[1, 1, 1, 1], explicit_paddings=[], padding="VALID", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](separable_conv2d_insert_copy_MShape/separable_conv2d/depthwise, separable_conv2d_insert_copy_MShape/separable_conv2d/ReadVariableOp_1)' with input shapes: [?,0,7,4], [1,1,0,736].

Call arguments received:
   inputs=tf.Tensor(shape=(None, 0, 9, 4), dtype=float32)
2024-06-13 06:34:59,932 logger.py[line:35] INFO INFO: Mutation progress 98/100
2024-06-13 06:34:59,933 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:34:59,933 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:34:59,933 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:34:59,933 logger.py[line:35] INFO Score for MParam is: 0.7162162162162162
2024-06-13 06:34:59,933 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:34:59,933 logger.py[line:35] INFO Score for MDims is: 0.7021276595744681
2024-06-13 06:34:59,933 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:34:59,933 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:34:59,933 logger.py[line:35] INFO Score for SpecialI is: 0.46
2024-06-13 06:34:59,933 logger.py[line:35] INFO The last used seed is: MShape
2024-06-13 06:34:59,933 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:34:59,933 logger.py[line:35] INFO Choose seed: inception.resnet.v2-MParam50-MDtype52-MDtype102-MDtype81
2024-06-13 06:34:59,933 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:35:07,483 logger.py[line:35] INFO Generating model using MParam
model outputs {'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam')>}
2024-06-13 06:35:11,215 logger.py[line:35] INFO Changing 2/15 of layer conv2d_39_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:35:11,215 logger.py[line:35] INFO changing config filters in layer conv2d_39_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from 32 to 8
2024-06-13 06:35:11,215 logger.py[line:35] INFO changing config kernel_constraint in layer conv2d_39_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from None to Constraint
2024-06-13 06:35:11,215 logger.py[line:35] INFO changing config bias_regularizer in layer conv2d_39_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from None to l2
2024-06-13 06:35:11,215 logger.py[line:35] INFO Changing 1/1 of layer block17_14_mixed_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:35:11,216 logger.py[line:35] INFO changing config axis in layer block17_14_mixed_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from 3 to -2
2024-06-13 06:35:11,216 logger.py[line:35] INFO Changing 2/5 of layer batch_normalization_61_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:35:11,216 logger.py[line:35] INFO changing config center in layer batch_normalization_61_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:35:11,216 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:35:11,216 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:35:11,216 logger.py[line:35] INFO changing config axis in layer batch_normalization_61_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:35:11,216 logger.py[line:35] INFO changing config scale in layer batch_normalization_61_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from False to True
2024-06-13 06:35:11,216 logger.py[line:35] INFO Changing 1/15 of layer block17_15_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:35:11,216 logger.py[line:35] INFO changing config padding in layer block17_15_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from same to valid
2024-06-13 06:35:11,217 logger.py[line:35] INFO changing config bias_regularizer in layer block17_15_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from None to l2
2024-06-13 06:35:11,217 logger.py[line:35] INFO Changing 3/15 of layer conv2d_158_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:35:11,217 logger.py[line:35] INFO changing config kernel_initializer in layer conv2d_158_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}} to lecun_uniform
2024-06-13 06:35:11,217 logger.py[line:35] INFO changing config activity_regularizer in layer conv2d_158_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from None to l2
2024-06-13 06:35:11,217 logger.py[line:35] INFO changing config padding in layer conv2d_158_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from valid to valid
2024-06-13 06:35:11,217 logger.py[line:35] INFO changing config data_format in layer conv2d_158_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from channels_last to channels_first
2024-06-13 06:35:11,217 logger.py[line:35] INFO Changing 1/5 of layer batch_normalization_118_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:35:11,217 logger.py[line:35] INFO changing config center in layer batch_normalization_118_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from True to False
2024-06-13 06:35:11,217 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:35:11,217 logger.py[line:35] INFO changing config axis in layer batch_normalization_118_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from ListWrapper([3]) to -1
2024-06-13 06:35:11,217 logger.py[line:35] INFO Changing 3/5 of layer batch_normalization_21_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:35:11,217 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:35:11,218 logger.py[line:35] INFO changing config scale in layer batch_normalization_21_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from False to False
2024-06-13 06:35:11,218 logger.py[line:35] INFO changing config axis in layer batch_normalization_21_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from ListWrapper([3]) to -2
2024-06-13 06:35:11,218 logger.py[line:35] INFO changing config center in layer batch_normalization_21_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from True to True
2024-06-13 06:35:11,218 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:35:11,218 logger.py[line:35] INFO Changing 1/1 of layer block8_10_mixed_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:35:11,218 logger.py[line:35] INFO changing config axis in layer block8_10_mixed_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from 3 to -2
2024-06-13 06:35:11,218 logger.py[line:35] INFO Changing 1/15 of layer conv2d_146_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:35:11,218 logger.py[line:35] INFO changing config dilation_rate in layer conv2d_146_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from (1, 1) to [2, 1]
2024-06-13 06:35:11,218 logger.py[line:35] INFO Numeric Parameter Is Full!!
2024-06-13 06:35:11,218 logger.py[line:35] INFO changing config activation in layer conv2d_146_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from linear to exponential
2024-06-13 06:35:11,218 logger.py[line:35] INFO Changing 1/15 of layer block17_8_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam's configuration
2024-06-13 06:35:11,218 logger.py[line:35] INFO changing config bias_regularizer in layer block17_8_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from None to l1
2024-06-13 06:35:11,219 logger.py[line:35] INFO changing config padding in layer block17_8_conv_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam: from same to valid
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 82, in generate_model_by_model_mutation
    architecture_measure=architecture_measure, max_layer_num=MAX_LAYER_NUM, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 283, in mutate_param
    new_model = utils.ModelUtils.functional_model_operation(MParam_model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 101, in functional_model_operation
    x = cloned_layer(layer_input_tensors)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "inception_resnet_v2.py", line 319, in <lambda>
ValueError: Exception encountered when calling layer "block17_14_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam" (type Lambda).

Dimensions must be equal, but are 17 and 34 for '{{node block17_14_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam/add}} = AddV2[T=DT_FLOAT](Placeholder, block17_14_copy_MParam_copy_MDtype_copy_MDtype_copy_MDtype_copy_MParam/mul)' with input shapes: [?,17,17,1088], [?,17,34,1088].

Call arguments received:
   inputs=['tf.Tensor(shape=(None, 17, 17, 1088), dtype=float32)', 'tf.Tensor(shape=(None, 17, 34, 1088), dtype=float32)']
   mask=None
   training=None
2024-06-13 06:35:14,327 logger.py[line:35] INFO INFO: Mutation progress 98/100
2024-06-13 06:35:14,327 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:35:14,327 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:35:14,327 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:35:14,327 logger.py[line:35] INFO Score for MParam is: 0.7162162162162162
2024-06-13 06:35:14,327 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:35:14,327 logger.py[line:35] INFO Score for MDims is: 0.7021276595744681
2024-06-13 06:35:14,327 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:35:14,327 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:35:14,327 logger.py[line:35] INFO Score for SpecialI is: 0.46
2024-06-13 06:35:14,327 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:35:14,328 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:35:14,328 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype58-MDtype89
2024-06-13 06:35:14,328 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:35:18,656 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_Edge_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_MDtype_copy_NLAll')>, 'cropping2d_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'cropping2d_copy_MDtype_copy_MDtype_copy_NLAll')>, 'avg_pool_copy_Edge_2_copy_MDtype_copy_MDtype': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_MDtype_copy_NLAll')>}
2024-06-13 06:35:19,889 logger.py[line:35] INFO Insert 3 out of 26 Local New Layers
2024-06-13 06:35:19,889 logger.py[line:35] INFO insert GaussianNoise after conv1_pad_copy_Edge_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 06:35:19,890 logger.py[line:35] INFO insert ConvLSTM1D after conv4_block4_2_bn_copy_Edge_copy_MDtype_copy_MDtype_copy_NLAll
2024-06-13 06:35:19,890 logger.py[line:35] INFO insert Softmax after cropping2d_copy_MDtype_copy_MDtype_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.noise.GaussianNoise object at 0x7f2d18464610>
2024-06-13 06:35:19,897 logger.py[line:35] INFO Converting output shape (None, 230, 230, 3) to actual shape [None, 230, 230, 3]
[DEBUG] Inserting layer: <keras.layers.convolutional_recurrent.ConvLSTM1D object at 0x7f2d1822ab10>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/recurrent.py", line 679, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/initializers/initializers_v2.py", line 674, in __call__
    'Identity matrix initializer can only be used for 2D matrices. '
ValueError: Identity matrix initializer can only be used for 2D matrices. Received: shape=(1024,) of rank 1.
2024-06-13 06:35:20,998 logger.py[line:35] INFO INFO: Mutation progress 98/100
2024-06-13 06:35:20,998 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:35:20,998 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:35:20,998 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:35:20,999 logger.py[line:35] INFO Score for MParam is: 0.7162162162162162
2024-06-13 06:35:20,999 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:35:20,999 logger.py[line:35] INFO Score for MDims is: 0.7021276595744681
2024-06-13 06:35:20,999 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:35:20,999 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:35:20,999 logger.py[line:35] INFO Score for SpecialI is: 0.46
2024-06-13 06:35:20,999 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:35:20,999 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:35:20,999 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-LMerg10-NLAll66
2024-06-13 06:35:20,999 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:35:25,271 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_LMerg_copy_LMerg_copy_NLAll': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll')>}
2024-06-13 06:35:26,493 logger.py[line:35] INFO Insert 2 out of 21 Local New Layers
2024-06-13 06:35:26,494 logger.py[line:35] INFO insert ConvLSTM1D after conv2_block1_1_bn_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll
2024-06-13 06:35:26,494 logger.py[line:35] INFO insert Softmax after conv1_pad_copy_LMerg_copy_LMerg_copy_NLAll_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.advanced_activations.Softmax object at 0x7f3df0397690>
2024-06-13 06:35:26,515 logger.py[line:35] INFO Converting output shape (None, 230, 230, 3) to actual shape [None, 230, 230, 3]
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 62, in new_layer_addition
    layer_list = selected_layer(output_shape)
  File "/root/implementations/scripts/generation/layer_pools.py", line 463, in conv_lstm_1d
    inserted_layer = ConfigurationUtils.random_config(candidate_layer)
  File "/root/implementations/scripts/generation/layer_pools.py", line 57, in random_config
    new_layer = layer.from_config(layer_config)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 970, in from_config
    return cls(**config)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 1134, in __init__
    **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 842, in __init__
    **kwargs)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/convolutional_recurrent.py", line 141, in __init__
    'Unrolling is not possible with convolutional RNNs. '
TypeError: Unrolling is not possible with convolutional RNNs. Received: unroll=True
2024-06-13 06:35:27,028 logger.py[line:35] INFO INFO: Mutation progress 98/100
2024-06-13 06:35:27,028 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:35:27,029 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:35:27,029 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:35:27,029 logger.py[line:35] INFO Score for MParam is: 0.7162162162162162
2024-06-13 06:35:27,029 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:35:27,029 logger.py[line:35] INFO Score for MDims is: 0.7021276595744681
2024-06-13 06:35:27,029 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:35:27,029 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:35:27,029 logger.py[line:35] INFO Score for SpecialI is: 0.46
2024-06-13 06:35:27,029 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:35:27,029 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:35:27,029 logger.py[line:35] INFO Choose seed: resnet50-Edge65-MDtype58
2024-06-13 06:35:27,029 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:35:31,335 logger.py[line:35] INFO Generating model using NLAll
model outputs {'predictions_copy_Edge_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_Edge_copy_MDtype_copy_NLAll')>, 'cropping2d_copy_MDtype': <KerasTensor: shape=(None, 10, 10, 512) dtype=float32 (created by layer 'cropping2d_copy_MDtype_copy_NLAll')>, 'avg_pool_copy_Edge_2_copy_MDtype': <KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'avg_pool_copy_Edge_2_copy_MDtype_copy_NLAll')>}
2024-06-13 06:35:32,564 logger.py[line:35] INFO Insert 6 out of 26 Local New Layers
2024-06-13 06:35:32,564 logger.py[line:35] INFO insert ActivityRegularization after cropping2d_copy_MDtype_copy_NLAll
2024-06-13 06:35:32,564 logger.py[line:35] INFO insert UpSampling2D after conv1_pad_copy_Edge_copy_MDtype_copy_NLAll
2024-06-13 06:35:32,564 logger.py[line:35] INFO insert AveragePooling2D after cropping2d_copy_MDtype_copy_NLAll
2024-06-13 06:35:32,564 logger.py[line:35] INFO insert Conv2DTranspose after cropping2d_copy_MDtype_copy_NLAll
2024-06-13 06:35:32,565 logger.py[line:35] INFO insert DepthwiseConv2D after pool1_pool_copy_Edge_copy_MDtype_copy_NLAll
2024-06-13 06:35:32,565 logger.py[line:35] INFO insert ReLU after pool1_pool_copy_Edge_copy_MDtype_copy_NLAll
2024-06-13 06:35:32,565 logger.py[line:35] INFO Fail to find enough new layers to insert, randomly choose 3
2024-06-13 06:35:32,568 logger.py[line:35] INFO Fail to find suitable insertion point for dimension: [3]
2024-06-13 06:35:32,568 logger.py[line:35] INFO insert Conv1D after conv4_block5_1_conv_copy_Edge_copy_MDtype_copy_NLAll
2024-06-13 06:35:32,578 logger.py[line:35] INFO insert PReLU after predictions_copy_Edge_copy_MDtype_copy_NLAll
2024-06-13 06:35:32,588 logger.py[line:35] INFO insert GaussianDropout after conv3_block1_0_bn_copy_Edge_copy_MDtype_copy_NLAll
[DEBUG] Inserting layer: <keras.layers.convolutional.UpSampling2D object at 0x7f9c80613a10>
2024-06-13 06:35:32,596 logger.py[line:35] INFO Converting output shape (None, 230, 230, 3) to actual shape [None, 230, 230, 3]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.ReLU object at 0x7f9c80686750>
2024-06-13 06:35:32,623 logger.py[line:35] INFO Converting output shape (None, 56, 56, 64) to actual shape [None, 56, 56, 64]
[DEBUG] Inserting layer: <keras.layers.noise.GaussianDropout object at 0x7f9c801eebd0>
2024-06-13 06:35:32,834 logger.py[line:35] INFO Converting output shape (None, 28, 28, 512) to actual shape [None, 28, 28, 512]
[DEBUG] Inserting layer: <scripts.generation.custom_layers.CustomDropDimLayer object at 0x7f9c80113090>
[DEBUG] Inserting layer: <keras.layers.convolutional.Conv1D object at 0x7f9c801ab950>
2024-06-13 06:35:33,290 logger.py[line:35] INFO Converting output shape (None, 256, 256) to actual shape [None, 14, 14, 256]
[DEBUG] Inserting layer: <keras.layers.advanced_activations.PReLU object at 0x7f9c2858af90>
Traceback (most recent call last):
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/comet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/generation/generate_model.py", line 123, in <module>
    new_model = modelGenerator.mutate_model(origin_model)
  File "/root/implementations/scripts/generation/generate_model.py", line 58, in mutate_model
    architecture_measure=self.architecture_measure
  File "/root/implementations/scripts/mutation/structure_mutation_generators.py", line 69, in generate_model_by_model_mutation
    return InteractionMutationUtils.insert_layers(model=model, layer_type=operator, max_num=MAX_LAYER_NUM, architecture_measure=architecture_measure, mutation_mode=mutation_operator_mode)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 134, in insert_layers
    mutated_model = NL_mut(NL_model, selection_pair, [])
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 82, in NL_mut
    new_model = utils.ModelUtils.functional_model_operation(model, operation=operation)
  File "/root/implementations/scripts/tools/utils.py", line 92, in functional_model_operation
    x = operation[layer.name](x, cloned_layer)
  File "/root/implementations/scripts/mutation/comet_mutation_operators.py", line 65, in new_layer_addition
    y = layer(layer_input)
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/envs/comet/lib/python3.7/site-packages/keras/layers/advanced_activations.py", line 147, in build
    param_shape[i - 1] = 1
IndexError: list assignment index out of range
2024-06-13 06:35:34,206 logger.py[line:35] INFO INFO: Mutation progress 98/100
2024-06-13 06:35:34,206 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:35:34,207 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:35:34,207 logger.py[line:35] INFO Score for Edge is: 0.7162162162162162
2024-06-13 06:35:34,207 logger.py[line:35] INFO Score for MParam is: 0.7162162162162162
2024-06-13 06:35:34,207 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:35:34,207 logger.py[line:35] INFO Score for MDims is: 0.7021276595744681
2024-06-13 06:35:34,207 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:35:34,207 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:35:34,207 logger.py[line:35] INFO Score for SpecialI is: 0.46
2024-06-13 06:35:34,207 logger.py[line:35] INFO The last used seed is: NLAll
2024-06-13 06:35:34,207 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:35:34,207 logger.py[line:35] INFO Choose seed: resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype87
2024-06-13 06:35:34,207 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:35:38,634 logger.py[line:35] INFO Generating model using Edge
model outputs {'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype': <KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge')>}
Choosing 7 To Insert
2024-06-13 06:35:39,626 logger.py[line:35] INFO Insert 7 Local New Edges
2024-06-13 06:35:39,626 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'BatchNormalization')
2024-06-13 06:35:40,609 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting conv2_block1_0_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv3_block1_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:41,513 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'BatchNormalization'] by Connecting conv2_block1_0_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv3_block1_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:41,513 logger.py[line:35] INFO Candidate Edge: ('Conv2D', 'BatchNormalization')
2024-06-13 06:35:42,635 logger.py[line:35] INFO Trying Adding Edge: ['Conv2D', 'BatchNormalization'] by Connecting conv4_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv3_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:43,541 logger.py[line:35] INFO Successfully Add Edge: ['Conv2D', 'BatchNormalization'] by Connecting conv4_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv3_block2_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:43,541 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'ZeroPadding2D')
2024-06-13 06:35:44,549 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'ZeroPadding2D'] by Connecting conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:45,660 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'ZeroPadding2D'] by Connecting conv1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:45,661 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'Conv2D')
2024-06-13 06:35:46,709 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'Conv2D'] by Connecting pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1 and conv2_block1_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:47,671 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'Conv2D'] by Connecting pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1 and conv2_block1_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:47,671 logger.py[line:35] INFO Candidate Edge: ('ZeroPadding2D', 'GlobalAveragePooling2D')
2024-06-13 06:35:48,711 logger.py[line:35] INFO Trying Adding Edge: ['ZeroPadding2D', 'GlobalAveragePooling2D'] by Connecting pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1 and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:49,893 logger.py[line:35] INFO Successfully Add Edge: ['ZeroPadding2D', 'GlobalAveragePooling2D'] by Connecting pool1_pad_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge_1 and avg_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:49,894 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'Conv2D')
2024-06-13 06:35:50,934 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'Conv2D'] by Connecting conv4_block3_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv2_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:51,882 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'Conv2D'] by Connecting conv4_block3_3_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and conv2_block2_2_conv_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:51,882 logger.py[line:35] INFO Candidate Edge: ('BatchNormalization', 'MaxPooling2D')
2024-06-13 06:35:52,923 logger.py[line:35] INFO Trying Adding Edge: ['BatchNormalization', 'MaxPooling2D'] by Connecting conv4_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:54,075 logger.py[line:35] INFO Successfully Add Edge: ['BatchNormalization', 'MaxPooling2D'] by Connecting conv4_block3_1_bn_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge and pool1_pool_copy_LMerg_copy_MShape_copy_MDtype_copy_MParam_copy_MDtype_copy_Edge
2024-06-13 06:35:54,211 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
The API Pair Coverage Is: 178/2170
The Configuration Coverage is: 505/2049
The NDims Coverage Is: 68/117
The DType Coverage Is: 83/354
The Shape Coverage Is: 165/295
The Input Coverage Is: 316/766
2024-06-13 06:35:56,429 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:35:56,892 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
2024-06-13 06:36:28,229 logger.py[line:35] INFO Current GPU device for pytorch: 0
2024-06-13 06:36:28,230 logger.py[line:35] INFO Now pytorch is using: cuda
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 230, in <module>
    predictor.predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 179, in predict
    pred = self.model(self.input)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 224, in forward
    activations[out_op_id] = op(*in_activations)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: expected scalar type Float but found Double

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:36:31,603 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 34s
2024-06-13 06:36:31,603 logger.py[line:35] INFO resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype87-Edge98 crash on backend pytorch when predicting
2024-06-13 06:36:31,624 logger.py[line:35] INFO coverage_c=14541
2024-06-13 06:36:31,685 logger.py[line:35] INFO Fail on backend: pytorch of model resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype87-Edge98
2024-06-13 06:36:31,686 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:36:31,686 logger.py[line:35] INFO after_prediction
2024-06-13 06:36:31,686 logger.py[line:35] INFO No representative seed generated: resnet50-LMerg2-MShape5-MDtype6-MParam94-MDtype87-Edge98, do not increase the reward
2024-06-13 06:36:31,826 logger.py[line:35] INFO INFO: Mutation progress 99/100
2024-06-13 06:36:31,826 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:36:31,826 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:36:31,827 logger.py[line:35] INFO Score for MParam is: 0.7162162162162162
2024-06-13 06:36:31,827 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:36:31,827 logger.py[line:35] INFO Score for Edge is: 0.7066666666666667
2024-06-13 06:36:31,827 logger.py[line:35] INFO Score for MDims is: 0.7021276595744681
2024-06-13 06:36:31,827 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:36:31,827 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:36:31,827 logger.py[line:35] INFO Score for SpecialI is: 0.46
2024-06-13 06:36:31,827 logger.py[line:35] INFO The last used seed is: Edge
2024-06-13 06:36:31,827 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:36:31,827 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-NLAll54-NLAll124-MDtype128
2024-06-13 06:36:31,827 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:36:34,849 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:36:35,635 logger.py[line:35] INFO Generating model using MParam
2024-06-13 06:36:35,638 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_MParam')>}
2024-06-13 06:36:35,855 logger.py[line:35] INFO Changing 1/1 of layer softmax_insert_copy_MDtype_copy_MParam's configuration
2024-06-13 06:36:35,856 logger.py[line:35] INFO changing config axis in layer softmax_insert_copy_MDtype_copy_MParam: from -2 to -2
2024-06-13 06:36:35,856 logger.py[line:35] INFO Changing 2/16 of layer conv3d_transpose_insert_copy_MDtype_copy_MParam's configuration
2024-06-13 06:36:35,856 logger.py[line:35] INFO changing config padding in layer conv3d_transpose_insert_copy_MDtype_copy_MParam: from same to valid
2024-06-13 06:36:35,856 logger.py[line:35] INFO changing config activation in layer conv3d_transpose_insert_copy_MDtype_copy_MParam: from softsign to selu
2024-06-13 06:36:35,856 logger.py[line:35] INFO changing config bias_constraint in layer conv3d_transpose_insert_copy_MDtype_copy_MParam: from {'class_name': 'Constraint', 'config': {}} to UnitNorm
2024-06-13 06:36:35,856 logger.py[line:35] INFO Changing 1/1 of layer up_sampling3d_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_MParam's configuration
2024-06-13 06:36:35,856 logger.py[line:35] INFO changing config data_format in layer up_sampling3d_insert_copy_NLAll_copy_NLAll_copy_MDtype_copy_MParam: from channels_first to channels_first
2024-06-13 06:36:35,859 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_MParam': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_MParam')>}
2024-06-13 06:36:36,172 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:36:36,699 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_NLAll_copy_NLAll_copy_MDtype_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 181/2170
The Configuration Coverage is: 508/2049
The NDims Coverage Is: 68/117
The DType Coverage Is: 84/354
The Shape Coverage Is: 165/295
The Input Coverage Is: 317/766
2024-06-13 06:36:36,946 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:36:37,420 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/envs/model_convertor/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 58, in <module>
    transform_onnx(model_path)
  File "/root/implementations/scripts/tools/prediction_toolkit.py", line 41, in transform_onnx
    model = keras.models.load_model(model_path, custom_objects=custom_objects())
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/save.py", line 201, in load_model
    compile)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/hdf5_format.py", line 181, in load_model_from_hdf5
    custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/saving/model_config.py", line 52, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 678, in deserialize_keras_object
    list(custom_objects.items())))
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 663, in from_config
    config, custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1273, in reconstruct_from_config
    process_layer(layer_data)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/functional.py", line 1255, in process_layer
    layer = deserialize_layer(layer_data, custom_objects=custom_objects)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/serialization.py", line 212, in deserialize
    printable_module_name='layer')
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 681, in deserialize_keras_object
    deserialized_obj = cls.from_config(cls_config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 748, in from_config
    return cls(**config)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/layers/noise.py", line 107, in __init__
    super(GaussianDropout, self).__init__(**kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/engine/base_layer.py", line 323, in __init__
    generic_utils.validate_kwargs(kwargs, allowed_kwargs)
  File "/opt/conda/envs/model_convertor/lib/python3.6/site-packages/keras/utils/generic_utils.py", line 1143, in validate_kwargs
    raise TypeError(error_message, kwarg)
TypeError: ('Keyword argument not understood:', 'seed')
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 141, in before_predict
    onnx_model = onnx.load(self.onnx_path)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 120, in load_model
    s = _load_bytes(f)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx/__init__.py", line 34, in _load_bytes
    with open(cast(Text, f), 'rb') as readable:
FileNotFoundError: [Errno 2] No such file or directory: '/root/data/working_dir/COMET/results/models/lstm2-NLAll38-NLAll54-NLAll124-MDtype128-MParam99/lstm2-NLAll38-NLAll54-NLAll124-MDtype128-MParam99.onnx'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:36:42,743 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 5s
2024-06-13 06:36:42,744 logger.py[line:35] INFO lstm2-NLAll38-NLAll54-NLAll124-MDtype128-MParam99 crash on backend pytorch when predicting
2024-06-13 06:36:42,765 logger.py[line:35] INFO coverage_c=14541
2024-06-13 06:36:42,872 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-NLAll54-NLAll124-MDtype128-MParam99
2024-06-13 06:36:42,872 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:36:42,872 logger.py[line:35] INFO after_prediction
2024-06-13 06:36:43,006 logger.py[line:35] INFO INFO: Mutation progress 100/100
2024-06-13 06:36:43,006 logger.py[line:35] INFO Logging for Seeds
2024-06-13 06:36:43,007 logger.py[line:35] INFO Score for NLAll is: 0.813953488372093
2024-06-13 06:36:43,007 logger.py[line:35] INFO Score for MDtype is: 0.7142857142857143
2024-06-13 06:36:43,007 logger.py[line:35] INFO Score for MParam is: 0.7105263157894737
2024-06-13 06:36:43,007 logger.py[line:35] INFO Score for Edge is: 0.7066666666666667
2024-06-13 06:36:43,007 logger.py[line:35] INFO Score for MDims is: 0.7021276595744681
2024-06-13 06:36:43,007 logger.py[line:35] INFO Score for LMerg is: 0.6875
2024-06-13 06:36:43,007 logger.py[line:35] INFO Score for MShape is: 0.5714285714285714
2024-06-13 06:36:43,007 logger.py[line:35] INFO Score for SpecialI is: 0.46
2024-06-13 06:36:43,007 logger.py[line:35] INFO The last used seed is: MParam
2024-06-13 06:36:43,007 logger.py[line:35] INFO Randomly Choose One Config From the Config Pool: 1
2024-06-13 06:36:43,007 logger.py[line:35] INFO Choose seed: lstm2-NLAll38-MDtype45-MDims17-MDims55
2024-06-13 06:36:43,007 logger.py[line:35] INFO start mutating the generated model
2024-06-13 06:36:46,031 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2024-06-13 06:36:46,734 logger.py[line:35] INFO Generating model using MParam
2024-06-13 06:36:46,737 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MParam')>}
2024-06-13 06:36:46,906 logger.py[line:35] INFO Changing 1/1 of layer up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MParam's configuration
2024-06-13 06:36:46,907 logger.py[line:35] INFO changing config data_format in layer up_sampling3d_insert_copy_MDtype_copy_MDims_copy_MDims_copy_MParam: from channels_first to channels_last
2024-06-13 06:36:46,910 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
model outputs {'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MParam': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MParam')>}
2024-06-13 06:36:47,092 saving_utils.py[line:316] WARNING Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2024-06-13 06:36:47,537 recurrent_v2.py[line:1127] WARNING Layer lstm_1_copy_NLAll_copy_MDtype_copy_MDims_copy_MDims_copy_MParam will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
The API Pair Coverage Is: 181/2170
The Configuration Coverage is: 508/2049
The NDims Coverage Is: 68/117
The DType Coverage Is: 84/354
The Shape Coverage Is: 165/295
The Input Coverage Is: 317/766
2024-06-13 06:36:47,717 logger.py[line:35] INFO Working on Multiprocessing Prediction
2024-06-13 06:36:48,181 logger.py[line:35] INFO Start Predicting on Backend: pytorch
1 Physical GPUs, 1 Logical GPUs
Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 229, in <module>
    predictor.before_predict()
  File "/root/implementations/scripts/prediction/predict_model.py", line 142, in before_predict
    self.model = ConvertModel(onnx_model, experimental=True)
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/model.py", line 126, in __init__
    enable_pruning,
  File "/opt/conda/envs/pytorch/lib/python3.6/site-packages/onnx2pytorch/convert/operations.py", line 159, in convert_operations
    next_node = onnx_graph.node[i + 1]
IndexError: list index (44) out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/implementations/scripts/prediction/predict_model.py", line 235, in <module>
    raise ValueError(f"CRASH ON BACKEND {flags.backend}!!!")
ValueError: CRASH ON BACKEND pytorch!!!
2024-06-13 06:36:55,807 logger.py[line:35] INFO Prediction Time Used on pytorch : 0h, 0m, 7s
2024-06-13 06:36:55,807 logger.py[line:35] INFO lstm2-NLAll38-MDtype45-MDims17-MDims55-MParam100 crash on backend pytorch when predicting
2024-06-13 06:36:55,830 logger.py[line:35] INFO coverage_c=14541
2024-06-13 06:36:55,936 logger.py[line:35] INFO Fail on backend: pytorch of model lstm2-NLAll38-MDtype45-MDims17-MDims55-MParam100
2024-06-13 06:36:55,937 logger.py[line:35] INFO Error: Move Crash model
2024-06-13 06:36:55,937 logger.py[line:35] INFO after_prediction
2024-06-13 06:36:55,937 logger.py[line:35] INFO No representative seed generated: lstm2-NLAll38-MDtype45-MDims17-MDims55-MParam100, do not increase the reward
2024-06-13 06:36:56,063 logger.py[line:35] INFO COMET Is Finished: Time used: 1 hour,33 min,57 sec
